2025-12-13 12:41:09,552 - INFO - Created default predefined prompts
2025-12-13 12:41:09,552 - INFO - Saved 6 prompts to prompts.json
2025-12-13 12:53:23,372 - INFO - Loaded 6 predefined prompts
2025-12-13 13:04:41,379 - INFO - Loaded 6 predefined prompts
2025-12-13 13:05:33,254 - INFO - Loaded 3 API keys
2025-12-13 13:09:09,272 - WARNING - Invalid JSON content from response: b'<!DOCTYPE html>\n<html lang=en>\n  <meta charset=utf-8>\n  <meta name=viewport content="initial-scale=1, minimum-scale=1, width=device-width">\n  <title>Error 403 (Forbidden)!!1</title>\n  <style>\n    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n  </style>\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n  <p><b>403.</b> <ins>That\xe2\x80\x99s an error.</ins>\n  <p>Your client does not have permission to get URL <code>/$discovery/rest</code> from this server.  <ins>That\xe2\x80\x99s all we know.</ins>\n'
2025-12-13 13:09:09,275 - ERROR - PDF processing failed: <HttpError 403 when requesting https://generativelanguage.googleapis.com/$discovery/rest?version=v1beta&key=AIzaSyCB--3e9K9jXd45b8E0gRWj4M-XRS3T28Y returned "Forbidden". Details: "<!DOCTYPE html>
<html lang=en>
  <meta charset=utf-8>
  <meta name=viewport content="initial-scale=1, minimum-scale=1, width=device-width">
  <title>Error 403 (Forbidden)!!1</title>
  <style>
    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}
  </style>
  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>
  <p><b>403.</b> <ins>That’s an error.</ins>
  <p>Your client does not have permission to get URL <code>/$discovery/rest</code> from this server.  <ins>That’s all we know.</ins>
">
2025-12-13 13:09:17,844 - WARNING - Invalid JSON content from response: b'<!DOCTYPE html>\n<html lang=en>\n  <meta charset=utf-8>\n  <meta name=viewport content="initial-scale=1, minimum-scale=1, width=device-width">\n  <title>Error 403 (Forbidden)!!1</title>\n  <style>\n    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n  </style>\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n  <p><b>403.</b> <ins>That\xe2\x80\x99s an error.</ins>\n  <p>Your client does not have permission to get URL <code>/$discovery/rest</code> from this server.  <ins>That\xe2\x80\x99s all we know.</ins>\n'
2025-12-13 13:09:17,845 - ERROR - PDF processing failed: <HttpError 403 when requesting https://generativelanguage.googleapis.com/$discovery/rest?version=v1beta&key=AIzaSyAeEYiizFmdY7hB2UmQWDY_NP4Hf4GNAQc returned "Forbidden". Details: "<!DOCTYPE html>
<html lang=en>
  <meta charset=utf-8>
  <meta name=viewport content="initial-scale=1, minimum-scale=1, width=device-width">
  <title>Error 403 (Forbidden)!!1</title>
  <style>
    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}
  </style>
  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>
  <p><b>403.</b> <ins>That’s an error.</ins>
  <p>Your client does not have permission to get URL <code>/$discovery/rest</code> from this server.  <ins>That’s all we know.</ins>
">
2025-12-13 13:10:02,224 - WARNING - Invalid JSON content from response: b'<!DOCTYPE html>\n<html lang=en>\n  <meta charset=utf-8>\n  <meta name=viewport content="initial-scale=1, minimum-scale=1, width=device-width">\n  <title>Error 403 (Forbidden)!!1</title>\n  <style>\n    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n  </style>\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n  <p><b>403.</b> <ins>That\xe2\x80\x99s an error.</ins>\n  <p>Your client does not have permission to get URL <code>/$discovery/rest</code> from this server.  <ins>That\xe2\x80\x99s all we know.</ins>\n'
2025-12-13 13:10:02,227 - ERROR - PDF processing failed: <HttpError 403 when requesting https://generativelanguage.googleapis.com/$discovery/rest?version=v1beta&key=AIzaSyCZSapNa6rwXOE2ezmdo-LRTrHdGJR1y4Y returned "Forbidden". Details: "<!DOCTYPE html>
<html lang=en>
  <meta charset=utf-8>
  <meta name=viewport content="initial-scale=1, minimum-scale=1, width=device-width">
  <title>Error 403 (Forbidden)!!1</title>
  <style>
    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}
  </style>
  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>
  <p><b>403.</b> <ins>That’s an error.</ins>
  <p>Your client does not have permission to get URL <code>/$discovery/rest</code> from this server.  <ins>That’s all we know.</ins>
">
2025-12-13 14:11:37,663 - INFO - Loaded 6 predefined prompts
2025-12-13 14:12:03,002 - INFO - Loaded 3 API keys
2025-12-13 14:13:11,538 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46-1-20.pdf
2025-12-13 14:13:23,759 - INFO - PDF processed successfully with gemini-2.5-flash
2025-12-13 14:19:19,426 - INFO - Loaded 6 predefined prompts
2025-12-13 14:19:42,114 - INFO - Loaded 3 API keys
2025-12-13 14:22:23,626 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46-1-20.pdf
2025-12-13 14:22:33,185 - INFO - PDF processed successfully with gemini-2.5-flash
2025-12-13 14:22:33,190 - INFO - Response saved to: /home/mohammadbagher/Bolognia 5th Edition 2024 (1)-7-26-46-1-20_response_20251213_142233.txt
2025-12-13 14:26:21,149 - INFO - Loaded 6 predefined prompts
2025-12-13 14:30:09,395 - INFO - Loaded 3 API keys
2025-12-13 14:31:15,279 - INFO - Full prompt being sent (4635 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

You will now receive a PDF, respond in the exact structure described above.
2025-12-13 14:31:24,980 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46-1-20.pdf
2025-12-13 14:31:24,981 - INFO - Sending prompt (length: 4635 characters)
2025-12-13 14:31:32,399 - INFO - Response received (length: 101 characters)
2025-12-13 14:31:33,086 - INFO - PDF processed successfully with gemini-2.5-flash
2025-12-13 14:31:33,087 - INFO - Response length: 101 characters
2025-12-13 14:31:33,094 - WARNING - python-docx not available, saving as text file
2025-12-13 14:31:33,097 - ERROR - Error saving response: cannot access local variable 'prompt' where it is not associated with a value
2025-12-13 14:34:28,017 - INFO - Loaded 6 predefined prompts
2025-12-13 14:34:57,989 - INFO - Loaded 3 API keys
2025-12-13 14:35:49,321 - INFO - === Starting PDF Processing ===
2025-12-13 14:35:49,323 - INFO - Model: gemini-2.5-flash
2025-12-13 14:35:49,323 - INFO - PDF: /home/mohammadbagher/Downloads/Bolognia 5th Edition 2024 (1)-7-26-46-1-20.pdf
2025-12-13 14:35:49,327 - INFO - Full prompt being sent (4635 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

You will now receive a PDF, respond in the exact structure described above.
2025-12-13 14:35:58,770 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46-1-20.pdf
2025-12-13 14:35:58,771 - INFO - Using model: gemini-2.5-flash
2025-12-13 14:35:58,771 - INFO - Sending prompt (length: 4635 characters)
2025-12-13 14:35:58,772 - INFO - Max output tokens: 8192
2025-12-13 14:36:32,629 - INFO - Response received (length: 22595 characters)
2025-12-13 14:36:32,631 - WARNING - Response might be truncated - checking for finish reason
2025-12-13 14:36:32,632 - INFO - Candidate 0 finish reason: 2
2025-12-13 14:36:33,514 - INFO - Extracted response from response.text (22595 chars)
2025-12-13 14:36:33,514 - INFO - PDF processed successfully with gemini-2.5-flash
2025-12-13 14:36:33,515 - INFO - Full response length: 22595 characters
2025-12-13 14:36:33,558 - INFO - === Response Received ===
2025-12-13 14:36:33,558 - INFO - Response length: 22595 characters
2025-12-13 14:36:33,558 - INFO - Response preview (first 500 chars): # Page Metadata
- **Book title**: VESICULOBULLOUS DISEASES
- **Chapter title**: Pemphigoid Group
- **Page numbers**: 517-533.e3 (inclusive of e-figures)
- **Section headings found**:
  - Bullous Pemphigoid
  - Introduction
  - History
  - Epidemiology
  - Pathogenesis
  - Humoral and cellular responses
  - Clinical Features
  - Non-bullous pemphigoid
  - Bullous phase
  - Clinical variants
  - Associated Diseases
  - Drug-induced bullous pemphigoid
  - Diagnosis
  - Light microscopy
  - Direct i...
2025-12-13 14:36:33,558 - INFO - Response preview (last 500 chars): ...in adults, during childhood the condition is frequently associated with annular and polycyclic lesions, often with peripheral blisters, as well as involvement of the genital and perioral region. However, identical features are also observed in childhood BP (see Fig. 30.7B) [18,20].
- **Anti-p200 pemphigoid (anti-laminin $\gamma$1 pemphigoid).** Although patients often have features similar to BP, they tend to be younger and are more likely to have involvement of palmoplantar and cephalic regions
2025-12-13 14:36:33,560 - WARNING - python-docx not available, saving as text file
2025-12-13 14:36:33,562 - ERROR - Error saving response: cannot access local variable 'prompt' where it is not associated with a value
2025-12-14 08:26:11,809 - INFO - Loaded 6 predefined prompts
2025-12-14 08:43:58,560 - INFO - Loaded 6 predefined prompts
2025-12-14 08:44:48,860 - INFO - Loaded 3 API keys
2025-12-14 08:47:28,012 - INFO - === Starting PDF Processing ===
2025-12-14 08:47:28,012 - INFO - Model: gemini-2.5-flash
2025-12-14 08:47:28,013 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/ilovepdf_split/Bolognia 5th Edition 2024 (1)-1.pdf
2025-12-14 08:47:28,013 - INFO - Full prompt being sent (7497 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a CSV in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

بسیار مهم: خروجی ات به صورت تک خطی (Minified) باشد و به هیچ عنوان از دکمه Enter در خروجی ات استفاده نکن.



You will now receive a PDF, respond in the exact structure described above.
2025-12-14 08:47:52,210 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-1.pdf
2025-12-14 08:47:52,211 - INFO - Using max_output_tokens: 8192
2025-12-14 08:47:52,212 - INFO - Using model: gemini-2.5-flash
2025-12-14 08:47:52,213 - INFO - Sending prompt (length: 7497 characters)
2025-12-14 08:47:52,213 - INFO - Max output tokens: 8192
2025-12-14 08:48:43,578 - INFO - Response received (length: 1149 characters)
2025-12-14 08:48:43,580 - WARNING - Response might be truncated - checking for finish reason
2025-12-14 08:48:43,581 - INFO - Candidate 0 finish reason: MAX_TOKENS (truncated!)
2025-12-14 08:48:43,582 - ERROR - ❌ CRITICAL: Response was TRUNCATED due to MAX_TOKENS limit!
2025-12-14 08:48:43,583 - ERROR - Current max_output_tokens: 8192
2025-12-14 08:48:43,583 - ERROR - The response is INCOMPLETE! Consider:
2025-12-14 08:48:43,584 - ERROR -   1. Using gemini-2.5-pro model (better for long responses)
2025-12-14 08:48:43,585 - ERROR -   2. Breaking the task into smaller parts
2025-12-14 08:48:43,587 - ERROR -   3. Simplifying the prompt to get shorter responses
2025-12-14 08:48:44,225 - INFO - Extracted response from response.text (1149 chars)
2025-12-14 08:48:44,225 - INFO - PDF processed successfully with gemini-2.5-flash
2025-12-14 08:48:44,226 - INFO - Full response length: 1149 characters
2025-12-14 08:48:44,226 - INFO - Response preview (first 500 chars): ```csv
Type;;;Extraction;;;Number;;;Part
page text;;;# Page Metadata;;;Book title: Dermatology (Fifth Edition, Volume One);;;Chapter title: Volume One;;;Page number: 1;;;Section headings found: None;;;Confidence notes: None;;;# Body;;;Volume One;;;Enhanced DIGITAL VERSION Included;;;Fifth Edition;;;DERMATOLOGY;;;JEAN L. BOLOGNIA | JULIE V. SCHAFFER | LORENZO CERRONI;;;ASSOCIATE EDITORS;;;JEFFREY P. CALLEN | EDWARD W. COWEN;;;KARYNNE O. DUNCAN | GEORGE J. HRUZA;;;JONATHAN LEVENTHAL | LUIS REQUENA...
2025-12-14 08:48:44,227 - INFO - Response preview (last 500 chars): ... Dermatology;;;Page number: 2;;;Section headings found: ## INTRODUCTION TO CLINICAL DERMATOLOGY, ## Etiologic Premises, ## Inflammatory versus neoplastic, ## Morphology;;;Confidence notes: None;;;# Body;;;OVERVIEW OF BASIC SCIENCE SECTION 1;;;Basic Principles of Dermatology O;;;Whitney A. High, Carlo F. Tomasini, Giuseppe Argenziano, Iris Zalaudek, Marco Ardigò, Chiara Franceschini and Philipp Tschandl;;;Chapter Contents;;;Introduction to Clinical Dermatology. 1;;;The Role of Dermatopathology in
2025-12-14 08:48:44,228 - WARNING - ⚠️ Response might be cut off - doesn't end with proper punctuation
2025-12-14 08:48:58,928 - INFO - === Response Received ===
2025-12-14 08:48:58,929 - INFO - Response length: 1149 characters
2025-12-14 08:48:58,929 - INFO - Truncated: True
2025-12-14 08:48:58,930 - INFO - Response preview (first 500 chars): ```csv
Type;;;Extraction;;;Number;;;Part
page text;;;# Page Metadata;;;Book title: Dermatology (Fifth Edition, Volume One);;;Chapter title: Volume One;;;Page number: 1;;;Section headings found: None;;;Confidence notes: None;;;# Body;;;Volume One;;;Enhanced DIGITAL VERSION Included;;;Fifth Edition;;;DERMATOLOGY;;;JEAN L. BOLOGNIA | JULIE V. SCHAFFER | LORENZO CERRONI;;;ASSOCIATE EDITORS;;;JEFFREY P. CALLEN | EDWARD W. COWEN;;;KARYNNE O. DUNCAN | GEORGE J. HRUZA;;;JONATHAN LEVENTHAL | LUIS REQUENA...
2025-12-14 08:48:58,932 - INFO - Response preview (last 500 chars): ... Dermatology;;;Page number: 2;;;Section headings found: ## INTRODUCTION TO CLINICAL DERMATOLOGY, ## Etiologic Premises, ## Inflammatory versus neoplastic, ## Morphology;;;Confidence notes: None;;;# Body;;;OVERVIEW OF BASIC SCIENCE SECTION 1;;;Basic Principles of Dermatology O;;;Whitney A. High, Carlo F. Tomasini, Giuseppe Argenziano, Iris Zalaudek, Marco Ardigò, Chiara Franceschini and Philipp Tschandl;;;Chapter Contents;;;Introduction to Clinical Dermatology. 1;;;The Role of Dermatopathology in
2025-12-14 08:48:59,317 - WARNING - python-docx not available, saving as text file
2025-12-14 08:48:59,325 - INFO - Response displayed and saved to: /home/mohammadbagher/Desktop/Bolognia 5th Edition 2024 (1)-1_response_20251214_084859.txt
2025-12-14 08:52:42,333 - INFO - Loaded 6 predefined prompts
2025-12-14 08:53:05,310 - INFO - Loaded 3 API keys
2025-12-14 08:54:42,629 - INFO - === Starting PDF Processing ===
2025-12-14 08:54:42,629 - INFO - Model: gemini-2.5-flash
2025-12-14 08:54:42,629 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/ilovepdf_split/Bolognia 5th Edition 2024 (1)-1.pdf
2025-12-14 08:54:42,629 - INFO - Full prompt being sent (7497 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a CSV in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

بسیار مهم: خروجی ات به صورت تک خطی (Minified) باشد و به هیچ عنوان از دکمه Enter در خروجی ات استفاده نکن.



You will now receive a PDF, respond in the exact structure described above.
2025-12-14 08:55:19,003 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-1.pdf
2025-12-14 08:55:19,004 - INFO - Model: gemini-2.5-flash, Max tokens for model: 32768, Using: 32768
2025-12-14 08:55:19,005 - INFO - Using max_output_tokens: 32768
2025-12-14 08:55:19,005 - INFO - Using model: gemini-2.5-flash
2025-12-14 08:55:19,006 - INFO - Sending prompt (length: 7497 characters)
2025-12-14 08:55:19,006 - INFO - Max output tokens: 32768
2025-12-14 08:55:19,007 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 08:57:10,754 - INFO - Streaming completed: 493 chunks, 105231 characters received
2025-12-14 08:57:10,755 - INFO - Streaming finish reason: MAX_TOKENS (truncated!)
2025-12-14 08:57:10,755 - WARNING - ⚠️ Response may be truncated (finish_reason: MAX_TOKENS (truncated!))
2025-12-14 08:57:10,756 - INFO - Response received (length: 105231 characters)
2025-12-14 08:57:10,756 - WARNING - Response might be truncated - checking for finish reason
2025-12-14 08:57:11,617 - INFO - Extracted response from response.text (105231 chars)
2025-12-14 08:57:11,618 - INFO - PDF processed successfully with gemini-2.5-flash
2025-12-14 08:57:11,619 - INFO - Full response length: 105231 characters
2025-12-14 08:57:11,620 - INFO - Response preview (first 500 chars): ```csv
Type;;;Extraction;;;Number;;;Part
page text;;;# Page Metadata\nBook title: Dermatology, Fifth Edition, Volume One\nChapter title: Basic Principles of Dermatology\nPage number: 1 (Chapter Page)\nSection headings found: INTRODUCTION TO CLINICAL DERMATOLOGY, Etiologic Premises, Inflammatory versus neoplastic, Morphology\nConfidence notes: The book title and edition are from the cover page (PDF page 1). Chapter page number is inferred from the chapter contents.;;;# Body\n## INTRODUCTION TO CL...
2025-12-14 08:57:11,621 - INFO - Response preview (last 500 chars): ...e to an underlying plasma cell dyscrasia, whereas in others, exogenous material has been purposefully or accidentally inoculated into the skin (e.g. cosmetic filler material, tattoo pigment). These materials may accumulate within the dermis, the subcutaneous fat, or both. Deposits of some materials, such as the silver in patients with argyria, may be limited to cutaneous adnexa. Use of polarized light or darkfield microscopy (where light enters tissue at an angle that is not perpendicular to the
2025-12-14 08:57:11,622 - INFO - ✓ Response is very long (105231 chars) - likely complete
2025-12-14 08:57:11,623 - WARNING - ⚠️ Response might be cut off - doesn't end with proper punctuation
2025-12-14 09:10:03,349 - INFO - Loaded 6 predefined prompts
2025-12-14 09:10:29,268 - INFO - Loaded 3 API keys
2025-12-14 09:11:05,978 - INFO - === Starting PDF Processing ===
2025-12-14 09:11:05,978 - INFO - Model: gemini-2.5-flash
2025-12-14 09:11:05,978 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/ilovepdf_split/Bolognia 5th Edition 2024 (1)-1.pdf
2025-12-14 09:11:05,978 - INFO - Full prompt being sent (7497 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a CSV in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

بسیار مهم: خروجی ات به صورت تک خطی (Minified) باشد و به هیچ عنوان از دکمه Enter در خروجی ات استفاده نکن.



You will now receive a PDF, respond in the exact structure described above.
2025-12-14 09:11:30,356 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-1.pdf
2025-12-14 09:11:30,357 - INFO - Model: gemini-2.5-flash, Max tokens for model: 32768, Using: 32768
2025-12-14 09:11:30,357 - INFO - Using max_output_tokens: 32768
2025-12-14 09:11:30,358 - INFO - Using model: gemini-2.5-flash
2025-12-14 09:11:30,358 - INFO - Sending prompt (length: 7497 characters)
2025-12-14 09:11:30,359 - INFO - Max output tokens: 32768
2025-12-14 09:11:30,359 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 09:14:02,864 - INFO - Streaming completed: 342 chunks, 70844 characters received
2025-12-14 09:14:02,865 - INFO - Streaming finish reason: MAX_TOKENS (truncated!)
2025-12-14 09:14:02,866 - WARNING - ⚠️ Response may be truncated (finish_reason: MAX_TOKENS (truncated!))
2025-12-14 09:14:02,867 - INFO - Response received (length: 70844 characters)
2025-12-14 09:14:02,867 - WARNING - Response might be truncated - checking for finish reason
2025-12-14 09:14:03,715 - INFO - Extracted response from response.text (70844 chars)
2025-12-14 09:14:03,716 - WARNING - CSV code block missing closing marker - response may be truncated
2025-12-14 09:14:03,717 - INFO - PDF processed successfully with gemini-2.5-flash
2025-12-14 09:14:03,717 - INFO - Full response length: 70844 characters
2025-12-14 09:14:03,718 - INFO - Extracted CSV from code block: 70837 characters
2025-12-14 09:14:03,718 - INFO - Response preview (first 500 chars): Type;;;Extraction;;;Number;;;Part
page text;;;# Page Metadata\nBook title: DERMATOLOGY Volume One Fifth Edition\nChapter title: Basic Principles of Dermatology\nPage number: 1 (PDF page 2)\nSection headings found: Chapter Contents, INTRODUCTION TO CLINICAL DERMATOLOGY, Etiologic Premises, Inflammatory versus neoplastic, Morphology\nConfidence notes: none\n# Body\n## Chapter Contents\nIntroduction to Clinical Dermatology. 1\nThe Role of Dermatopathology in Clinicopathologic Correlation. . .12\nIn...
2025-12-14 09:14:03,718 - INFO - Response preview (last 500 chars): ...There is often associated exocytosis of inflammatory cells, with migration from the vasculature into the epidermis. It is important to note that even those spongiotic dermatitides that characteristically develop vesicles, for example acute allergic contact dermatitis, may not do so, i.e. patients have only macules and papules throughout the entire course of their disease.\nSpongiotic dermatoses may be further subdivided into acute, subacute, and chronic forms. In acute spongiotic dermatitis, the
2025-12-14 09:14:03,718 - INFO - ✓ Response is very long (70837 chars) - likely complete
2025-12-14 09:14:03,719 - INFO - ✓ CSV response appears complete (last row has delimiter)
2025-12-14 09:15:20,731 - INFO - === Response Received ===
2025-12-14 09:15:20,732 - INFO - Response length: 70837 characters
2025-12-14 09:15:20,732 - INFO - Truncated: True
2025-12-14 09:15:20,733 - INFO - Response preview (first 500 chars): Type;;;Extraction;;;Number;;;Part
page text;;;# Page Metadata\nBook title: DERMATOLOGY Volume One Fifth Edition\nChapter title: Basic Principles of Dermatology\nPage number: 1 (PDF page 2)\nSection headings found: Chapter Contents, INTRODUCTION TO CLINICAL DERMATOLOGY, Etiologic Premises, Inflammatory versus neoplastic, Morphology\nConfidence notes: none\n# Body\n## Chapter Contents\nIntroduction to Clinical Dermatology. 1\nThe Role of Dermatopathology in Clinicopathologic Correlation. . .12\nIn...
2025-12-14 09:15:20,736 - INFO - Response preview (last 500 chars): ...There is often associated exocytosis of inflammatory cells, with migration from the vasculature into the epidermis. It is important to note that even those spongiotic dermatitides that characteristically develop vesicles, for example acute allergic contact dermatitis, may not do so, i.e. patients have only macules and papules throughout the entire course of their disease.\nSpongiotic dermatoses may be further subdivided into acute, subacute, and chronic forms. In acute spongiotic dermatitis, the
2025-12-14 09:15:21,163 - INFO - Response saved to CSV file: /home/mohammadbagher/Downloads/PDFs/ilovepdf_split/Bolognia 5th Edition 2024 (1)-1_response_20251214_091521.csv
2025-12-14 09:15:21,165 - INFO - Response displayed and saved to: /home/mohammadbagher/Downloads/PDFs/ilovepdf_split/Bolognia 5th Edition 2024 (1)-1_response_20251214_091521.csv
2025-12-14 09:29:22,706 - INFO - Loaded 6 predefined prompts
2025-12-14 09:30:08,848 - INFO - Loaded 3 API keys
2025-12-14 09:32:50,087 - INFO - === Starting PDF Processing ===
2025-12-14 09:32:50,087 - INFO - Model: gemini-2.5-flash
2025-12-14 09:32:50,088 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/ilovepdf_split/Bolognia 5th Edition 2024 (1)-1.pdf
2025-12-14 09:32:50,088 - INFO - Full prompt being sent (7497 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a CSV in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

بسیار مهم: خروجی ات به صورت تک خطی (Minified) باشد و به هیچ عنوان از دکمه Enter در خروجی ات استفاده نکن.



You will now receive a PDF, respond in the exact structure described above.
2025-12-14 09:32:50,191 - INFO - Processing PDF with 100 pages in batches of 10 pages
2025-12-14 09:33:20,103 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-1.pdf
2025-12-14 09:33:20,106 - INFO - Processing batch 1/10: pages 1-10
2025-12-14 09:34:21,706 - INFO - Extracted content from generic code block
2025-12-14 09:34:21,708 - INFO - Batch pages 1-10: Extracted 22 rows
2025-12-14 09:34:21,713 - INFO - Processing batch 2/10: pages 11-20
2025-12-14 09:36:08,896 - INFO - Extracted content from generic code block
2025-12-14 09:36:08,898 - INFO - Batch pages 11-20: Extracted 29 rows
2025-12-14 09:36:08,902 - INFO - Processing batch 3/10: pages 21-30
2025-12-14 09:37:20,991 - INFO - Extracted content from generic code block
2025-12-14 09:37:20,994 - INFO - Batch pages 21-30: Extracted 27 rows
2025-12-14 09:37:20,999 - INFO - Processing batch 4/10: pages 31-40
2025-12-14 09:39:03,077 - WARNING - Code block missing closing marker - response may be truncated
2025-12-14 09:39:03,086 - WARNING - Could not extract JSON from response
2025-12-14 09:39:03,087 - WARNING - Batch pages 31-40: No JSON data extracted
2025-12-14 09:39:03,097 - WARNING - Batch 4 returned no results
2025-12-14 09:39:03,103 - INFO - Processing batch 5/10: pages 41-50
2025-12-14 09:40:08,332 - INFO - Batch pages 41-50: Extracted 28 rows
2025-12-14 09:40:08,337 - INFO - Processing batch 6/10: pages 51-60
2025-12-14 09:40:54,813 - INFO - Batch pages 51-60: Extracted 27 rows
2025-12-14 09:40:54,817 - INFO - Processing batch 7/10: pages 61-70
2025-12-14 09:42:17,153 - INFO - Extracted content from generic code block
2025-12-14 09:42:17,155 - INFO - Batch pages 61-70: Extracted 10 rows
2025-12-14 09:42:17,158 - INFO - Processing batch 8/10: pages 71-80
2025-12-14 09:43:25,275 - INFO - Extracted content from generic code block
2025-12-14 09:43:25,278 - INFO - Batch pages 71-80: Extracted 22 rows
2025-12-14 09:43:25,282 - INFO - Processing batch 9/10: pages 81-90
2025-12-14 09:44:35,776 - INFO - Batch pages 81-90: Extracted 28 rows
2025-12-14 09:44:35,782 - INFO - Processing batch 10/10: pages 91-100
2025-12-14 09:45:57,680 - INFO - Extracted content from generic code block
2025-12-14 09:45:57,683 - WARNING - Could not extract JSON from response
2025-12-14 09:45:57,684 - WARNING - Batch pages 91-100: No JSON data extracted
2025-12-14 09:45:57,687 - WARNING - Batch 10 returned no results
2025-12-14 09:45:59,077 - INFO - === Response Received ===
2025-12-14 09:45:59,077 - INFO - Response length: 401511 characters
2025-12-14 09:45:59,077 - INFO - Truncated: False
2025-12-14 09:45:59,077 - INFO - Response preview (first 500 chars): Type;;;Extraction;;;Number;;;Part
page text;;;# Page Metadata
- Book title: DERMATOLOGY Volume One, Fifth Edition
- Author(s): JEAN L. BOLOGNIA, JULIE V. SCHAFFER, LORENZO CERRONI (Associate Editors: JEFFREY P. CALLEN, EDWARD W. COWEN, KARYNNE O. DUNCAN, GEORGE J. HRUZA, JONATHAN LEVENTHAL, LUIS REQUENA, ANTONIO TORRELO, THOMAS WIESNER)
- Page number: 1 (Cover page)
- Section headings found: None
- Confidence notes: Page 1 is a cover page, no main body text content.;;;1;;;1
page text;;;# Page Me...
2025-12-14 09:45:59,077 - INFO - Response preview (last 500 chars): ..."ddTTP", "ddCTP", "ddGTP", "CA", "CACCGAAT", "CACCG", "CACCGA", "CACCGAATACAT", "CACCGAATACATCTG", "CACCGAA", "CACCGAATA", "CACCGAATACA", "CACCGAATACATCT", "CACCGAATACATC", "3'", "GTCTACATAAGCCAC", "CACCGAATACATCTG", "CACCGAATACATCT", "CACCGAATACATC", "CACCGAATACAT", "CACCGAATACA", "CACCGAATAC", "CACCGAATA", "CACCGAAT", "CACCGAA", "CACCGA", "CACCG", "CACC", "CAC", "CA", "5'", "Sequencing gel", "CACCGAATACATCTG", "80", "390", "Automated fluorescent sequencing scan"], "data_points": null};;;90;;;1
2025-12-14 09:45:59,389 - WARNING - python-docx not available, saving as text file
2025-12-14 09:45:59,397 - INFO - Response displayed and saved to: /home/mohammadbagher/Downloads/PDFs/ilovepdf_split/Bolognia 5th Edition 2024 (1)-1_response_20251214_094559.txt
2025-12-14 10:09:42,623 - INFO - Loaded 6 predefined prompts
2025-12-14 10:10:00,618 - INFO - Loaded 3 API keys
2025-12-14 10:10:55,885 - INFO - === Starting PDF Processing ===
2025-12-14 10:10:55,885 - INFO - Model: gemini-2.5-flash
2025-12-14 10:10:55,886 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/ilovepdf_split/Bolognia 5th Edition 2024 (1)-1.pdf
2025-12-14 10:10:55,886 - INFO - Full prompt being sent (7387 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a CSV in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER
You will now receive a PDF, respond in the exact structure described above.
2025-12-14 10:10:55,996 - INFO - Processing PDF with 100 pages in batches of 10 pages
2025-12-14 10:10:55,997 - INFO - Using original prompt with JSON output instruction for batch processing (prompt preserved)
2025-12-14 10:12:03,061 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-1.pdf
2025-12-14 10:12:03,064 - INFO - Processing batch 1/10: pages 1-10
2025-12-14 10:12:52,157 - INFO - ✓ Batch pages 1-10: Completed normally
2025-12-14 10:12:52,166 - INFO - Successfully extracted JSON array using regex with 26 items
2025-12-14 10:12:52,167 - INFO - Batch pages 1-10: Extracted 26 rows
2025-12-14 10:12:52,174 - INFO - Processing batch 2/10: pages 11-20
2025-12-14 10:13:48,536 - INFO - ✓ Batch pages 11-20: Completed normally
2025-12-14 10:13:48,537 - INFO - Extracted content from generic code block
2025-12-14 10:13:48,539 - INFO - Successfully parsed JSON array with 33 items
2025-12-14 10:13:48,540 - INFO - Batch pages 11-20: Extracted 33 rows
2025-12-14 10:13:48,547 - INFO - Processing batch 3/10: pages 21-30
2025-12-14 10:14:51,098 - INFO - ✓ Batch pages 21-30: Completed normally
2025-12-14 10:14:51,100 - INFO - Extracted content from generic code block
2025-12-14 10:14:51,103 - INFO - Successfully parsed JSON array with 26 items
2025-12-14 10:14:51,104 - INFO - Batch pages 21-30: Extracted 26 rows
2025-12-14 10:14:51,109 - INFO - Processing batch 4/10: pages 31-40
2025-12-14 10:16:00,280 - INFO - ✓ Batch pages 31-40: Completed normally
2025-12-14 10:16:00,281 - INFO - Extracted content from generic code block
2025-12-14 10:16:00,281 - INFO - Successfully parsed JSON array with 33 items
2025-12-14 10:16:00,281 - INFO - Batch pages 31-40: Extracted 33 rows
2025-12-14 10:16:00,282 - INFO - Processing batch 5/10: pages 41-50
2025-12-14 10:16:41,071 - INFO - ✓ Batch pages 41-50: Completed normally
2025-12-14 10:16:41,072 - INFO - Extracted content from generic code block
2025-12-14 10:16:41,074 - INFO - Successfully parsed JSON array with 16 items
2025-12-14 10:16:41,075 - INFO - Batch pages 41-50: Extracted 16 rows
2025-12-14 10:16:41,079 - INFO - Processing batch 6/10: pages 51-60
2025-12-14 10:17:38,176 - INFO - ✓ Batch pages 51-60: Completed normally
2025-12-14 10:17:38,178 - INFO - Extracted content from generic code block
2025-12-14 10:17:38,183 - INFO - Successfully parsed JSON array with 18 items
2025-12-14 10:17:38,183 - INFO - Batch pages 51-60: Extracted 18 rows
2025-12-14 10:17:38,187 - INFO - Processing batch 7/10: pages 61-70
2025-12-14 10:18:37,573 - INFO - ✓ Batch pages 61-70: Completed normally
2025-12-14 10:18:37,574 - INFO - Extracted content from generic code block
2025-12-14 10:18:37,576 - INFO - Successfully parsed JSON array with 23 items
2025-12-14 10:18:37,577 - INFO - Batch pages 61-70: Extracted 23 rows
2025-12-14 10:18:37,584 - INFO - Processing batch 8/10: pages 71-80
2025-12-14 10:20:18,939 - WARNING - ⚠️ Batch pages 71-80: Response may be truncated (MAX_TOKENS)
2025-12-14 10:20:18,941 - WARNING - Code block missing closing marker - response may be truncated
2025-12-14 10:20:18,954 - WARNING - Regex-extracted JSON also failed to parse: Unterminated string starting at: line 124 column 19 (char 63259)
2025-12-14 10:20:18,955 - WARNING - JSON appears to be truncated (missing closing bracket)
2025-12-14 10:20:18,957 - WARNING - Could not extract valid JSON from response
2025-12-14 10:20:18,958 - WARNING - Batch pages 71-80: No JSON data extracted
2025-12-14 10:20:18,964 - WARNING - Batch 8 returned no results
2025-12-14 10:20:19,034 - INFO - Processing batch 9/10: pages 81-90
2025-12-14 10:21:13,367 - INFO - ✓ Batch pages 81-90: Completed normally
2025-12-14 10:21:13,368 - INFO - Extracted content from generic code block
2025-12-14 10:21:13,374 - WARNING - Regex-extracted JSON also failed to parse: Expecting ',' delimiter: line 23 column 5 (char 14563)
2025-12-14 10:21:13,375 - WARNING - Could not extract valid JSON from response
2025-12-14 10:21:13,375 - WARNING - Batch pages 81-90: No JSON data extracted
2025-12-14 10:21:13,379 - WARNING - Batch 9 returned no results
2025-12-14 10:21:13,382 - INFO - Processing batch 10/10: pages 91-100
2025-12-14 10:22:12,482 - INFO - ✓ Batch pages 91-100: Completed normally
2025-12-14 10:22:12,485 - INFO - Extracted content from generic code block
2025-12-14 10:22:12,492 - INFO - Successfully parsed JSON array with 22 items
2025-12-14 10:22:12,494 - INFO - Batch pages 91-100: Extracted 22 rows
2025-12-14 10:22:12,551 - INFO - CSV saved to: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 (1)-1_output_20251214_102212.csv
2025-12-14 10:22:12,591 - INFO - CSV saved to: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 (1)-1_output_20251214_102212.csv
2025-12-14 10:22:14,356 - INFO - === Response Received ===
2025-12-14 10:22:14,356 - INFO - Response length: 369443 characters
2025-12-14 10:22:14,357 - INFO - Truncated: False
2025-12-14 10:22:14,357 - INFO - Response preview (first 500 chars): Type;;;Extraction;;;Number;;;Part
page text;;;# Page Metadata
- Book title: DERMATOLOGY
- Chapter title: Basic Principles of Dermatology
- Page number: 1
- Section headings: OVERVIEW OF BASIC SCIENCE SECTION 1, Chapter Contents, INTRODUCTION TO CLINICAL DERMATOLOGY, Etiologic Premises, Inflammatory versus neoplastic, Morphology

# Body
## Chapter Contents
Introduction to Clinical Dermatology. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
The Role of Dermatopathology i...
2025-12-14 10:22:14,357 - INFO - Response preview (last 500 chars): ...ion of phagosome with ER, retransport to cytoplasm, degradation by proteasomes, and entry into the TAP pathway.", "visible_labels": ["THE PATHWAY OF ENDOGENOUS ANTIGEN DELIVERY TO MHC CLASS I MOLECULES", "Cell membrane", "Endoplasmic reticulum", "Calnexin", "MHCI", "β₂m", "Cytoplasm", "Endogenous protein (viral, tumor)", "Proteasome", "Digested protein", "TAP, transporter associated with antigen processing", "Golgi apparatus", "TAP-1 and TAP-2", "MHCI", "Antigen"], "data_points": null};;;100;;;1
2025-12-14 10:22:14,730 - WARNING - python-docx not available, saving as text file
2025-12-14 10:22:14,742 - INFO - Response displayed and saved to: /home/mohammadbagher/Downloads/PDFs/ilovepdf_split/Bolognia 5th Edition 2024 (1)-1_response_20251214_102214.txt
2025-12-14 10:48:07,033 - INFO - Loaded 6 predefined prompts
2025-12-14 10:48:30,003 - INFO - Loaded 3 API keys
2025-12-14 10:49:43,525 - INFO - === Starting PDF Processing ===
2025-12-14 10:49:43,526 - INFO - Model: gemini-2.5-pro
2025-12-14 10:49:43,527 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/ilovepdf_split/Bolognia 5th Edition 2024 (1)-1.pdf
2025-12-14 10:49:43,528 - INFO - Full prompt being sent (7387 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “,”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.
You will now receive a PDF, respond in the exact structure described above.
2025-12-14 10:50:40,424 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-1.pdf
2025-12-14 10:50:40,424 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 10:50:40,424 - INFO - Using max_output_tokens: 32768
2025-12-14 10:50:40,424 - INFO - Using model: gemini-2.5-pro
2025-12-14 10:50:40,424 - INFO - Sending prompt (length: 7387 characters)
2025-12-14 10:50:40,424 - INFO - Max output tokens: 32768
2025-12-14 10:50:40,424 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 10:50:40,424 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 10:59:51,233 - WARNING - Streaming not available or failed: 429 Resource has been exhausted (e.g. check quota)., using non-streaming
2025-12-14 10:59:51,777 - ERROR - PDF processing failed: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 11:08:16,387 - INFO - === Starting PDF Processing ===
2025-12-14 11:08:16,387 - INFO - Model: gemini-2.5-pro
2025-12-14 11:08:16,387 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:08:16,387 - INFO - Full prompt being sent (7387 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “,”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.
You will now receive a PDF, respond in the exact structure described above.
2025-12-14 11:08:26,787 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:08:26,788 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 11:08:26,790 - INFO - Using max_output_tokens: 32768
2025-12-14 11:08:26,791 - INFO - Using model: gemini-2.5-pro
2025-12-14 11:08:26,791 - INFO - Sending prompt (length: 7387 characters)
2025-12-14 11:08:26,792 - INFO - Max output tokens: 32768
2025-12-14 11:08:26,792 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 11:08:26,793 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 11:08:28,132 - WARNING - Streaming not available or failed: 403 Your API key was reported as leaked. Please use another API key., using non-streaming
2025-12-14 11:08:28,509 - ERROR - PDF processing failed: 403 Your API key was reported as leaked. Please use another API key.
2025-12-14 11:08:48,876 - INFO - Loaded 6 predefined prompts
2025-12-14 11:09:23,963 - INFO - Loaded 3 API keys
2025-12-14 11:09:56,179 - INFO - === Starting PDF Processing ===
2025-12-14 11:09:56,179 - INFO - Model: gemini-1.5-pro
2025-12-14 11:09:56,179 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:09:56,179 - INFO - Full prompt being sent (7387 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “,”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.
You will now receive a PDF, respond in the exact structure described above.
2025-12-14 11:10:06,088 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 11:10:06,088 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:10:06,091 - INFO - Model: gemini-1.5-pro, Max tokens for model: 8192, Using: 8192
2025-12-14 11:10:06,092 - INFO - Using max_output_tokens: 8192
2025-12-14 11:10:06,094 - INFO - Using model: gemini-1.5-pro
2025-12-14 11:10:06,094 - INFO - Sending prompt (length: 7387 characters)
2025-12-14 11:10:06,094 - INFO - Max output tokens: 8192
2025-12-14 11:10:06,095 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 11:10:06,095 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 11:10:07,343 - ERROR - Error processing PDF: 'GeminiAPIClient' object has no attribute '_is_quota_error'
Traceback (most recent call last):
  File "/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/api_layer.py", line 1074, in process_pdf_with_prompt
    response_stream = model.generate_content(
                      ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohammadbagher/anaconda3/lib/python3.11/site-packages/google/generativeai/generative_models.py", line 325, in generate_content
    iterator = self._client.stream_generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohammadbagher/anaconda3/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 1143, in stream_generate_content
    response = rpc(
               ^^^^
  File "/home/mohammadbagher/anaconda3/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohammadbagher/anaconda3/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/home/mohammadbagher/anaconda3/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/mohammadbagher/anaconda3/lib/python3.11/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/home/mohammadbagher/anaconda3/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/home/mohammadbagher/anaconda3/lib/python3.11/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohammadbagher/anaconda3/lib/python3.11/site-packages/google/api_core/grpc_helpers.py", line 173, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.NotFound: 404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/api_layer.py", line 1143, in process_pdf_with_prompt
    if self._is_quota_error(stream_error):
       ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'GeminiAPIClient' object has no attribute '_is_quota_error'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/main_gui.py", line 566, in worker
    response = self.api_client.process_pdf_with_prompt(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/api_layer.py", line 1342, in process_pdf_with_prompt
    if self._is_quota_error(e):
       ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'GeminiAPIClient' object has no attribute '_is_quota_error'
2025-12-14 11:11:50,982 - INFO - Loaded 6 predefined prompts
2025-12-14 11:12:22,396 - INFO - Loaded 3 API keys
2025-12-14 11:12:42,414 - INFO - === Starting PDF Processing ===
2025-12-14 11:12:42,414 - INFO - Model: gemini-2.5-pro
2025-12-14 11:12:42,414 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:12:42,414 - INFO - Full prompt being sent (7387 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “,”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.
You will now receive a PDF, respond in the exact structure described above.
2025-12-14 11:12:54,933 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 11:12:54,934 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:12:54,935 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 11:12:54,936 - INFO - Using max_output_tokens: 32768
2025-12-14 11:12:54,936 - INFO - Using model: gemini-2.5-pro
2025-12-14 11:12:54,937 - INFO - Sending prompt (length: 7387 characters)
2025-12-14 11:12:54,938 - INFO - Max output tokens: 32768
2025-12-14 11:12:54,939 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 11:12:54,939 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 11:12:56,136 - WARNING - Streaming not available or failed: 403 Your API key was reported as leaked. Please use another API key., using non-streaming
2025-12-14 11:12:56,453 - ERROR - PDF processing failed: 403 Your API key was reported as leaked. Please use another API key.
2025-12-14 11:21:55,901 - INFO - Loaded 6 predefined prompts
2025-12-14 11:22:18,319 - INFO - Loaded 3 API keys
2025-12-14 11:22:46,107 - INFO - === Starting PDF Processing ===
2025-12-14 11:22:46,108 - INFO - Model: gemini-2.5-flash
2025-12-14 11:22:46,108 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:22:46,108 - INFO - Full prompt being sent (7387 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “,”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.
You will now receive a PDF, respond in the exact structure described above.
2025-12-14 11:23:03,977 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 11:23:03,978 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:23:03,979 - INFO - Model: gemini-2.5-flash, Max tokens for model: 32768, Using: 32768
2025-12-14 11:23:03,979 - INFO - Using max_output_tokens: 32768
2025-12-14 11:23:03,980 - INFO - Using model: gemini-2.5-flash
2025-12-14 11:23:03,980 - INFO - Sending prompt (length: 7387 characters)
2025-12-14 11:23:03,981 - INFO - Max output tokens: 32768
2025-12-14 11:23:03,981 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 11:23:03,982 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 11:23:05,281 - WARNING - ⚠️ API key leaked (403) or invalid. Attempting to switch to next key...
2025-12-14 11:23:05,282 - INFO - Retrying with API key 1/3: bagher
2025-12-14 11:23:14,384 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 11:23:14,385 - INFO - Retrying with API key 2/3: bagher
2025-12-14 11:25:38,434 - INFO - ✓ Successfully retried with new API key: bagher
2025-12-14 11:25:39,006 - INFO - === Response Received ===
2025-12-14 11:25:39,007 - INFO - Response length: 106590 characters
2025-12-14 11:25:39,007 - INFO - Truncated: False
2025-12-14 11:25:39,008 - INFO - Response preview (first 500 chars): [{"Type": "page text", "Extraction": "# Page Metadata\nBook title: VESICULOBULLOUS DISEASES SECTION 5\nChapter title: Pemphigoid Group 30\nPage number: 517\nSection headings: Bullous Pemphigoid, Synonym: Pemphigoid, Key features, Introduction, History, Epidemiology, Pathogenesis, Humoral and cellular responses\n\n# Body\n## BULLOUS PEMPHIGOID\n### Synonym: Pemphigoid\n\n### Key features\n- Bullous pemphigoid (BP) is the most common autoimmune subepidermal blistering disease, and its onset is oft...
2025-12-14 11:25:39,008 - INFO - Response preview (last 500 chars): ...rt": 2},
{"Type": "figure", "Extraction": "{\"type\": \"figure\", \"title\": \"eFig. 30.13 Mucous membrane pemphigoid. Desquamative gingivitis can be the presenting sign of the disease. Courtesy Jeffrey P. Callen, MD.\", \"description\": \"A photograph showing desquamative gingivitis on the gums, which can be a presenting sign of mucous membrane pemphigoid.\", \"visible_labels\": [], \"data_points\": null}", "Number": "533.e3", "Part": 2},
{"Type": "figure", "Extraction": "{\"type\": \"figure\",
2025-12-14 11:25:39,015 - ERROR - Error processing PDF: 'ContentAutomationGUI' object has no attribute 'is_json_format'
Traceback (most recent call last):
  File "/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/main_gui.py", line 617, in worker
    is_json = self.is_json_format(response)
              ^^^^^^^^^^^^^^^^^^^
AttributeError: 'ContentAutomationGUI' object has no attribute 'is_json_format'
2025-12-14 11:30:10,925 - INFO - Loaded 6 predefined prompts
2025-12-14 11:30:31,043 - INFO - Loaded 3 API keys
2025-12-14 11:31:44,751 - INFO - === Starting PDF Processing ===
2025-12-14 11:31:44,752 - INFO - Model: gemini-2.5-pro
2025-12-14 11:31:44,752 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:31:44,753 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 11:31:44,826 - INFO - Processing PDF with 21 pages in batches of 10 pages
2025-12-14 11:31:44,826 - INFO - Using original prompt with JSON output instruction for batch processing (prompt preserved)
2025-12-14 11:31:56,815 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:31:56,818 - INFO - Processing batch 1/3: pages 1-10
2025-12-14 11:31:58,038 - WARNING - ⚠️ API key leaked (403) in batch processing. Will try next key in next batch.
2025-12-14 11:31:58,038 - WARNING - Batch 1 returned no results
2025-12-14 11:31:58,039 - INFO - Processing batch 2/3: pages 11-20
2025-12-14 11:31:58,320 - WARNING - ⚠️ API key leaked (403) in batch processing. Will try next key in next batch.
2025-12-14 11:31:58,320 - WARNING - Batch 2 returned no results
2025-12-14 11:31:58,321 - INFO - Processing batch 3/3: pages 21-21
2025-12-14 11:31:58,603 - WARNING - ⚠️ API key leaked (403) in batch processing. Will try next key in next batch.
2025-12-14 11:31:58,603 - WARNING - Batch 3 returned no results
2025-12-14 11:31:58,603 - ERROR - No data extracted from any batch
2025-12-14 11:35:51,250 - INFO - Loaded 6 predefined prompts
2025-12-14 11:36:12,519 - INFO - Loaded 3 API keys
2025-12-14 11:36:42,837 - INFO - === Starting PDF Processing ===
2025-12-14 11:36:42,837 - INFO - Model: gemini-2.5-pro
2025-12-14 11:36:42,838 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:36:42,838 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 11:36:53,832 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 11:36:53,832 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:36:53,833 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 11:36:53,834 - INFO - Using max_output_tokens: 32768
2025-12-14 11:36:53,835 - INFO - Using model: gemini-2.5-pro
2025-12-14 11:36:53,835 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 11:36:53,836 - INFO - Max output tokens: 32768
2025-12-14 11:36:53,836 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 11:36:53,837 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 11:36:55,080 - WARNING - ⚠️ API key leaked (403) or invalid. Attempting to switch to next key...
2025-12-14 11:36:55,080 - INFO - Retrying with API key 1/3: bagher
2025-12-14 11:37:08,312 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 11:37:08,314 - INFO - Retrying with API key 2/3: bagher
2025-12-14 11:37:18,504 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 11:37:18,505 - INFO - Retrying with API key 3/3: bagher
2025-12-14 11:37:21,031 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 11:37:21,032 - ERROR - ❌ All 3 API keys exhausted or failed. Cannot process request.
2025-12-14 11:37:47,159 - INFO - === Starting PDF Processing ===
2025-12-14 11:37:47,159 - INFO - Model: gemini-1.5-pro
2025-12-14 11:37:47,160 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:37:47,161 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 11:37:57,563 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 11:37:57,564 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:37:57,565 - INFO - Model: gemini-1.5-pro, Max tokens for model: 8192, Using: 8192
2025-12-14 11:37:57,566 - INFO - Using max_output_tokens: 8192
2025-12-14 11:37:57,566 - INFO - Using model: gemini-1.5-pro
2025-12-14 11:37:57,567 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 11:37:57,568 - INFO - Max output tokens: 8192
2025-12-14 11:37:57,569 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 11:37:57,570 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 11:37:58,968 - WARNING - Streaming not available or failed: 404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods., using non-streaming
2025-12-14 11:37:59,319 - ERROR - PDF processing failed: 404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
2025-12-14 11:38:14,861 - INFO - === Starting PDF Processing ===
2025-12-14 11:38:14,861 - INFO - Model: gemini-2.5-flash
2025-12-14 11:38:14,862 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:38:14,862 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 11:38:25,820 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 11:38:25,821 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:38:25,822 - INFO - Model: gemini-2.5-flash, Max tokens for model: 32768, Using: 32768
2025-12-14 11:38:25,823 - INFO - Using max_output_tokens: 32768
2025-12-14 11:38:25,823 - INFO - Using model: gemini-2.5-flash
2025-12-14 11:38:25,823 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 11:38:25,824 - INFO - Max output tokens: 32768
2025-12-14 11:38:25,824 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 11:38:25,825 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 11:38:27,177 - WARNING - ⚠️ API key leaked (403) or invalid. Attempting to switch to next key...
2025-12-14 11:38:27,178 - INFO - Retrying with API key 1/3: bagher
2025-12-14 11:38:39,936 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 11:38:39,937 - INFO - Retrying with API key 2/3: bagher
2025-12-14 11:38:49,832 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 11:38:49,833 - INFO - Retrying with API key 3/3: bagher
2025-12-14 11:38:52,274 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 11:38:52,275 - ERROR - ❌ All 3 API keys exhausted or failed. Cannot process request.
2025-12-14 11:44:51,738 - INFO - === Starting PDF Processing ===
2025-12-14 11:44:51,738 - INFO - Model: gemini-2.5-pro
2025-12-14 11:44:51,738 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:44:51,738 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 11:45:10,326 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 11:45:10,327 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 11:45:10,328 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 11:45:10,329 - INFO - Using max_output_tokens: 32768
2025-12-14 11:45:10,329 - INFO - Using model: gemini-2.5-pro
2025-12-14 11:45:10,330 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 11:45:10,331 - INFO - Max output tokens: 32768
2025-12-14 11:45:10,331 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 11:45:10,332 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 11:45:11,811 - WARNING - ⚠️ API key leaked (403) or invalid. Attempting to switch to next key...
2025-12-14 11:45:11,812 - INFO - Retrying with API key 1/3: bagher
2025-12-14 11:45:27,664 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 11:45:27,664 - INFO - Retrying with API key 2/3: bagher
2025-12-14 11:45:39,526 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 11:45:39,527 - INFO - Retrying with API key 3/3: bagher
2025-12-14 11:45:42,046 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 11:45:42,047 - ERROR - ❌ All 3 API keys exhausted or failed. Cannot process request.
2025-12-14 12:07:04,356 - INFO - Loaded 6 predefined prompts
2025-12-14 12:07:32,579 - INFO - Loaded 3 API keys
2025-12-14 12:08:08,442 - INFO - === Starting PDF Processing ===
2025-12-14 12:08:08,443 - INFO - Model: gemini-2.5-flash
2025-12-14 12:08:08,443 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:08:08,443 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 12:08:17,847 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 12:08:17,847 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:08:17,848 - INFO - Model: gemini-2.5-flash, Max tokens for model: 32768, Using: 32768
2025-12-14 12:08:17,848 - INFO - Using max_output_tokens: 32768
2025-12-14 12:08:17,848 - INFO - Using model: gemini-2.5-flash
2025-12-14 12:08:17,848 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 12:08:17,848 - INFO - Max output tokens: 32768
2025-12-14 12:08:17,848 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 12:08:17,848 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 12:08:18,921 - WARNING - ⚠️ API key leaked (403) or invalid. Attempting to switch to next key...
2025-12-14 12:08:18,922 - INFO - Retrying with API key 1/3: bagher
2025-12-14 12:08:30,246 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 12:08:30,247 - INFO - Retrying with API key 2/3: bagher
2025-12-14 12:08:41,299 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 12:08:41,299 - INFO - Retrying with API key 3/3: bagher
2025-12-14 12:08:43,839 - WARNING - API key bagher also leaked (403), trying next...
2025-12-14 12:08:43,839 - ERROR - ❌ All 3 API keys failed. Cannot process request.
2025-12-14 12:08:43,839 - ERROR - 
2025-12-14 12:08:43,839 - ERROR - ============================================================
2025-12-14 12:08:43,839 - ERROR - API KEY ERROR - ACTION REQUIRED
2025-12-14 12:08:43,839 - ERROR - ============================================================
2025-12-14 12:08:43,840 - ERROR - 
2025-12-14 12:08:43,840 - ERROR - Possible reasons:
2025-12-14 12:08:43,840 - ERROR -   1. All API keys were reported as LEAKED (403 error)
2025-12-14 12:08:43,840 - ERROR -      → Solution: Remove leaked keys and add new valid API keys
2025-12-14 12:08:43,840 - ERROR - 
2025-12-14 12:08:43,840 - ERROR -   2. All API keys have QUOTA EXHAUSTED (429 error)
2025-12-14 12:08:43,840 - ERROR -      → Solution: Wait for quota reset or add more API keys
2025-12-14 12:08:43,840 - ERROR - 
2025-12-14 12:08:43,840 - ERROR -   3. API keys are INVALID or EXPIRED
2025-12-14 12:08:43,840 - ERROR -      → Solution: Generate new API keys from Google AI Studio
2025-12-14 12:08:43,841 - ERROR - 
2025-12-14 12:08:43,841 - ERROR - Steps to fix:
2025-12-14 12:08:43,841 - ERROR -   1. Open your API keys CSV file
2025-12-14 12:08:43,841 - ERROR -   2. Remove any leaked/invalid keys
2025-12-14 12:08:43,841 - ERROR -   3. Add new valid API keys from: https://aistudio.google.com/apikey
2025-12-14 12:08:43,841 - ERROR -   4. Save the CSV file and reload it in the application
2025-12-14 12:08:43,841 - ERROR -   5. Try processing again
2025-12-14 12:08:43,841 - ERROR - 
2025-12-14 12:08:43,841 - ERROR - ============================================================
2025-12-14 12:16:44,946 - INFO - Loaded 6 predefined prompts
2025-12-14 12:17:09,147 - ERROR - No valid API keys found in the file
2025-12-14 12:20:20,717 - ERROR - No valid API keys found in the file
2025-12-14 12:22:56,253 - INFO - Loaded 3 API keys
2025-12-14 12:23:25,727 - INFO - === Starting PDF Processing ===
2025-12-14 12:23:25,727 - INFO - Model: gemini-2.5-flash
2025-12-14 12:23:25,727 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:23:25,727 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 12:23:41,274 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 12:23:41,274 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:23:41,274 - INFO - Model: gemini-2.5-flash, Max tokens for model: 32768, Using: 32768
2025-12-14 12:23:41,274 - INFO - Using max_output_tokens: 32768
2025-12-14 12:23:41,274 - INFO - Using model: gemini-2.5-flash
2025-12-14 12:23:41,275 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 12:23:41,275 - INFO - Max output tokens: 32768
2025-12-14 12:23:41,275 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 12:23:41,275 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 12:25:50,613 - INFO - Streaming completed: 55 chunks, 10530 characters received
2025-12-14 12:25:50,614 - INFO - Streaming finish reason: MAX_TOKENS (truncated!)
2025-12-14 12:25:50,614 - WARNING - ⚠️ Response may be truncated (finish_reason: MAX_TOKENS (truncated!))
2025-12-14 12:25:50,614 - INFO - Response received (length: 10530 characters)
2025-12-14 12:25:50,614 - WARNING - Response might be truncated - checking for finish reason
2025-12-14 12:25:51,305 - INFO - Extracted response from response.text (10530 chars)
2025-12-14 12:25:51,306 - WARNING - Code block missing closing marker - response may be truncated
2025-12-14 12:25:51,307 - INFO - PDF processed successfully with gemini-2.5-flash
2025-12-14 12:25:51,308 - INFO - Full response length: 10530 characters
2025-12-14 12:25:51,309 - INFO - Extracted from code block: 10522 characters
2025-12-14 12:25:51,310 - INFO - Response preview (first 500 chars): [
  {
    "Type": "page text",
    "Extraction": "# Page Metadata\n- Book title: VESICULOBULLOUS DISEASES SECTION 5\n- Chapter title: Pemphigoid Group 30\n- Page number: 517\n- Section headings found: Chapter Contents, BULLOUS PEMPHIGOID, Synonym: Pemphigoid, Key features, Introduction, History, Epidemiology, Pathogenesis, Humoral and cellular responses.\n\n# Body\n## Chapter Contents\nBullous Pemphigoid...............................................517\nMucous Membrane Pemphigoid..................
2025-12-14 12:25:51,310 - INFO - Response preview (last 500 chars): ...nal pemphigoid\", \"BP180/BPAG2/collagen XVII\", \"180\", \"Hemidesmosomal plaque/anchoring filaments\"], [\"Gestational pemphigoid\", \"BP230/BPAG1e\", \"230\", \"Hemidesmosomal plaque\"], [\"Mucous membrane pemphigoid\", \"BP180/BPAG2/collagen XVII\", \"180\", \"Hemidesmosomal plaque/anchoring filaments\"], [\"Mucous membrane pemphigoid\", \"BP230/BPAG1e\\u2020\", \"230\", \"Hemidesmosomal plaque\"], [\"Mucous membrane pemphigoid\", \"Laminin 332 (laminin 5; \\u03b13\\u03b23\\u03b32; epiligrin
2025-12-14 12:25:51,311 - INFO - Returning raw response from model (no JSON extraction)
2025-12-14 12:25:51,312 - INFO - ✓ CSV response appears complete (last row has delimiter)
2025-12-14 12:26:53,078 - INFO - === Response Received ===
2025-12-14 12:26:53,078 - INFO - Response length: 10522 characters
2025-12-14 12:26:53,078 - INFO - Truncated: True
2025-12-14 12:26:53,078 - INFO - Response preview (first 500 chars): [
  {
    "Type": "page text",
    "Extraction": "# Page Metadata\n- Book title: VESICULOBULLOUS DISEASES SECTION 5\n- Chapter title: Pemphigoid Group 30\n- Page number: 517\n- Section headings found: Chapter Contents, BULLOUS PEMPHIGOID, Synonym: Pemphigoid, Key features, Introduction, History, Epidemiology, Pathogenesis, Humoral and cellular responses.\n\n# Body\n## Chapter Contents\nBullous Pemphigoid...............................................517\nMucous Membrane Pemphigoid..................
2025-12-14 12:26:53,078 - INFO - Response preview (last 500 chars): ...nal pemphigoid\", \"BP180/BPAG2/collagen XVII\", \"180\", \"Hemidesmosomal plaque/anchoring filaments\"], [\"Gestational pemphigoid\", \"BP230/BPAG1e\", \"230\", \"Hemidesmosomal plaque\"], [\"Mucous membrane pemphigoid\", \"BP180/BPAG2/collagen XVII\", \"180\", \"Hemidesmosomal plaque/anchoring filaments\"], [\"Mucous membrane pemphigoid\", \"BP230/BPAG1e\\u2020\", \"230\", \"Hemidesmosomal plaque\"], [\"Mucous membrane pemphigoid\", \"Laminin 332 (laminin 5; \\u03b13\\u03b23\\u03b32; epiligrin
2025-12-14 12:26:53,467 - WARNING - python-docx not available, saving as text file
2025-12-14 12:26:53,475 - INFO - Response displayed and saved to: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46_response_20251214_122653.txt
2025-12-14 12:27:04,439 - INFO - === Starting PDF Processing ===
2025-12-14 12:27:04,439 - INFO - Model: gemini-2.5-pro
2025-12-14 12:27:04,439 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:27:04,439 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 12:27:12,570 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 12:27:12,571 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:27:12,571 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 12:27:12,571 - INFO - Using max_output_tokens: 32768
2025-12-14 12:27:12,571 - INFO - Using model: gemini-2.5-pro
2025-12-14 12:27:12,571 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 12:27:12,571 - INFO - Max output tokens: 32768
2025-12-14 12:27:12,571 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 12:27:12,571 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 12:27:13,874 - WARNING - ⚠️ Quota exhausted (429) with current API key. Attempting to switch to next key...
2025-12-14 12:27:13,874 - INFO - Retrying with API key 1/3: bagher
2025-12-14 12:27:23,573 - WARNING - API key bagher also exhausted, trying next...
2025-12-14 12:27:23,573 - INFO - Retrying with API key 2/3: bagher
2025-12-14 12:27:33,970 - WARNING - API key bagher also exhausted, trying next...
2025-12-14 12:27:33,970 - INFO - Retrying with API key 3/3: bagher
2025-12-14 12:27:36,775 - WARNING - API key bagher also exhausted, trying next...
2025-12-14 12:27:36,775 - ERROR - ❌ All 3 API keys failed. Cannot process request.
2025-12-14 12:27:36,776 - ERROR - 
2025-12-14 12:27:36,776 - ERROR - ============================================================
2025-12-14 12:27:36,776 - ERROR - API KEY ERROR - ACTION REQUIRED
2025-12-14 12:27:36,776 - ERROR - ============================================================
2025-12-14 12:27:36,776 - ERROR - 
2025-12-14 12:27:36,776 - ERROR - Possible reasons:
2025-12-14 12:27:36,776 - ERROR -   1. All API keys were reported as LEAKED (403 error)
2025-12-14 12:27:36,776 - ERROR -      → Solution: Remove leaked keys and add new valid API keys
2025-12-14 12:27:36,776 - ERROR - 
2025-12-14 12:27:36,776 - ERROR -   2. All API keys have QUOTA EXHAUSTED (429 error)
2025-12-14 12:27:36,776 - ERROR -      → Solution: Wait for quota reset or add more API keys
2025-12-14 12:27:36,777 - ERROR - 
2025-12-14 12:27:36,778 - ERROR -   3. API keys are INVALID or EXPIRED
2025-12-14 12:27:36,778 - ERROR -      → Solution: Generate new API keys from Google AI Studio
2025-12-14 12:27:36,778 - ERROR - 
2025-12-14 12:27:36,778 - ERROR - Steps to fix:
2025-12-14 12:27:36,779 - ERROR -   1. Open your API keys CSV file
2025-12-14 12:27:36,779 - ERROR -   2. Remove any leaked/invalid keys
2025-12-14 12:27:36,779 - ERROR -   3. Add new valid API keys from: https://aistudio.google.com/apikey
2025-12-14 12:27:36,779 - ERROR -   4. Save the CSV file and reload it in the application
2025-12-14 12:27:36,779 - ERROR -   5. Try processing again
2025-12-14 12:27:36,779 - ERROR - 
2025-12-14 12:27:36,779 - ERROR - ============================================================
2025-12-14 12:33:16,988 - INFO - Loaded 6 predefined prompts
2025-12-14 12:33:46,312 - ERROR - No valid API keys found in the file
2025-12-14 12:33:54,448 - INFO - Loaded 3 API keys
2025-12-14 12:34:26,344 - INFO - === Starting PDF Processing ===
2025-12-14 12:34:26,345 - INFO - Model: gemini-2.5-pro
2025-12-14 12:34:26,345 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:34:26,345 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 12:34:34,686 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 12:34:34,687 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:34:34,687 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 12:34:34,687 - INFO - Using max_output_tokens: 32768
2025-12-14 12:34:34,687 - INFO - Using model: gemini-2.5-pro
2025-12-14 12:34:34,687 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 12:34:34,687 - INFO - Max output tokens: 32768
2025-12-14 12:34:34,687 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 12:34:34,687 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 12:34:35,967 - WARNING - ⚠️ Quota exhausted (429) with current API key. Attempting to switch to next key...
2025-12-14 12:34:35,967 - INFO - Retrying with API key 1/3: bagher
2025-12-14 12:34:44,918 - WARNING - API key bagher also exhausted, trying next...
2025-12-14 12:34:44,918 - INFO - Retrying with API key 2/3: bagher
2025-12-14 12:34:54,747 - WARNING - API key bagher also exhausted, trying next...
2025-12-14 12:34:54,747 - INFO - Retrying with API key 3/3: bagher
2025-12-14 12:34:57,112 - WARNING - API key bagher also exhausted, trying next...
2025-12-14 12:34:57,113 - ERROR - ======================================================================
2025-12-14 12:34:57,113 - ERROR - ❌ All 3 API keys failed. Cannot process request.
2025-12-14 12:34:57,113 - ERROR - ======================================================================
2025-12-14 12:34:57,113 - ERROR - 
2025-12-14 12:34:57,113 - ERROR - Possible reasons:
2025-12-14 12:34:57,113 - ERROR -   • All keys LEAKED (403) → Remove leaked keys, add new ones
2025-12-14 12:34:57,113 - ERROR -   • All keys QUOTA EXHAUSTED (429) → Wait for reset or add more keys
2025-12-14 12:34:57,114 - ERROR -   • Keys INVALID/EXPIRED → Generate new keys from Google AI Studio
2025-12-14 12:34:57,114 - ERROR - 
2025-12-14 12:34:57,114 - ERROR - Quick fix:
2025-12-14 12:34:57,114 - ERROR -   1. Open API keys CSV file
2025-12-14 12:34:57,114 - ERROR -   2. Remove leaked/invalid keys
2025-12-14 12:34:57,115 - ERROR -   3. Add new keys from: https://aistudio.google.com/apikey
2025-12-14 12:34:57,115 - ERROR -   4. Save CSV and reload in application
2025-12-14 12:34:57,115 - ERROR -   5. Try again
2025-12-14 12:34:57,115 - ERROR - 
2025-12-14 12:34:57,115 - ERROR - ======================================================================
2025-12-14 12:40:08,769 - ERROR - No valid API keys found in the file
2025-12-14 12:41:25,220 - INFO - Loaded 2 API keys
2025-12-14 12:41:30,767 - INFO - === Starting PDF Processing ===
2025-12-14 12:41:30,768 - INFO - Model: gemini-2.5-pro
2025-12-14 12:41:30,768 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:41:30,768 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 12:41:30,769 - ERROR - PDF processing failed: list index out of range
2025-12-14 12:41:36,830 - INFO - === Starting PDF Processing ===
2025-12-14 12:41:36,830 - INFO - Model: gemini-2.5-pro
2025-12-14 12:41:36,830 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:41:36,831 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 12:41:36,834 - ERROR - PDF processing failed: list index out of range
2025-12-14 12:44:37,537 - INFO - === Starting PDF Processing ===
2025-12-14 12:44:37,538 - INFO - Model: gemini-2.5-pro
2025-12-14 12:44:37,538 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:44:37,538 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 12:44:37,539 - ERROR - PDF processing failed: list index out of range
2025-12-14 12:44:54,735 - INFO - Loaded 6 predefined prompts
2025-12-14 12:45:27,000 - INFO - Loaded 2 API keys
2025-12-14 12:46:04,053 - INFO - === Starting PDF Processing ===
2025-12-14 12:46:04,055 - INFO - Model: gemini-2.5-pro
2025-12-14 12:46:04,056 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:46:04,058 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 12:46:06,487 - ERROR - PDF processing failed: <HttpError 400 when requesting None returned "API key expired. Please renew the API key.". Details: "[{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key expired. Please renew the API key.'}]">
2025-12-14 12:55:16,748 - INFO - Loaded 3 API keys
2025-12-14 12:55:21,157 - INFO - === Starting PDF Processing ===
2025-12-14 12:55:21,157 - INFO - Model: gemini-2.5-pro
2025-12-14 12:55:21,158 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:55:21,159 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 12:55:30,461 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 12:55:30,461 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 12:55:30,462 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 12:55:30,462 - INFO - Using max_output_tokens: 32768
2025-12-14 12:55:30,462 - INFO - Using model: gemini-2.5-pro
2025-12-14 12:55:30,462 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 12:55:30,462 - INFO - Max output tokens: 32768
2025-12-14 12:55:30,462 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 12:55:30,463 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 12:55:31,874 - WARNING - ⚠️ Quota exhausted (429) with current API key. Attempting to switch to next key...
2025-12-14 12:55:31,875 - INFO - Retrying with API key 1/3: bagher
2025-12-14 12:55:43,946 - WARNING - API key bagher also exhausted, trying next...
2025-12-14 12:55:43,946 - INFO - Retrying with API key 2/3: bagher
2025-12-14 12:55:54,049 - WARNING - API key bagher also exhausted, trying next...
2025-12-14 12:55:54,049 - INFO - Retrying with API key 3/3: bagher
2025-12-14 12:55:56,560 - WARNING - API key bagher also exhausted, trying next...
2025-12-14 12:55:56,560 - ERROR - ======================================================================
2025-12-14 12:55:56,561 - ERROR - ❌ All 3 API keys failed. Cannot process request.
2025-12-14 12:55:56,562 - ERROR - ======================================================================
2025-12-14 12:55:56,563 - ERROR - 
2025-12-14 12:55:56,563 - ERROR - Possible reasons:
2025-12-14 12:55:56,564 - ERROR -   • All keys LEAKED (403) → Remove leaked keys, add new ones
2025-12-14 12:55:56,565 - ERROR -   • All keys QUOTA EXHAUSTED (429) → Wait for reset or add more keys
2025-12-14 12:55:56,565 - ERROR -   • Keys INVALID/EXPIRED → Generate new keys from Google AI Studio
2025-12-14 12:55:56,566 - ERROR - 
2025-12-14 12:55:56,566 - ERROR - Quick fix:
2025-12-14 12:55:56,567 - ERROR -   1. Open API keys CSV file
2025-12-14 12:55:56,567 - ERROR -   2. Remove leaked/invalid keys
2025-12-14 12:55:56,568 - ERROR -   3. Add new keys from: https://aistudio.google.com/apikey
2025-12-14 12:55:56,568 - ERROR -   4. Save CSV and reload in application
2025-12-14 12:55:56,569 - ERROR -   5. Try again
2025-12-14 12:55:56,569 - ERROR - 
2025-12-14 12:55:56,570 - ERROR - ======================================================================
2025-12-14 13:00:54,153 - INFO - === Starting PDF Processing ===
2025-12-14 13:00:54,154 - INFO - Model: gemini-2.5-pro
2025-12-14 13:00:54,154 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:00:54,154 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 13:01:03,493 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 13:01:03,493 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:01:03,494 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 13:01:03,495 - INFO - Using max_output_tokens: 32768
2025-12-14 13:01:03,495 - INFO - Using model: gemini-2.5-pro
2025-12-14 13:01:03,496 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 13:01:03,496 - INFO - Max output tokens: 32768
2025-12-14 13:01:03,497 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 13:01:03,497 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 13:01:04,769 - WARNING - ⚠️ Quota exhausted (429) with current API key. Attempting to switch to next key...
2025-12-14 13:01:04,769 - INFO - Retrying with API key 1/3: bagher
2025-12-14 13:01:15,802 - INFO - Loaded 6 predefined prompts
2025-12-14 13:01:36,438 - INFO - Loaded 3 API keys
2025-12-14 13:02:28,319 - INFO - === Starting PDF Processing ===
2025-12-14 13:02:28,320 - INFO - Model: gemini-2.5-pro
2025-12-14 13:02:28,321 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:02:28,322 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 13:02:37,973 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 13:02:37,974 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:02:37,974 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 13:02:37,974 - INFO - Using max_output_tokens: 32768
2025-12-14 13:02:37,975 - INFO - Using model: gemini-2.5-pro
2025-12-14 13:02:37,975 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 13:02:37,975 - INFO - Max output tokens: 32768
2025-12-14 13:02:37,975 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 13:02:37,975 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 13:02:39,357 - WARNING - ⚠️ Quota exhausted (429) with current API key. Attempting to switch to next key...
2025-12-14 13:02:39,358 - INFO - Retrying with API key 1/3: bagher
2025-12-14 13:02:51,135 - WARNING - API key bagher also exhausted, trying next...
2025-12-14 13:02:51,135 - INFO - Retrying with API key 2/3: bagher
2025-12-14 13:03:00,808 - WARNING - API key bagher also exhausted, trying next...
2025-12-14 13:03:00,809 - INFO - Retrying with API key 3/3: bagher
2025-12-14 13:03:03,413 - WARNING - API key bagher also exhausted, trying next...
2025-12-14 13:03:03,414 - ERROR - ======================================================================
2025-12-14 13:03:03,414 - ERROR - ❌ All 3 API keys failed. Cannot process request.
2025-12-14 13:03:03,415 - ERROR - ======================================================================
2025-12-14 13:03:03,416 - ERROR - 
2025-12-14 13:03:03,416 - ERROR - Possible reasons:
2025-12-14 13:03:03,417 - ERROR -   • All keys LEAKED (403) → Remove leaked keys, add new ones
2025-12-14 13:03:03,417 - ERROR -   • All keys QUOTA EXHAUSTED (429) → Wait for reset or add more keys
2025-12-14 13:03:03,417 - ERROR -   • Keys INVALID/EXPIRED → Generate new keys from Google AI Studio
2025-12-14 13:03:03,418 - ERROR - 
2025-12-14 13:03:03,418 - ERROR - Quick fix:
2025-12-14 13:03:03,419 - ERROR -   1. Open API keys CSV file
2025-12-14 13:03:03,419 - ERROR -   2. Remove leaked/invalid keys
2025-12-14 13:03:03,420 - ERROR -   3. Add new keys from: https://aistudio.google.com/apikey
2025-12-14 13:03:03,420 - ERROR -   4. Save CSV and reload in application
2025-12-14 13:03:03,420 - ERROR -   5. Try again
2025-12-14 13:03:03,421 - ERROR - 
2025-12-14 13:03:03,421 - ERROR - ======================================================================
2025-12-14 13:06:52,100 - INFO - Loaded 6 predefined prompts
2025-12-14 13:07:15,040 - INFO - Loaded 3 API keys
2025-12-14 13:07:46,149 - INFO - === Starting PDF Processing ===
2025-12-14 13:07:46,149 - INFO - Model: gemini-2.5-pro
2025-12-14 13:07:46,149 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:07:46,150 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 13:07:56,128 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 13:07:56,129 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:07:56,130 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 13:07:56,131 - INFO - Using max_output_tokens: 32768
2025-12-14 13:07:56,131 - INFO - Using model: gemini-2.5-pro
2025-12-14 13:07:56,132 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 13:07:56,132 - INFO - Max output tokens: 32768
2025-12-14 13:07:56,133 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 13:07:56,133 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 13:07:57,420 - WARNING - ⚠️ Rate limit hit (429). Waiting 5.0s before retry 1/3...
2025-12-14 13:07:57,420 - WARNING -    Error: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:08:02,738 - WARNING - ⚠️ Rate limit hit (429). Waiting 10.0s before retry 2/3...
2025-12-14 13:08:02,739 - WARNING -    Error: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:08:13,057 - WARNING - ⚠️ Quota exhausted (429) with current API key. Attempting to switch to next key...
2025-12-14 13:08:13,058 - INFO - Retrying with API key 1/3: bagher
2025-12-14 13:08:22,889 - WARNING - ⚠️ Rate limit hit (429). Waiting 3.0s before retry 1/2...
2025-12-14 13:08:22,890 - WARNING -    Error: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:08:26,192 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 13:08:26,195 - INFO - Retrying with API key 2/3: bagher
2025-12-14 13:08:37,997 - WARNING - ⚠️ Rate limit hit (429). Waiting 3.0s before retry 1/2...
2025-12-14 13:08:37,997 - WARNING -    Error: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:08:41,321 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 13:08:41,321 - INFO - Retrying with API key 3/3: bagher
2025-12-14 13:08:44,029 - WARNING - ⚠️ Rate limit hit (429). Waiting 3.0s before retry 1/2...
2025-12-14 13:08:44,029 - WARNING -    Error: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:08:47,339 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 13:08:47,339 - ERROR - ======================================================================
2025-12-14 13:08:47,339 - ERROR - ❌ All 3 API keys failed. Cannot process request.
2025-12-14 13:08:47,340 - ERROR - ======================================================================
2025-12-14 13:08:47,340 - ERROR - 
2025-12-14 13:08:47,340 - ERROR - Possible reasons:
2025-12-14 13:08:47,340 - ERROR -   • All keys LEAKED (403) → Remove leaked keys, add new ones
2025-12-14 13:08:47,340 - ERROR -   • All keys QUOTA EXHAUSTED (429) → Wait for reset or add more keys
2025-12-14 13:08:47,340 - ERROR -   • Keys INVALID/EXPIRED → Generate new keys from Google AI Studio
2025-12-14 13:08:47,340 - ERROR - 
2025-12-14 13:08:47,340 - ERROR - Quick fix:
2025-12-14 13:08:47,340 - ERROR -   1. Open API keys CSV file
2025-12-14 13:08:47,340 - ERROR -   2. Remove leaked/invalid keys
2025-12-14 13:08:47,341 - ERROR -   3. Add new keys from: https://aistudio.google.com/apikey
2025-12-14 13:08:47,341 - ERROR -   4. Save CSV and reload in application
2025-12-14 13:08:47,341 - ERROR -   5. Try again
2025-12-14 13:08:47,341 - ERROR - 
2025-12-14 13:08:47,341 - ERROR - ======================================================================
2025-12-14 13:18:03,826 - INFO - Loaded 6 predefined prompts
2025-12-14 13:18:38,341 - INFO - Loaded 3 API keys
2025-12-14 13:21:20,607 - INFO - === Starting PDF Processing ===
2025-12-14 13:21:20,607 - INFO - Model: gemini-2.5-flash
2025-12-14 13:21:20,607 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:21:20,608 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 13:21:32,507 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 13:21:32,508 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:21:32,510 - INFO - Model: gemini-2.5-flash, Max tokens for model: 32768, Using: 32768
2025-12-14 13:21:32,512 - INFO - Using max_output_tokens: 32768
2025-12-14 13:21:32,513 - INFO - Using model: gemini-2.5-flash
2025-12-14 13:21:32,513 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 13:21:32,514 - INFO - Max output tokens: 32768
2025-12-14 13:21:32,514 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 13:21:32,515 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 13:23:40,228 - INFO - Streaming completed: 115473 characters received
2025-12-14 13:23:40,229 - INFO - Streaming finish reason: MAX_TOKENS (truncated!)
2025-12-14 13:23:40,229 - WARNING - ⚠️ Response may be truncated (finish_reason: MAX_TOKENS (truncated!))
2025-12-14 13:23:40,230 - INFO - Response received (length: 115473 characters)
2025-12-14 13:23:40,231 - WARNING - Response might be truncated - checking for finish reason
2025-12-14 13:23:40,967 - INFO - Extracted response from response.text (115473 chars)
2025-12-14 13:23:40,968 - INFO - Extracted content from generic code block
2025-12-14 13:23:40,968 - INFO - PDF processed successfully with gemini-2.5-flash
2025-12-14 13:23:40,969 - INFO - Full response length: 115473 characters
2025-12-14 13:23:40,969 - INFO - Extracted from code block: 8369 characters
2025-12-14 13:23:40,970 - INFO - Response preview (first 500 chars): [
  {
    "Type": "page text",
    "Extraction": "# Page Metadata\n- Book title: VESICULOBULLOUS DISEASES SECTION 5\n- Chapter title: Pemphigoid Group\n- Page number: 517\n- Section headings: Chapter Contents, BULLOUS PEMPHIGOID, Synonym: Pemphigoid, Key features, Introduction, History, Epidemiology, Pathogenesis, Humoral and cellular responses\n# Body\nVESICULOBULLOUS DISEASES SECTION 5\nPemphigoid Group 30\nLuca Borradori and Michael Hertl\n## Chapter Contents\nBullous Pemphigoid.................
2025-12-14 13:23:40,971 - INFO - Response preview (last 500 chars): ... The latter serve to further amplify the inflammatory response$^{5,11-16}$ while the proteinases, together with reactive oxygen species, degrade various extracellular matrix proteins as well as BP180$^{11-16}$. IgG anti-BP180 autoantibodies can also boost the inflammatory response by stimulating keratinocytes to express inflammatory cytokines (Fig. 30.1)$^{11}$. Furthermore, IgG autoantibodies are able to directly impair dermal-epidermal adhesion without complement activation$^{11}$.\n# Tables\n
2025-12-14 13:23:40,971 - INFO - Returning raw response from model (no JSON extraction)
2025-12-14 13:23:40,972 - INFO - ✓ CSV response appears complete (last row has delimiter)
2025-12-14 13:24:06,379 - INFO - === Response Received ===
2025-12-14 13:24:06,381 - INFO - Response length: 8369 characters
2025-12-14 13:24:06,382 - INFO - Truncated: True
2025-12-14 13:24:06,383 - INFO - Response preview (first 500 chars): [
  {
    "Type": "page text",
    "Extraction": "# Page Metadata\n- Book title: VESICULOBULLOUS DISEASES SECTION 5\n- Chapter title: Pemphigoid Group\n- Page number: 517\n- Section headings: Chapter Contents, BULLOUS PEMPHIGOID, Synonym: Pemphigoid, Key features, Introduction, History, Epidemiology, Pathogenesis, Humoral and cellular responses\n# Body\nVESICULOBULLOUS DISEASES SECTION 5\nPemphigoid Group 30\nLuca Borradori and Michael Hertl\n## Chapter Contents\nBullous Pemphigoid.................
2025-12-14 13:24:06,383 - INFO - Response preview (last 500 chars): ... The latter serve to further amplify the inflammatory response$^{5,11-16}$ while the proteinases, together with reactive oxygen species, degrade various extracellular matrix proteins as well as BP180$^{11-16}$. IgG anti-BP180 autoantibodies can also boost the inflammatory response by stimulating keratinocytes to express inflammatory cytokines (Fig. 30.1)$^{11}$. Furthermore, IgG autoantibodies are able to directly impair dermal-epidermal adhesion without complement activation$^{11}$.\n# Tables\n
2025-12-14 13:24:06,902 - WARNING - python-docx not available, saving as text file
2025-12-14 13:24:06,909 - INFO - Response displayed and saved to: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46_response_20251214_132406.txt
2025-12-14 13:25:14,369 - INFO - === Starting PDF Processing ===
2025-12-14 13:25:14,369 - INFO - Model: gemini-1.5-pro
2025-12-14 13:25:14,369 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:25:14,369 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 13:25:25,662 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 13:25:25,662 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:25:25,663 - INFO - Model: gemini-1.5-pro, Max tokens for model: 8192, Using: 8192
2025-12-14 13:25:25,664 - INFO - Using max_output_tokens: 8192
2025-12-14 13:25:25,664 - INFO - Using model: gemini-1.5-pro
2025-12-14 13:25:25,664 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 13:25:25,665 - INFO - Max output tokens: 8192
2025-12-14 13:25:25,665 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 13:25:25,666 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 13:25:27,020 - WARNING - Streaming not available or failed: 404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods., using non-streaming
2025-12-14 13:25:27,308 - ERROR - PDF processing failed: 404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
2025-12-14 13:25:34,808 - INFO - === Starting PDF Processing ===
2025-12-14 13:25:34,809 - INFO - Model: gemini-2.5-pro
2025-12-14 13:25:34,810 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:25:34,810 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 13:25:45,222 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 13:25:45,222 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:25:45,227 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 13:25:45,228 - INFO - Using max_output_tokens: 32768
2025-12-14 13:25:45,228 - INFO - Using model: gemini-2.5-pro
2025-12-14 13:25:45,229 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 13:25:45,230 - INFO - Max output tokens: 32768
2025-12-14 13:25:45,230 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 13:25:45,231 - INFO - Generating content with streaming enabled for complete response...
2025-12-14 13:25:46,582 - WARNING - ⚠️ Rate limit hit (429). Waiting 5.0s before retry 1/3...
2025-12-14 13:25:46,583 - WARNING -    Error: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:25:51,894 - WARNING - ⚠️ Rate limit hit (429). Waiting 10.0s before retry 2/3...
2025-12-14 13:25:51,894 - WARNING -    Error: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:26:02,232 - WARNING - ⚠️ Quota exhausted (429) with current API key. Attempting to switch to next key...
2025-12-14 13:26:02,233 - INFO - Retrying with API key 1/3: bagher
2025-12-14 13:26:11,484 - WARNING - ⚠️ Rate limit hit (429). Waiting 3.0s before retry 1/2...
2025-12-14 13:26:11,484 - WARNING -    Error: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:26:14,799 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 13:26:14,800 - INFO - Retrying with API key 2/3: bagher
2025-12-14 13:26:28,245 - WARNING - ⚠️ Rate limit hit (429). Waiting 3.0s before retry 1/2...
2025-12-14 13:26:28,245 - WARNING -    Error: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:26:31,555 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 13:26:31,556 - INFO - Retrying with API key 3/3: bagher
2025-12-14 13:26:34,424 - WARNING - ⚠️ Rate limit hit (429). Waiting 3.0s before retry 1/2...
2025-12-14 13:26:34,424 - WARNING -    Error: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:26:37,723 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 13:26:37,724 - ERROR - ======================================================================
2025-12-14 13:26:37,725 - ERROR - ❌ All 3 API keys failed. Cannot process request.
2025-12-14 13:26:37,725 - ERROR - ======================================================================
2025-12-14 13:26:37,726 - ERROR - 
2025-12-14 13:26:37,726 - ERROR - Possible reasons:
2025-12-14 13:26:37,726 - ERROR -   • All keys LEAKED (403) → Remove leaked keys, add new ones
2025-12-14 13:26:37,727 - ERROR -   • All keys QUOTA EXHAUSTED (429) → Wait for reset or add more keys
2025-12-14 13:26:37,727 - ERROR -   • Keys INVALID/EXPIRED → Generate new keys from Google AI Studio
2025-12-14 13:26:37,728 - ERROR - 
2025-12-14 13:26:37,728 - ERROR - Quick fix:
2025-12-14 13:26:37,729 - ERROR -   1. Open API keys CSV file
2025-12-14 13:26:37,729 - ERROR -   2. Remove leaked/invalid keys
2025-12-14 13:26:37,730 - ERROR -   3. Add new keys from: https://aistudio.google.com/apikey
2025-12-14 13:26:37,730 - ERROR -   4. Save CSV and reload in application
2025-12-14 13:26:37,731 - ERROR -   5. Try again
2025-12-14 13:26:37,731 - ERROR - 
2025-12-14 13:26:37,732 - ERROR - ======================================================================
2025-12-14 13:38:14,394 - INFO - Loaded 6 predefined prompts
2025-12-14 13:38:35,037 - INFO - Loaded 3 API keys
2025-12-14 13:39:15,040 - INFO - === Starting PDF Processing ===
2025-12-14 13:39:15,040 - INFO - Model: gemini-2.5-pro
2025-12-14 13:39:15,040 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:39:15,040 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 13:39:24,835 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 13:39:24,836 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:39:24,837 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 13:39:24,838 - INFO - Using max_output_tokens: 32768
2025-12-14 13:39:24,840 - INFO - Using model: gemini-2.5-pro
2025-12-14 13:39:24,841 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 13:39:24,842 - INFO - Max output tokens: 32768
2025-12-14 13:39:24,843 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 13:39:24,844 - INFO - Streaming disabled for large request (prompt: 7731 chars, max_tokens: 32768)
2025-12-14 13:39:24,846 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-14 13:39:31,150 - WARNING - ⚠️ Rate limit hit (429) - Attempt 1/3
2025-12-14 13:39:31,150 - WARNING -    Waiting 60.0s before retry... (Error count: 1/5)
2025-12-14 13:39:31,150 - WARNING -    Error: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:40:31,523 - WARNING - ⚠️ Rate limit hit (429) - Attempt 2/3
2025-12-14 13:40:31,523 - WARNING -    Waiting 90.0s before retry... (Error count: 2/5)
2025-12-14 13:40:31,523 - WARNING -    Error: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:42:01,875 - ERROR - ⚠️ Rate limit (429) persisted after all backoff retries. Attempting to switch to next key...
2025-12-14 13:42:31,876 - INFO - Retrying with API key 1/3: bagher
2025-12-14 13:42:42,230 - INFO - Streaming disabled for large request (prompt: 7731 chars, max_tokens: 32768)
2025-12-14 13:42:43,468 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 13:42:43,468 - INFO - Retrying with API key 2/3: bagher
2025-12-14 13:42:52,224 - INFO - Streaming disabled for large request (prompt: 7731 chars, max_tokens: 32768)
2025-12-14 13:42:52,224 - INFO - Waiting 30s before trying key 2...
2025-12-14 13:43:23,465 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 13:43:23,466 - INFO - Retrying with API key 3/3: bagher
2025-12-14 13:43:24,630 - INFO - Streaming disabled for large request (prompt: 7731 chars, max_tokens: 32768)
2025-12-14 13:43:24,630 - INFO - Waiting 45s before trying key 3...
2025-12-14 13:44:10,912 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 13:44:10,912 - ERROR - ======================================================================
2025-12-14 13:44:10,913 - ERROR - ❌ All 3 API keys failed. Cannot process request.
2025-12-14 13:44:10,914 - ERROR - ======================================================================
2025-12-14 13:44:10,914 - ERROR - 
2025-12-14 13:44:10,915 - ERROR - Possible reasons:
2025-12-14 13:44:10,915 - ERROR -   • All keys LEAKED (403) → Remove leaked keys, add new ones
2025-12-14 13:44:10,916 - ERROR -   • All keys QUOTA EXHAUSTED (429) → Wait for reset or add more keys
2025-12-14 13:44:10,917 - ERROR -   • Keys INVALID/EXPIRED → Generate new keys from Google AI Studio
2025-12-14 13:44:10,917 - ERROR - 
2025-12-14 13:44:10,918 - ERROR - Quick fix:
2025-12-14 13:44:10,918 - ERROR -   1. Open API keys CSV file
2025-12-14 13:44:10,919 - ERROR -   2. Remove leaked/invalid keys
2025-12-14 13:44:10,919 - ERROR -   3. Add new keys from: https://aistudio.google.com/apikey
2025-12-14 13:44:10,920 - ERROR -   4. Save CSV and reload in application
2025-12-14 13:44:10,920 - ERROR -   5. Try again
2025-12-14 13:44:10,921 - ERROR - 
2025-12-14 13:44:10,921 - ERROR - ======================================================================
2025-12-14 13:53:26,832 - INFO - Loaded 6 predefined prompts
2025-12-14 13:53:50,402 - INFO - Loaded 3 API keys
2025-12-14 13:55:00,824 - INFO - === Starting PDF Processing ===
2025-12-14 13:55:00,824 - INFO - Model: gemini-2.5-pro
2025-12-14 13:55:00,824 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:55:00,825 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 13:55:22,835 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 13:55:22,836 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 13:55:22,837 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 13:55:22,839 - INFO - Using max_output_tokens: 32768
2025-12-14 13:55:22,840 - INFO - Using model: gemini-2.5-pro
2025-12-14 13:55:22,841 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 13:55:22,841 - INFO - Max output tokens: 32768
2025-12-14 13:55:22,842 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 13:55:22,842 - INFO - Streaming disabled for large request (prompt: 7731 chars, max_tokens: 32768)
2025-12-14 13:55:22,843 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-14 13:55:26,837 - ERROR - ================================================================================
2025-12-14 13:55:26,837 - ERROR - 🔴 RATE LIMIT ERROR (429) - COMPLETE DETAILS
2025-12-14 13:55:26,837 - ERROR - ================================================================================
2025-12-14 13:55:26,837 - ERROR - Error Type: ResourceExhausted
2025-12-14 13:55:26,837 - ERROR - Status Code: 429
2025-12-14 13:55:26,837 - ERROR - Error Message: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:55:26,837 - ERROR - 
2025-12-14 13:55:26,838 - ERROR - 📊 CONCURRENCY INFORMATION:
2025-12-14 13:55:26,838 - ERROR -   Process ID (PID): 84566
2025-12-14 13:55:26,838 - ERROR -   Process Name: run.py
2025-12-14 13:55:26,838 - ERROR -   Thread ID: 124824265094720
2025-12-14 13:55:26,838 - ERROR -   Thread Name: Thread-1 (worker)
2025-12-14 13:55:26,838 - ERROR -   Worker ID: 124824413722432
2025-12-14 13:55:26,839 - ERROR - 
2025-12-14 13:55:26,839 - ERROR - 🔍 FULL ERROR REPRESENTATION:
2025-12-14 13:55:26,839 - ERROR -   ResourceExhausted('Resource has been exhausted (e.g. check quota).')
2025-12-14 13:55:26,839 - ERROR - ================================================================================
2025-12-14 13:55:26,840 - WARNING - ⚠️ Rate limit hit (429) - Attempt 1/3
2025-12-14 13:55:26,840 - WARNING -    Waiting 60.0s before retry... (Error count: 1/5)
2025-12-14 13:56:28,736 - ERROR - ================================================================================
2025-12-14 13:56:28,737 - ERROR - 🔴 RATE LIMIT ERROR (429) - COMPLETE DETAILS
2025-12-14 13:56:28,741 - ERROR - ================================================================================
2025-12-14 13:56:28,741 - ERROR - Error Type: ResourceExhausted
2025-12-14 13:56:28,742 - ERROR - Status Code: 429
2025-12-14 13:56:28,742 - ERROR - Error Message: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:56:28,743 - ERROR - 
2025-12-14 13:56:28,743 - ERROR - 📊 CONCURRENCY INFORMATION:
2025-12-14 13:56:28,744 - ERROR -   Process ID (PID): 84566
2025-12-14 13:56:28,744 - ERROR -   Process Name: run.py
2025-12-14 13:56:28,745 - ERROR -   Thread ID: 124824265094720
2025-12-14 13:56:28,746 - ERROR -   Thread Name: Thread-1 (worker)
2025-12-14 13:56:28,746 - ERROR -   Worker ID: 124824413722432
2025-12-14 13:56:28,747 - ERROR - 
2025-12-14 13:56:28,748 - ERROR - 🔍 FULL ERROR REPRESENTATION:
2025-12-14 13:56:28,749 - ERROR -   ResourceExhausted('Resource has been exhausted (e.g. check quota).')
2025-12-14 13:56:28,749 - ERROR - ================================================================================
2025-12-14 13:56:28,750 - WARNING - ⚠️ Rate limit hit (429) - Attempt 2/3
2025-12-14 13:56:28,751 - WARNING -    Waiting 90.0s before retry... (Error count: 2/5)
2025-12-14 13:57:59,104 - ERROR - ================================================================================
2025-12-14 13:57:59,104 - ERROR - 🔴 RATE LIMIT ERROR (429) - COMPLETE DETAILS
2025-12-14 13:57:59,104 - ERROR - ================================================================================
2025-12-14 13:57:59,105 - ERROR - Error Type: ResourceExhausted
2025-12-14 13:57:59,105 - ERROR - Status Code: 429
2025-12-14 13:57:59,105 - ERROR - Error Message: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:57:59,105 - ERROR - 
2025-12-14 13:57:59,105 - ERROR - 📊 CONCURRENCY INFORMATION:
2025-12-14 13:57:59,105 - ERROR -   Process ID (PID): 84566
2025-12-14 13:57:59,105 - ERROR -   Process Name: run.py
2025-12-14 13:57:59,105 - ERROR -   Thread ID: 124824265094720
2025-12-14 13:57:59,105 - ERROR -   Thread Name: Thread-1 (worker)
2025-12-14 13:57:59,105 - ERROR -   Worker ID: 124824413722432
2025-12-14 13:57:59,105 - ERROR - 
2025-12-14 13:57:59,105 - ERROR - 🔍 FULL ERROR REPRESENTATION:
2025-12-14 13:57:59,105 - ERROR -   ResourceExhausted('Resource has been exhausted (e.g. check quota).')
2025-12-14 13:57:59,106 - ERROR - ================================================================================
2025-12-14 13:57:59,106 - ERROR - ================================================================================
2025-12-14 13:57:59,106 - ERROR - 🔴 API ERROR - COMPLETE DETAILS
2025-12-14 13:57:59,106 - ERROR - ================================================================================
2025-12-14 13:57:59,106 - ERROR - Error Type: ResourceExhausted
2025-12-14 13:57:59,109 - ERROR - Status Code: 429
2025-12-14 13:57:59,111 - ERROR - Error Message: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 13:57:59,111 - ERROR - 
2025-12-14 13:57:59,111 - ERROR - 📊 CONCURRENCY INFORMATION:
2025-12-14 13:57:59,111 - ERROR -   Process ID (PID): 84566
2025-12-14 13:57:59,111 - ERROR -   Process Name: run.py
2025-12-14 13:57:59,113 - ERROR -   Thread ID: 124824265094720
2025-12-14 13:57:59,114 - ERROR -   Thread Name: Thread-1 (worker)
2025-12-14 13:57:59,114 - ERROR -   Worker ID: 124824413722432
2025-12-14 13:57:59,114 - ERROR - ================================================================================
2025-12-14 13:57:59,115 - ERROR - ⚠️ Rate limit (429) persisted after all backoff retries. Attempting to switch to next key...
2025-12-14 13:58:29,115 - INFO - Retrying with API key 1/3: bagher
2025-12-14 13:58:40,349 - INFO - Streaming disabled for large request (prompt: 7731 chars, max_tokens: 32768)
2025-12-14 13:58:41,632 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 13:58:41,633 - INFO - Retrying with API key 2/3: bagher
2025-12-14 13:58:51,440 - INFO - Streaming disabled for large request (prompt: 7731 chars, max_tokens: 32768)
2025-12-14 13:58:51,440 - INFO - Waiting 30s before trying key 2...
2025-12-14 13:59:22,857 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 13:59:22,858 - INFO - Retrying with API key 3/3: bagher
2025-12-14 13:59:24,287 - INFO - Streaming disabled for large request (prompt: 7731 chars, max_tokens: 32768)
2025-12-14 13:59:24,287 - INFO - Waiting 45s before trying key 3...
2025-12-14 14:00:10,804 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 14:00:10,805 - ERROR - ======================================================================
2025-12-14 14:00:10,805 - ERROR - ❌ All 3 API keys failed. Cannot process request.
2025-12-14 14:00:10,806 - ERROR - ======================================================================
2025-12-14 14:00:10,806 - ERROR - 
2025-12-14 14:00:10,807 - ERROR - Possible reasons:
2025-12-14 14:00:10,807 - ERROR -   • All keys LEAKED (403) → Remove leaked keys, add new ones
2025-12-14 14:00:10,808 - ERROR -   • All keys QUOTA EXHAUSTED (429) → Wait for reset or add more keys
2025-12-14 14:00:10,808 - ERROR -   • Keys INVALID/EXPIRED → Generate new keys from Google AI Studio
2025-12-14 14:00:10,809 - ERROR - 
2025-12-14 14:00:10,809 - ERROR - Quick fix:
2025-12-14 14:00:10,809 - ERROR -   1. Open API keys CSV file
2025-12-14 14:00:10,810 - ERROR -   2. Remove leaked/invalid keys
2025-12-14 14:00:10,810 - ERROR -   3. Add new keys from: https://aistudio.google.com/apikey
2025-12-14 14:00:10,811 - ERROR -   4. Save CSV and reload in application
2025-12-14 14:00:10,811 - ERROR -   5. Try again
2025-12-14 14:00:10,812 - ERROR - 
2025-12-14 14:00:10,812 - ERROR - ======================================================================
2025-12-14 14:09:11,376 - INFO - Loaded 6 predefined prompts
2025-12-14 14:11:04,525 - ERROR - No valid API keys found in the file
2025-12-14 14:11:14,759 - INFO - Loaded 3 API keys
2025-12-14 14:12:07,140 - INFO - === Starting PDF Processing ===
2025-12-14 14:12:07,141 - INFO - Model: gemini-2.5-pro
2025-12-14 14:12:07,141 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 14:12:07,143 - INFO - Full prompt being sent (7390 chars): You are a meticulous medical OCR & structuring assistant. Your job is to extract **only** what is present on each provided textbook page image/PDF and convert it into clean, AI-ready text with structured sections. You MUST avoid hallucinations and preserve original medical meaning precisely. Follow these global rules:

GLOBAL PRINCIPLES
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write: "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology; do not normalize British↔American spelling.
- CLEAN OCR: 
  - Remove page headers/footers, running titles, folios, and footers like “©Publisher 2023”.
  - Fix broken words at line breaks (e.g., "thera-\npy" → "therapy").
  - Replace ligatures (ﬁ, ﬂ) with normal letters.
  - Preserve meaningful capitalization, italics markers (use *italic*), bold (**bold**), and inline sub/superscripts as LaTeX if clearly indicated (e.g., CO$_2$).
- CITATIONS: Keep in-text citations literally (e.g., “[12]”, “(Smith 2021)”).
- MATH/CHEM: For formulae, use inline LaTeX: e.g., `pH = -\log_{10} [H^+]`.
- NO IMAGES: Describe figures/diagrams/charts in text form—succinct but complete. Do not invent unseen labels.

STRUCTURED OUTPUT FORMAT (Markdown with embedded JSON blocks)
Always produce in this exact order:

1) `# Page Metadata`
   - Book title (if visible), chapter title (if visible), page number (if visible or inferable), section headings found.
   - Confidence notes: short bullets where uncertainty exists.

2) `# Body`
   - Clean, continuous paragraph text. Keep section/subsection headings as `##` and `###`.

3) `# Tables`
   - For each table found, output a JSON block per table with:
   ```json
   {
     "type": "table",
     "title": "Table 3.2 Disease-modifying agents",
     "note": "footnotes or legends if present",
     "columns": ["Column A", "Column B", "Column C"],
     "rows": [
       ["cell(1,1)", "cell(1,2)", "cell(1,3)"],
       ["cell(2,1)", "cell(2,2)", "cell(2,3)"]
     ],
     "uncertain_cells": [{"row":2,"col":3,"reason":"blurry"}]
   }
If a table is complex (merged cells), normalize by repeating header labels; if impossible, add "structure_note".

# Algorithms / Clinical Approaches

Convert any flowchart, algorithm box, or approach diagram into BOTH:
a) Bulleted steps (plain text):

Step 1: …

If lab X > Y → do …

Else → …
b) Machine-readable pseudo-logic JSON:

json
Copy code
{
  "type": "algorithm",
  "title": "Approach to suspected DKA",
  "nodes": [
    {"id":"start","text":"Patient with hyperglycemia"},
    {"id":"n1","text":"Check ketones"},
    {"id":"n2","text":"If ketones positive → start insulin infusion"}
  ],
  "edges": [
    {"from":"start","to":"n1"},
    {"from":"n1","to":"n2","condition":"ketones positive"}
  ]
}
Use simple IDs; preserve clinical thresholds verbatim.

# Figures / Diagrams / Charts

For each figure, write a compact textual description capturing labels, axes, and key relationships.

If a chart encodes data values, extract the visible numbers as a small table. If not given, describe trends only.

Example JSON:

json
Copy code
{
  "type": "figure",
  "title": "Figure 5.1 Cardiac cycle",
  "description": "Schematic phases (isovolumetric contraction, ejection, …); labels: LV pressure, aortic pressure… Trend: LV pressure rises during …",
  "visible_labels": ["LV", "Aorta", "Mitral"],
  "data_points": null
}
# Lists & Key Points

Convert bullet lists and numbered lists cleanly.

For “pearls”, “high-yield” callouts, prefix with **HIGH-YIELD:**.

# References / Footnotes on Page

Transcribe verbatim; if footnote markers map to table/figure, cross-reference.

# Uncertain / OCR Issues

JSON array, where each item has: location (body/table/figure), snippet (if any), reason (e.g., “scan blur”), and confidence score 0–1.

ADDITIONAL RULES FOR DIFFICULT LAYOUTS

Multi-column pages: Respect reading order left→right, top→bottom per row.

Sidebars/callouts: Place them after the paragraph they visually relate to; prefix with > Note: or > Caution:; also mirror inside # Lists & Key Points if “pearls”.

Units & thresholds: Keep exact units (mg/kg, mmol/L). Do not convert units.

Drug names: Preserve capitalization of brand/generic as shown.

Abbreviations: On first obvious occurrence, if expansion is shown on page, include (abbr: expansion).

OUTPUT VALIDATION

Ensure valid JSON blocks (UTF-8, double quotes).

No trailing commas.

Do not wrap JSON in code fences other than the ones I asked above.

Final Output structure: your output must be sent is as a JSON in a code block with the delimiter of three consecutive semicolons like “;;;”. Each row is representative of a “page text” or “figure” or “Table”. So each “page text” and “figure” and “Table”  will have a row. The columns Headers are:
    1. Type
    2. Extraction
    3. Number
    4. Part
The “Type” column is for mentioning the type of the cell row data. The acceptable types are “page text” or “figure” or “Table”. If you are writing the page’s text in the extraction column, then the type will be “page text”. If the row in for figures, write “Figure”. And ”. If the row in for Tables, write “Table”.
The “Extraction” column is the main column for each row. If you are extracting a page’s text, write the complete text here. The JSONs of tables and figures must be written here as well.
The References in the end of the chapter must not be extracted. Ignore it.
The ”Number” column must show the page it is extracted from like 1 or 2 and more.
The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part. 

VERY IMPORTANT: your output must be single line (minified). DO NOT EVER use the “ENTER” button inside the cells. It shouldn’t be html rich. Do not separate texts with ENTER.

You will now receive a PDF, respond in the exact structure described above.
2025-12-14 14:12:15,442 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 14:12:15,444 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 14:12:15,444 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 14:12:15,444 - INFO - Using max_output_tokens: 32768
2025-12-14 14:12:15,444 - INFO - Using model: gemini-2.5-pro
2025-12-14 14:12:15,445 - INFO - Sending prompt (length: 7390 characters)
2025-12-14 14:12:15,445 - INFO - Max output tokens: 32768
2025-12-14 14:12:15,446 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 14:12:15,446 - INFO - Streaming disabled for large request (prompt: 7731 chars, max_tokens: 32768)
2025-12-14 14:12:15,446 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-14 14:12:16,706 - ERROR - ================================================================================
2025-12-14 14:12:16,707 - ERROR - 🔴 RATE LIMIT ERROR (429) - COMPLETE DETAILS
2025-12-14 14:12:16,708 - ERROR - ================================================================================
2025-12-14 14:12:16,708 - ERROR - Error Type: ResourceExhausted
2025-12-14 14:12:16,709 - ERROR - Status Code: 429
2025-12-14 14:12:16,709 - ERROR - Error Message: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 14:12:16,710 - ERROR - 
2025-12-14 14:12:16,710 - ERROR - 📊 CONCURRENCY INFORMATION:
2025-12-14 14:12:16,711 - ERROR -   Process ID (PID): 85453
2025-12-14 14:12:16,711 - ERROR -   Process Name: run.py
2025-12-14 14:12:16,712 - ERROR -   Thread ID: 125214235752000
2025-12-14 14:12:16,712 - ERROR -   Thread Name: Thread-1 (worker)
2025-12-14 14:12:16,713 - ERROR -   Worker ID: 125214384912192
2025-12-14 14:12:16,713 - ERROR - 
2025-12-14 14:12:16,714 - ERROR - 🔍 FULL ERROR REPRESENTATION:
2025-12-14 14:12:16,716 - ERROR -   ResourceExhausted('Resource has been exhausted (e.g. check quota).')
2025-12-14 14:12:16,717 - ERROR - ================================================================================
2025-12-14 14:12:16,718 - WARNING - ⚠️ Rate limit hit (429) - Attempt 1/3
2025-12-14 14:12:16,719 - WARNING -    Waiting 60.0s before retry... (Error count: 1/5)
2025-12-14 14:13:17,052 - ERROR - ================================================================================
2025-12-14 14:13:17,053 - ERROR - 🔴 RATE LIMIT ERROR (429) - COMPLETE DETAILS
2025-12-14 14:13:17,054 - ERROR - ================================================================================
2025-12-14 14:13:17,054 - ERROR - Error Type: ResourceExhausted
2025-12-14 14:13:17,055 - ERROR - Status Code: 429
2025-12-14 14:13:17,055 - ERROR - Error Message: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 14:13:17,056 - ERROR - 
2025-12-14 14:13:17,056 - ERROR - 📊 CONCURRENCY INFORMATION:
2025-12-14 14:13:17,057 - ERROR -   Process ID (PID): 85453
2025-12-14 14:13:17,057 - ERROR -   Process Name: run.py
2025-12-14 14:13:17,058 - ERROR -   Thread ID: 125214235752000
2025-12-14 14:13:17,058 - ERROR -   Thread Name: Thread-1 (worker)
2025-12-14 14:13:17,059 - ERROR -   Worker ID: 125214384912192
2025-12-14 14:13:17,059 - ERROR - 
2025-12-14 14:13:17,060 - ERROR - 🔍 FULL ERROR REPRESENTATION:
2025-12-14 14:13:17,060 - ERROR -   ResourceExhausted('Resource has been exhausted (e.g. check quota).')
2025-12-14 14:13:17,061 - ERROR - ================================================================================
2025-12-14 14:13:17,061 - WARNING - ⚠️ Rate limit hit (429) - Attempt 2/3
2025-12-14 14:13:17,062 - WARNING -    Waiting 90.0s before retry... (Error count: 2/5)
2025-12-14 14:14:47,389 - ERROR - ================================================================================
2025-12-14 14:14:47,390 - ERROR - 🔴 RATE LIMIT ERROR (429) - COMPLETE DETAILS
2025-12-14 14:14:47,390 - ERROR - ================================================================================
2025-12-14 14:14:47,390 - ERROR - Error Type: ResourceExhausted
2025-12-14 14:14:47,390 - ERROR - Status Code: 429
2025-12-14 14:14:47,390 - ERROR - Error Message: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 14:14:47,390 - ERROR - 
2025-12-14 14:14:47,390 - ERROR - 📊 CONCURRENCY INFORMATION:
2025-12-14 14:14:47,390 - ERROR -   Process ID (PID): 85453
2025-12-14 14:14:47,390 - ERROR -   Process Name: run.py
2025-12-14 14:14:47,390 - ERROR -   Thread ID: 125214235752000
2025-12-14 14:14:47,390 - ERROR -   Thread Name: Thread-1 (worker)
2025-12-14 14:14:47,390 - ERROR -   Worker ID: 125214384912192
2025-12-14 14:14:47,390 - ERROR - 
2025-12-14 14:14:47,391 - ERROR - 🔍 FULL ERROR REPRESENTATION:
2025-12-14 14:14:47,391 - ERROR -   ResourceExhausted('Resource has been exhausted (e.g. check quota).')
2025-12-14 14:14:47,391 - ERROR - ================================================================================
2025-12-14 14:14:47,391 - ERROR - ================================================================================
2025-12-14 14:14:47,391 - ERROR - 🔴 API ERROR - COMPLETE DETAILS
2025-12-14 14:14:47,391 - ERROR - ================================================================================
2025-12-14 14:14:47,391 - ERROR - Error Type: ResourceExhausted
2025-12-14 14:14:47,391 - ERROR - Status Code: 429
2025-12-14 14:14:47,391 - ERROR - Error Message: 429 Resource has been exhausted (e.g. check quota).
2025-12-14 14:14:47,391 - ERROR - 
2025-12-14 14:14:47,391 - ERROR - 📊 CONCURRENCY INFORMATION:
2025-12-14 14:14:47,392 - ERROR -   Process ID (PID): 85453
2025-12-14 14:14:47,392 - ERROR -   Process Name: run.py
2025-12-14 14:14:47,392 - ERROR -   Thread ID: 125214235752000
2025-12-14 14:14:47,392 - ERROR -   Thread Name: Thread-1 (worker)
2025-12-14 14:14:47,392 - ERROR -   Worker ID: 125214384912192
2025-12-14 14:14:47,392 - ERROR - ================================================================================
2025-12-14 14:14:47,392 - ERROR - ⚠️ Rate limit (429) persisted after all backoff retries. Attempting to switch to next key...
2025-12-14 14:15:17,392 - INFO - Retrying with API key 1/3: bagher
2025-12-14 14:15:29,650 - INFO - Streaming disabled for large request (prompt: 7731 chars, max_tokens: 32768)
2025-12-14 14:15:30,957 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 14:15:30,957 - INFO - Retrying with API key 2/3: bagher
2025-12-14 14:15:46,613 - INFO - Streaming disabled for large request (prompt: 7731 chars, max_tokens: 32768)
2025-12-14 14:15:46,613 - INFO - Waiting 30s before trying key 2...
2025-12-14 14:16:17,927 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 14:16:17,927 - INFO - Retrying with API key 3/3: bagher
2025-12-14 14:16:19,101 - INFO - Streaming disabled for large request (prompt: 7731 chars, max_tokens: 32768)
2025-12-14 14:16:19,102 - INFO - Waiting 45s before trying key 3...
2025-12-14 14:17:05,577 - WARNING - API key bagher hit rate limit (429), trying next...
2025-12-14 14:17:05,577 - ERROR - ======================================================================
2025-12-14 14:17:05,577 - ERROR - ❌ All 3 API keys failed. Cannot process request.
2025-12-14 14:17:05,577 - ERROR - ======================================================================
2025-12-14 14:17:05,578 - ERROR - 
2025-12-14 14:17:05,578 - ERROR - Possible reasons:
2025-12-14 14:17:05,578 - ERROR -   • All keys LEAKED (403) → Remove leaked keys, add new ones
2025-12-14 14:17:05,578 - ERROR -   • All keys QUOTA EXHAUSTED (429) → Wait for reset or add more keys
2025-12-14 14:17:05,578 - ERROR -   • Keys INVALID/EXPIRED → Generate new keys from Google AI Studio
2025-12-14 14:17:05,578 - ERROR - 
2025-12-14 14:17:05,578 - ERROR - Quick fix:
2025-12-14 14:17:05,578 - ERROR -   1. Open API keys CSV file
2025-12-14 14:17:05,578 - ERROR -   2. Remove leaked/invalid keys
2025-12-14 14:17:05,578 - ERROR -   3. Add new keys from: https://aistudio.google.com/apikey
2025-12-14 14:17:05,578 - ERROR -   4. Save CSV and reload in application
2025-12-14 14:17:05,578 - ERROR -   5. Try again
2025-12-14 14:17:05,578 - ERROR - 
2025-12-14 14:17:05,578 - ERROR - ======================================================================
2025-12-14 14:30:16,617 - INFO - Loaded 6 predefined prompts
2025-12-14 14:31:43,155 - INFO - Loaded 3 API keys
2025-12-14 14:32:52,510 - INFO - === Starting PDF Processing ===
2025-12-14 14:32:52,510 - INFO - Model: gemini-2.5-flash
2025-12-14 14:32:52,510 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 14:32:52,510 - INFO - Full prompt being sent (2527 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple PARTS.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE PART of the final output
- NOT repeat rows from previous parts
- Preserve the exact order of rows across parts

====================
OUTPUT FORMAT (EXACT)
====================
{
  "part_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <our part number>
    }
  ]
}

Rules for rows:
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
PART INSTRUCTIONS
====================
This is PART {part_index} of the output.

Generate ONLY the rows that belong to this part.
Stop when you reach a safe size limit.
If more content remains after this part, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate PART {part_index}.
2025-12-14 14:33:07,723 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 14:33:07,724 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 14:33:07,725 - INFO - Model: gemini-2.5-flash, Max tokens for model: 32768, Using: 32768
2025-12-14 14:33:07,725 - INFO - Using max_output_tokens: 32768
2025-12-14 14:33:07,726 - INFO - Using model: gemini-2.5-flash
2025-12-14 14:33:07,726 - INFO - Sending prompt (length: 2527 characters)
2025-12-14 14:33:07,727 - INFO - Max output tokens: 32768
2025-12-14 14:33:07,727 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 14:33:07,727 - INFO - Streaming disabled for large request (prompt: 2868 chars, max_tokens: 32768)
2025-12-14 14:33:07,728 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-14 14:35:05,694 - INFO - ✓ Request completed: 2618 characters received
2025-12-14 14:35:05,695 - INFO - Finish reason: MAX_TOKENS (truncated!)
2025-12-14 14:35:05,696 - WARNING - ⚠️ Response may be truncated (finish_reason: MAX_TOKENS (truncated!))
2025-12-14 14:35:12,157 - INFO - === Response Received ===
2025-12-14 14:35:12,159 - INFO - Response length: 2618 characters
2025-12-14 14:35:12,161 - INFO - Truncated: True
2025-12-14 14:35:12,162 - INFO - Response preview (first 500 chars):  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *...
2025-12-14 14:35:12,163 - INFO - Response preview (last 500 chars): ... * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
2025-12-14 14:35:12,458 - WARNING - python-docx not available, saving as text file
2025-12-14 14:35:12,460 - INFO - Response displayed and saved to: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46_response_20251214_143512.txt
2025-12-14 14:35:21,274 - INFO - === Starting PDF Processing ===
2025-12-14 14:35:21,274 - INFO - Model: gemini-2.5-pro
2025-12-14 14:35:21,275 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 14:35:21,275 - INFO - Full prompt being sent (2527 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple PARTS.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE PART of the final output
- NOT repeat rows from previous parts
- Preserve the exact order of rows across parts

====================
OUTPUT FORMAT (EXACT)
====================
{
  "part_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <our part number>
    }
  ]
}

Rules for rows:
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
PART INSTRUCTIONS
====================
This is PART {part_index} of the output.

Generate ONLY the rows that belong to this part.
Stop when you reach a safe size limit.
If more content remains after this part, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate PART {part_index}.
2025-12-14 14:35:48,465 - INFO - PDF uploaded successfully with API key: bagher
2025-12-14 14:35:48,466 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-14 14:35:48,467 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-14 14:35:48,468 - INFO - Using max_output_tokens: 32768
2025-12-14 14:35:48,469 - INFO - Using model: gemini-2.5-pro
2025-12-14 14:35:48,470 - INFO - Sending prompt (length: 2527 characters)
2025-12-14 14:35:48,471 - INFO - Max output tokens: 32768
2025-12-14 14:35:48,472 - INFO - Using original prompt with JSON output instruction (prompt preserved)
2025-12-14 14:35:48,473 - INFO - Streaming disabled for large request (prompt: 2868 chars, max_tokens: 32768)
2025-12-14 14:35:48,473 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-14 14:37:17,611 - INFO - ✓ Request completed: 13248 characters received
2025-12-14 14:37:17,612 - INFO - Finish reason: STOP (normal completion)
2025-12-14 14:37:17,614 - INFO - ✓ Response completed normally
2025-12-14 14:37:17,617 - INFO - === Response Received ===
2025-12-14 14:37:17,619 - INFO - Response length: 13248 characters
2025-12-14 14:37:17,620 - INFO - Truncated: False
2025-12-14 14:37:17,621 - INFO - Response preview (first 500 chars): ```json
{
  "part_index": 1,
  "is_last": false,
  "rows": [
    {
      "Type": "page text",
      "Extraction": "Pemphigoid Group 30",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Luca Borradori and Michael Hertl",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Chapter Contents\nBullous Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...
2025-12-14 14:37:17,622 - INFO - Response preview (last 500 chars): ...rther amplify the inflammatory response⁵,¹¹⁻¹⁶ while the proteinases, together with reactive oxygen species, degrade various extracellular matrix proteins as well as BP180.¹¹⁻¹⁶ IgG anti-BP180 autoantibodies can also boost the inflammatory response by stimulating keratinocytes to express inflammatory cytokines (Fig. 30.1)¹¹. Furthermore, IgG autoantibodies are able to directly impair dermal-epidermal adhesion without complement activation¹¹.",
      "Number": 518,
      "Part": 1
    }
  ]
}
```
2025-12-15 08:39:00,034 - INFO - Loaded 6 predefined prompts
2025-12-15 08:39:21,054 - ERROR - No valid API keys found in the file
2025-12-15 08:39:34,042 - INFO - Loaded 3 API keys
2025-12-15 08:41:01,105 - INFO - === Starting PDF Processing ===
2025-12-15 08:41:01,106 - INFO - Model: gemini-2.5-pro
2025-12-15 08:41:01,106 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 08:41:01,106 - INFO - Full prompt being sent (2527 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple PARTS.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE PART of the final output
- NOT repeat rows from previous parts
- Preserve the exact order of rows across parts

====================
OUTPUT FORMAT (EXACT)
====================
{
  "part_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <our part number>
    }
  ]
}

Rules for rows:
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
PART INSTRUCTIONS
====================
This is PART {part_index} of the output.

Generate ONLY the rows that belong to this part.
Stop when you reach a safe size limit.
If more content remains after this part, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate PART {part_index}.
2025-12-15 08:41:12,929 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 08:41:12,931 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 08:41:12,931 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 08:41:12,932 - INFO - Using max_output_tokens: 32768
2025-12-15 08:41:12,932 - INFO - Using model: gemini-2.5-pro
2025-12-15 08:41:12,932 - INFO - Sending prompt (length: 2527 characters)
2025-12-15 08:41:12,932 - INFO - Max output tokens: 32768
2025-12-15 08:41:12,933 - INFO - Using user's prompt as-is (no modifications)
2025-12-15 08:41:12,933 - INFO - Streaming disabled for large request (prompt: 2527 chars, max_tokens: 32768)
2025-12-15 08:41:12,933 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 08:41:55,659 - INFO - ✓ Request completed: 13951 characters received
2025-12-15 08:41:55,660 - INFO - Finish reason: STOP (normal completion)
2025-12-15 08:41:55,661 - INFO - ✓ Response completed normally
2025-12-15 08:41:55,664 - INFO - === Response Received ===
2025-12-15 08:41:55,665 - INFO - Response length: 13951 characters
2025-12-15 08:41:55,666 - INFO - Truncated: False
2025-12-15 08:41:55,666 - INFO - Response preview (first 500 chars): ```json
{
  "part_index": 1,
  "is_last": false,
  "rows": [
    {
      "Type": "page text",
      "Extraction": "Pemphigoid Group 30",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Luca Borradori and Michael Hertl",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "Table",
      "Extraction": "{\"Title\": \"Chapter Contents\", \"Data\": [{\"Content\": \"Bullous Pemphigoid\", \"Page\": \"517\"}, {\"Content\": \"Mucous Membrane P...
2025-12-15 08:41:55,669 - INFO - Response preview (last 500 chars): ...rther amplify the inflammatory response⁵,¹¹⁻¹⁶ while the proteinases, together with reactive oxygen species, degrade various extracellular matrix proteins as well as BP180.¹¹⁻¹⁶ IgG anti-BP180 autoantibodies can also boost the inflammatory response by stimulating keratinocytes to express inflammatory cytokines (Fig. 30.1)¹¹. Furthermore, IgG autoantibodies are able to directly impair dermal-epidermal adhesion without complement activation¹¹.",
      "Number": 518,
      "Part": 1
    }
  ]
}
```
2025-12-15 08:48:39,388 - INFO - Loaded 6 predefined prompts
2025-12-15 08:49:07,455 - INFO - Loaded 3 API keys
2025-12-15 08:49:38,701 - INFO - === Starting PDF Processing ===
2025-12-15 08:49:38,702 - INFO - Model: gemini-2.5-flash
2025-12-15 08:49:38,703 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 08:49:38,703 - INFO - Full prompt being sent (2527 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple PARTS.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE PART of the final output
- NOT repeat rows from previous parts
- Preserve the exact order of rows across parts

====================
OUTPUT FORMAT (EXACT)
====================
{
  "part_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <our part number>
    }
  ]
}

Rules for rows:
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
PART INSTRUCTIONS
====================
This is PART {part_index} of the output.

Generate ONLY the rows that belong to this part.
Stop when you reach a safe size limit.
If more content remains after this part, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate PART {part_index}.
2025-12-15 08:49:38,706 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7
2025-12-15 08:49:38,707 - INFO - No previous parts found, starting from part 1
2025-12-15 08:49:38,707 - INFO - === Processing Part 1 ===
2025-12-15 08:49:48,467 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 08:49:48,468 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 08:49:48,469 - INFO - Model: gemini-2.5-flash, Max tokens for model: 32768, Using: 32768
2025-12-15 08:49:48,469 - INFO - Using max_output_tokens: 32768
2025-12-15 08:49:48,469 - INFO - Using model: gemini-2.5-flash
2025-12-15 08:49:48,470 - INFO - Sending prompt (length: 2558 characters)
2025-12-15 08:49:48,470 - INFO - Max output tokens: 32768
2025-12-15 08:49:48,471 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 08:49:48,471 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 08:49:48,472 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 08:50:11,383 - INFO - ✓ Request completed: 9518 characters received
2025-12-15 08:50:11,384 - INFO - Finish reason: STOP (normal completion)
2025-12-15 08:50:11,384 - INFO - ✓ Response completed normally
2025-12-15 08:50:11,386 - ERROR - Part 1: JSON parse error: Invalid \escape: line 157 column 574 (char 8959)
2025-12-15 08:50:11,387 - ERROR - Part 1: Response text (first 1000 chars): {
  "part_index": 1,
  "is_last": false,
  "rows": [
    {
      "Type": "page text",
      "Extraction": "Pemphigoid Group 30",
      "Number": 1,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Luca Borradori and Michael Hertl",
      "Number": 1,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Chapter Contents",
      "Number": 1,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Bullous Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .517",
      "Number": 1,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Mucous Membrane Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .526",
      "Number": 1,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Epidermolysis Bullosa Acquisita . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .530",
      "Numbe
2025-12-15 08:50:11,389 - ERROR - Part 1: Response text (last 500 chars): L]-4, IL-5, IL-13; see Ch. 4)\textsuperscript{10,11}. Th2 and Th17 cytokines, which are particularly relevant to the pathophysiology of BP, predominate within lesional tissue and in patients' sera\textsuperscript{10-13}.",
      "Number": 1,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Upon binding of autoantibodies to their target antigens, subepidermal blister formation results from a cascade of events in which Fc",
      "Number": 1,
      "Part": 1
    }
  ]
}
2025-12-15 08:50:11,389 - ERROR - Part 1: Failed to parse response
2025-12-15 08:50:11,390 - ERROR - Part 1: Response text (first 1000 chars): ```json
{
  "part_index": 1,
  "is_last": false,
  "rows": [
    {
      "Type": "page text",
      "Extraction": "Pemphigoid Group 30",
      "Number": 1,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Luca Borradori and Michael Hertl",
      "Number": 1,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Chapter Contents",
      "Number": 1,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Bullous Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .517",
      "Number": 1,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Mucous Membrane Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .526",
      "Number": 1,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Epidermolysis Bullosa Acquisita . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .530",
    
2025-12-15 08:50:11,390 - ERROR - Part 1: Retrying same part...
2025-12-15 08:50:16,390 - INFO - === Processing Part 1 ===
2025-12-15 08:50:28,090 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 08:50:28,090 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 08:50:28,090 - INFO - Model: gemini-2.5-flash, Max tokens for model: 32768, Using: 32768
2025-12-15 08:50:28,090 - INFO - Using max_output_tokens: 32768
2025-12-15 08:50:28,090 - INFO - Using model: gemini-2.5-flash
2025-12-15 08:50:28,091 - INFO - Sending prompt (length: 2558 characters)
2025-12-15 08:50:28,091 - INFO - Max output tokens: 32768
2025-12-15 08:50:28,091 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 08:50:28,091 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 08:50:28,091 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 08:51:19,343 - INFO - Loaded 6 predefined prompts
2025-12-15 08:51:43,705 - INFO - Loaded 3 API keys
2025-12-15 08:52:21,576 - INFO - === Starting PDF Processing ===
2025-12-15 08:52:21,577 - INFO - Model: gemini-2.5-pro
2025-12-15 08:52:21,577 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 08:52:21,577 - INFO - Full prompt being sent (2527 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple PARTS.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE PART of the final output
- NOT repeat rows from previous parts
- Preserve the exact order of rows across parts

====================
OUTPUT FORMAT (EXACT)
====================
{
  "part_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <our part number>
    }
  ]
}

Rules for rows:
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
PART INSTRUCTIONS
====================
This is PART {part_index} of the output.

Generate ONLY the rows that belong to this part.
Stop when you reach a safe size limit.
If more content remains after this part, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate PART {part_index}.
2025-12-15 08:52:21,578 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7
2025-12-15 08:52:21,579 - INFO - No previous parts found, starting from part 1
2025-12-15 08:52:21,579 - INFO - === Processing Part 1 ===
2025-12-15 08:52:31,278 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 08:52:31,279 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 08:52:31,280 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 08:52:31,281 - INFO - Using max_output_tokens: 32768
2025-12-15 08:52:31,281 - INFO - Using model: gemini-2.5-pro
2025-12-15 08:52:31,282 - INFO - Sending prompt (length: 2558 characters)
2025-12-15 08:52:31,282 - INFO - Max output tokens: 32768
2025-12-15 08:52:31,283 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 08:52:31,283 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 08:52:31,284 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 08:53:43,280 - INFO - ✓ Request completed: 13469 characters received
2025-12-15 08:53:43,281 - INFO - Finish reason: STOP (normal completion)
2025-12-15 08:53:43,282 - INFO - ✓ Response completed normally
2025-12-15 08:53:43,285 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,285 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,286 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,286 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,287 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,287 - WARNING - Part 1, row 9: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,287 - WARNING - Part 1, row 10: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,288 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,288 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,289 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,289 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,290 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,290 - WARNING - Part 1, row 9: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,290 - WARNING - Part 1, row 10: Extraction contains newlines (should use \n)
2025-12-15 08:53:43,291 - INFO - Part 1: Parsed successfully - is_last=False, rows=14
2025-12-15 08:53:43,295 - INFO - ✓ Saved part 1 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_1.json
2025-12-15 08:53:43,296 - INFO - Part 1: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_1.json (not displayed to user)
2025-12-15 08:53:43,296 - INFO - Part 1: Added 14 rows (total: 14)
2025-12-15 08:53:43,297 - INFO - Part 1: is_last=false, continuing to next part...
2025-12-15 08:53:43,300 - INFO - Waiting 13.1s before next part...
2025-12-15 08:53:56,448 - INFO - === Processing Part 2 ===
2025-12-15 08:54:07,096 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 08:54:07,097 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 08:54:07,098 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 08:54:07,098 - INFO - Using max_output_tokens: 32768
2025-12-15 08:54:07,099 - INFO - Using model: gemini-2.5-pro
2025-12-15 08:54:07,099 - INFO - Sending prompt (length: 2592 characters)
2025-12-15 08:54:07,099 - INFO - Max output tokens: 32768
2025-12-15 08:54:07,100 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 08:54:07,100 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 08:54:07,101 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 08:55:43,968 - INFO - ✓ Request completed: 24433 characters received
2025-12-15 08:55:43,969 - INFO - Finish reason: STOP (normal completion)
2025-12-15 08:55:43,970 - INFO - ✓ Response completed normally
2025-12-15 08:55:43,974 - INFO - Part 2: Parsed successfully - is_last=False, rows=17
2025-12-15 08:55:43,978 - INFO - ✓ Saved part 2 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_2.json
2025-12-15 08:55:43,979 - INFO - Part 2: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_2.json (not displayed to user)
2025-12-15 08:55:43,980 - INFO - Part 2: Added 17 rows (total: 31)
2025-12-15 08:55:43,980 - INFO - Part 2: is_last=false, continuing to next part...
2025-12-15 08:55:43,982 - INFO - Waiting 11.2s before next part...
2025-12-15 08:55:55,215 - INFO - === Processing Part 3 ===
2025-12-15 08:56:05,154 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 08:56:05,155 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 08:56:05,156 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 08:56:05,156 - INFO - Using max_output_tokens: 32768
2025-12-15 08:56:05,156 - INFO - Using model: gemini-2.5-pro
2025-12-15 08:56:05,157 - INFO - Sending prompt (length: 2592 characters)
2025-12-15 08:56:05,157 - INFO - Max output tokens: 32768
2025-12-15 08:56:05,158 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 08:56:05,159 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 08:56:05,160 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 08:57:23,213 - INFO - ✓ Request completed: 18994 characters received
2025-12-15 08:57:23,214 - INFO - Finish reason: STOP (normal completion)
2025-12-15 08:57:23,215 - INFO - ✓ Response completed normally
2025-12-15 08:57:23,218 - INFO - Part 3: Parsed successfully - is_last=False, rows=12
2025-12-15 08:57:23,223 - INFO - ✓ Saved part 3 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_3.json
2025-12-15 08:57:23,224 - INFO - Part 3: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_3.json (not displayed to user)
2025-12-15 08:57:23,225 - INFO - Part 3: Added 12 rows (total: 43)
2025-12-15 08:57:23,227 - INFO - Part 3: is_last=false, continuing to next part...
2025-12-15 08:57:23,229 - INFO - Waiting 13.3s before next part...
2025-12-15 08:57:36,566 - INFO - === Processing Part 4 ===
2025-12-15 08:57:46,017 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 08:57:46,017 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 08:57:46,018 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 08:57:46,019 - INFO - Using max_output_tokens: 32768
2025-12-15 08:57:46,019 - INFO - Using model: gemini-2.5-pro
2025-12-15 08:57:46,020 - INFO - Sending prompt (length: 2592 characters)
2025-12-15 08:57:46,020 - INFO - Max output tokens: 32768
2025-12-15 08:57:46,021 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 08:57:46,022 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 08:57:46,022 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 08:58:53,119 - INFO - ✓ Request completed: 13088 characters received
2025-12-15 08:58:53,121 - INFO - Finish reason: STOP (normal completion)
2025-12-15 08:58:53,121 - INFO - ✓ Response completed normally
2025-12-15 08:58:53,124 - WARNING - Part 4, row 3: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,125 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,126 - WARNING - Part 4, row 8: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,126 - WARNING - Part 4, row 9: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,127 - WARNING - Part 4, row 10: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,127 - WARNING - Part 4, row 13: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,127 - WARNING - Part 4, row 14: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,128 - WARNING - Part 4, row 3: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,129 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,130 - WARNING - Part 4, row 8: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,130 - WARNING - Part 4, row 9: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,130 - WARNING - Part 4, row 10: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,131 - WARNING - Part 4, row 13: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,131 - WARNING - Part 4, row 14: Extraction contains newlines (should use \n)
2025-12-15 08:58:53,131 - INFO - Part 4: Parsed successfully - is_last=False, rows=15
2025-12-15 08:58:53,134 - INFO - ✓ Saved part 4 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_4.json
2025-12-15 08:58:53,134 - INFO - Part 4: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_4.json (not displayed to user)
2025-12-15 08:58:53,135 - INFO - Part 4: Added 15 rows (total: 58)
2025-12-15 08:58:53,135 - INFO - Part 4: is_last=false, continuing to next part...
2025-12-15 08:58:53,136 - INFO - Waiting 10.2s before next part...
2025-12-15 08:59:03,370 - INFO - === Processing Part 5 ===
2025-12-15 08:59:12,449 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 08:59:12,450 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 08:59:12,451 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 08:59:12,451 - INFO - Using max_output_tokens: 32768
2025-12-15 08:59:12,452 - INFO - Using model: gemini-2.5-pro
2025-12-15 08:59:12,453 - INFO - Sending prompt (length: 2592 characters)
2025-12-15 08:59:12,453 - INFO - Max output tokens: 32768
2025-12-15 08:59:12,454 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 08:59:12,454 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 08:59:12,455 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:00:37,669 - INFO - ✓ Request completed: 30743 characters received
2025-12-15 09:00:37,670 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:00:37,670 - INFO - ✓ Response completed normally
2025-12-15 09:00:37,674 - WARNING - Part 5, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,677 - WARNING - Part 5, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,677 - WARNING - Part 5, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,677 - WARNING - Part 5, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,678 - WARNING - Part 5, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,678 - WARNING - Part 5, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,678 - WARNING - Part 5, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,679 - WARNING - Part 5, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,679 - WARNING - Part 5, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,680 - WARNING - Part 5, row 26: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,680 - WARNING - Part 5, row 27: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,680 - WARNING - Part 5, row 28: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,680 - WARNING - Part 5, row 29: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,682 - WARNING - Part 5, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,682 - WARNING - Part 5, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,683 - WARNING - Part 5, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,683 - WARNING - Part 5, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,683 - WARNING - Part 5, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,683 - WARNING - Part 5, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,683 - WARNING - Part 5, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,684 - WARNING - Part 5, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,684 - WARNING - Part 5, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,685 - WARNING - Part 5, row 26: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,687 - WARNING - Part 5, row 27: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,687 - WARNING - Part 5, row 28: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,688 - WARNING - Part 5, row 29: Extraction contains newlines (should use \n)
2025-12-15 09:00:37,688 - INFO - Part 5: Parsed successfully - is_last=False, rows=30
2025-12-15 09:00:37,691 - INFO - ✓ Saved part 5 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_5.json
2025-12-15 09:00:37,691 - INFO - Part 5: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_5.json (not displayed to user)
2025-12-15 09:00:37,691 - INFO - Part 5: Added 30 rows (total: 88)
2025-12-15 09:00:37,691 - INFO - Part 5: is_last=false, continuing to next part...
2025-12-15 09:00:37,692 - INFO - Waiting 12.8s before next part...
2025-12-15 09:00:50,507 - INFO - === Processing Part 6 ===
2025-12-15 09:00:59,877 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:00:59,878 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:00:59,878 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:00:59,879 - INFO - Using max_output_tokens: 32768
2025-12-15 09:00:59,880 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:00:59,881 - INFO - Sending prompt (length: 2592 characters)
2025-12-15 09:00:59,881 - INFO - Max output tokens: 32768
2025-12-15 09:00:59,881 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:00:59,881 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:00:59,881 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:02:00,614 - INFO - ✓ Request completed: 14519 characters received
2025-12-15 09:02:00,615 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:02:00,616 - INFO - ✓ Response completed normally
2025-12-15 09:02:00,617 - INFO - Part 6: Parsed successfully - is_last=False, rows=10
2025-12-15 09:02:00,618 - INFO - ✓ Saved part 6 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_6.json
2025-12-15 09:02:00,618 - INFO - Part 6: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_6.json (not displayed to user)
2025-12-15 09:02:00,618 - INFO - Part 6: Added 10 rows (total: 98)
2025-12-15 09:02:00,619 - INFO - Part 6: is_last=false, continuing to next part...
2025-12-15 09:02:00,619 - INFO - Waiting 10.0s before next part...
2025-12-15 09:02:10,574 - INFO - === Processing Part 7 ===
2025-12-15 09:02:22,351 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:02:22,351 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:02:22,352 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:02:22,352 - INFO - Using max_output_tokens: 32768
2025-12-15 09:02:22,352 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:02:22,352 - INFO - Sending prompt (length: 2592 characters)
2025-12-15 09:02:22,352 - INFO - Max output tokens: 32768
2025-12-15 09:02:22,354 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:02:22,354 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:02:22,354 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:03:45,028 - INFO - ✓ Request completed: 23134 characters received
2025-12-15 09:03:45,029 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:03:45,031 - INFO - ✓ Response completed normally
2025-12-15 09:03:45,034 - WARNING - Part 7, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,035 - WARNING - Part 7, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,035 - WARNING - Part 7, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,036 - WARNING - Part 7, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,036 - WARNING - Part 7, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,037 - WARNING - Part 7, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,037 - WARNING - Part 7, row 19: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,038 - WARNING - Part 7, row 22: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,039 - WARNING - Part 7, row 23: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,040 - WARNING - Part 7, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,040 - WARNING - Part 7, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,041 - WARNING - Part 7, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,041 - WARNING - Part 7, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,042 - WARNING - Part 7, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,042 - WARNING - Part 7, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,043 - WARNING - Part 7, row 19: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,043 - WARNING - Part 7, row 22: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,044 - WARNING - Part 7, row 23: Extraction contains newlines (should use \n)
2025-12-15 09:03:45,044 - INFO - Part 7: Parsed successfully - is_last=False, rows=25
2025-12-15 09:03:45,050 - INFO - ✓ Saved part 7 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_7.json
2025-12-15 09:03:45,051 - INFO - Part 7: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_7.json (not displayed to user)
2025-12-15 09:03:45,051 - INFO - Part 7: Added 25 rows (total: 123)
2025-12-15 09:03:45,052 - INFO - Part 7: is_last=false, continuing to next part...
2025-12-15 09:03:45,054 - INFO - Waiting 14.6s before next part...
2025-12-15 09:03:59,647 - INFO - === Processing Part 8 ===
2025-12-15 09:04:08,735 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:04:08,736 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:04:08,737 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:04:08,738 - INFO - Using max_output_tokens: 32768
2025-12-15 09:04:08,739 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:04:08,739 - INFO - Sending prompt (length: 2592 characters)
2025-12-15 09:04:08,740 - INFO - Max output tokens: 32768
2025-12-15 09:04:08,740 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:04:08,741 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:04:08,741 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:04:55,440 - INFO - ✓ Request completed: 16241 characters received
2025-12-15 09:04:55,441 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:04:55,441 - INFO - ✓ Response completed normally
2025-12-15 09:04:55,444 - WARNING - Part 8, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,445 - WARNING - Part 8, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,445 - WARNING - Part 8, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,446 - WARNING - Part 8, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,447 - WARNING - Part 8, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,447 - WARNING - Part 8, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,449 - WARNING - Part 8, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,449 - WARNING - Part 8, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,450 - WARNING - Part 8, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,450 - WARNING - Part 8, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,451 - WARNING - Part 8, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,452 - WARNING - Part 8, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,452 - WARNING - Part 8, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,453 - WARNING - Part 8, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,453 - WARNING - Part 8, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,453 - WARNING - Part 8, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,454 - WARNING - Part 8, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,454 - WARNING - Part 8, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,455 - WARNING - Part 8, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,455 - WARNING - Part 8, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:04:55,456 - INFO - Part 8: Parsed successfully - is_last=False, rows=19
2025-12-15 09:04:55,459 - INFO - ✓ Saved part 8 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_8.json
2025-12-15 09:04:55,460 - INFO - Part 8: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_8.json (not displayed to user)
2025-12-15 09:04:55,460 - INFO - Part 8: Added 19 rows (total: 142)
2025-12-15 09:04:55,461 - INFO - Part 8: is_last=false, continuing to next part...
2025-12-15 09:04:55,463 - INFO - Waiting 11.6s before next part...
2025-12-15 09:05:07,028 - INFO - === Processing Part 9 ===
2025-12-15 09:05:15,797 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:05:15,797 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:05:15,797 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:05:15,797 - INFO - Using max_output_tokens: 32768
2025-12-15 09:05:15,798 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:05:15,798 - INFO - Sending prompt (length: 2592 characters)
2025-12-15 09:05:15,798 - INFO - Max output tokens: 32768
2025-12-15 09:05:15,798 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:05:15,798 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:05:15,799 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:06:42,862 - INFO - ✓ Request completed: 23091 characters received
2025-12-15 09:06:42,867 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:06:42,867 - INFO - ✓ Response completed normally
2025-12-15 09:06:42,875 - WARNING - Part 9, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,878 - WARNING - Part 9, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,878 - WARNING - Part 9, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,880 - WARNING - Part 9, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,880 - WARNING - Part 9, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,881 - WARNING - Part 9, row 9: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,881 - WARNING - Part 9, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,882 - WARNING - Part 9, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,884 - WARNING - Part 9, row 15: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,885 - WARNING - Part 9, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,885 - WARNING - Part 9, row 19: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,886 - WARNING - Part 9, row 21: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,886 - WARNING - Part 9, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,891 - WARNING - Part 9, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,891 - WARNING - Part 9, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,892 - WARNING - Part 9, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,892 - WARNING - Part 9, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,893 - WARNING - Part 9, row 9: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,893 - WARNING - Part 9, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,894 - WARNING - Part 9, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,894 - WARNING - Part 9, row 15: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,894 - WARNING - Part 9, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,895 - WARNING - Part 9, row 19: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,895 - WARNING - Part 9, row 21: Extraction contains newlines (should use \n)
2025-12-15 09:06:42,896 - INFO - Part 9: Parsed successfully - is_last=False, rows=22
2025-12-15 09:06:42,904 - INFO - ✓ Saved part 9 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_9.json
2025-12-15 09:06:42,905 - INFO - Part 9: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_9.json (not displayed to user)
2025-12-15 09:06:42,906 - INFO - Part 9: Added 22 rows (total: 164)
2025-12-15 09:06:42,907 - INFO - Part 9: is_last=false, continuing to next part...
2025-12-15 09:06:42,911 - INFO - Waiting 13.1s before next part...
2025-12-15 09:06:55,987 - INFO - === Processing Part 10 ===
2025-12-15 09:07:07,218 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:07:07,219 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:07:07,219 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:07:07,219 - INFO - Using max_output_tokens: 32768
2025-12-15 09:07:07,219 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:07:07,219 - INFO - Sending prompt (length: 2593 characters)
2025-12-15 09:07:07,219 - INFO - Max output tokens: 32768
2025-12-15 09:07:07,219 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:07:07,220 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:07:07,220 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:08:40,862 - INFO - ✓ Request completed: 25516 characters received
2025-12-15 09:08:40,864 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:08:40,864 - INFO - ✓ Response completed normally
2025-12-15 09:08:40,869 - INFO - Part 10: Parsed successfully - is_last=False, rows=33
2025-12-15 09:08:40,875 - INFO - ✓ Saved part 10 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_10.json
2025-12-15 09:08:40,876 - INFO - Part 10: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_10.json (not displayed to user)
2025-12-15 09:08:40,876 - INFO - Part 10: Added 33 rows (total: 197)
2025-12-15 09:08:40,877 - INFO - Part 10: is_last=false, continuing to next part...
2025-12-15 09:08:40,878 - INFO - Waiting 10.3s before next part...
2025-12-15 09:08:51,134 - INFO - === Processing Part 11 ===
2025-12-15 09:09:03,081 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:09:03,082 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:09:03,086 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:09:03,087 - INFO - Using max_output_tokens: 32768
2025-12-15 09:09:03,087 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:09:03,088 - INFO - Sending prompt (length: 2594 characters)
2025-12-15 09:09:03,088 - INFO - Max output tokens: 32768
2025-12-15 09:09:03,089 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:09:03,089 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:09:03,090 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:09:55,466 - INFO - ✓ Request completed: 11730 characters received
2025-12-15 09:09:55,467 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:09:55,468 - INFO - ✓ Response completed normally
2025-12-15 09:09:55,471 - INFO - Part 11: Parsed successfully - is_last=False, rows=15
2025-12-15 09:09:55,475 - INFO - ✓ Saved part 11 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_11.json
2025-12-15 09:09:55,476 - INFO - Part 11: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_11.json (not displayed to user)
2025-12-15 09:09:55,477 - INFO - Part 11: Added 15 rows (total: 212)
2025-12-15 09:09:55,478 - INFO - Part 11: is_last=false, continuing to next part...
2025-12-15 09:09:55,480 - INFO - Waiting 8.1s before next part...
2025-12-15 09:10:03,543 - INFO - === Processing Part 12 ===
2025-12-15 09:10:12,827 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:10:12,828 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:10:12,828 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:10:12,829 - INFO - Using max_output_tokens: 32768
2025-12-15 09:10:12,829 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:10:12,830 - INFO - Sending prompt (length: 2594 characters)
2025-12-15 09:10:12,830 - INFO - Max output tokens: 32768
2025-12-15 09:10:12,831 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:10:12,831 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:10:12,831 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:11:32,446 - INFO - ✓ Request completed: 31367 characters received
2025-12-15 09:11:32,447 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:11:32,447 - INFO - ✓ Response completed normally
2025-12-15 09:11:32,452 - WARNING - Part 12, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,453 - WARNING - Part 12, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,454 - WARNING - Part 12, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,455 - WARNING - Part 12, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,455 - WARNING - Part 12, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,456 - WARNING - Part 12, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,456 - WARNING - Part 12, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,457 - WARNING - Part 12, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,458 - WARNING - Part 12, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,458 - WARNING - Part 12, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,459 - WARNING - Part 12, row 20: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,460 - WARNING - Part 12, row 22: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,460 - WARNING - Part 12, row 23: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,460 - WARNING - Part 12, row 24: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,461 - WARNING - Part 12, row 25: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,461 - WARNING - Part 12, row 26: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,462 - WARNING - Part 12, row 27: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,463 - WARNING - Part 12, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,463 - WARNING - Part 12, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,464 - WARNING - Part 12, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,465 - WARNING - Part 12, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,465 - WARNING - Part 12, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,465 - WARNING - Part 12, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,466 - WARNING - Part 12, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,466 - WARNING - Part 12, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,466 - WARNING - Part 12, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,467 - WARNING - Part 12, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,467 - WARNING - Part 12, row 20: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,467 - WARNING - Part 12, row 22: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,467 - WARNING - Part 12, row 23: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,468 - WARNING - Part 12, row 24: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,468 - WARNING - Part 12, row 25: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,468 - WARNING - Part 12, row 26: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,468 - WARNING - Part 12, row 27: Extraction contains newlines (should use \n)
2025-12-15 09:11:32,469 - INFO - Part 12: Parsed successfully - is_last=False, rows=28
2025-12-15 09:11:32,472 - INFO - ✓ Saved part 12 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_12.json
2025-12-15 09:11:32,472 - INFO - Part 12: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_12.json (not displayed to user)
2025-12-15 09:11:32,472 - INFO - Part 12: Added 28 rows (total: 240)
2025-12-15 09:11:32,472 - INFO - Part 12: is_last=false, continuing to next part...
2025-12-15 09:11:32,473 - INFO - Waiting 10.6s before next part...
2025-12-15 09:11:43,091 - INFO - === Processing Part 13 ===
2025-12-15 09:11:51,700 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:11:51,701 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:11:51,702 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:11:51,703 - INFO - Using max_output_tokens: 32768
2025-12-15 09:11:51,703 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:11:51,704 - INFO - Sending prompt (length: 2594 characters)
2025-12-15 09:11:51,706 - INFO - Max output tokens: 32768
2025-12-15 09:11:51,707 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:11:51,707 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:11:51,708 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:12:53,963 - INFO - ✓ Request completed: 16347 characters received
2025-12-15 09:12:53,965 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:12:53,966 - INFO - ✓ Response completed normally
2025-12-15 09:12:53,969 - INFO - Part 13: Parsed successfully - is_last=False, rows=17
2025-12-15 09:12:53,974 - INFO - ✓ Saved part 13 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_13.json
2025-12-15 09:12:53,974 - INFO - Part 13: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_13.json (not displayed to user)
2025-12-15 09:12:53,975 - INFO - Part 13: Added 17 rows (total: 257)
2025-12-15 09:12:53,976 - INFO - Part 13: is_last=false, continuing to next part...
2025-12-15 09:12:53,979 - INFO - Waiting 8.5s before next part...
2025-12-15 09:13:02,460 - INFO - === Processing Part 14 ===
2025-12-15 09:13:11,716 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:13:11,717 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:13:11,718 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:13:11,718 - INFO - Using max_output_tokens: 32768
2025-12-15 09:13:11,718 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:13:11,719 - INFO - Sending prompt (length: 2594 characters)
2025-12-15 09:13:11,719 - INFO - Max output tokens: 32768
2025-12-15 09:13:11,719 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:13:11,719 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:13:11,719 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:14:10,249 - INFO - ✓ Request completed: 18286 characters received
2025-12-15 09:14:10,250 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:14:10,251 - INFO - ✓ Response completed normally
2025-12-15 09:14:10,254 - INFO - Part 14: Parsed successfully - is_last=False, rows=14
2025-12-15 09:14:10,258 - INFO - ✓ Saved part 14 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_14.json
2025-12-15 09:14:10,259 - INFO - Part 14: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_14.json (not displayed to user)
2025-12-15 09:14:10,259 - INFO - Part 14: Added 14 rows (total: 271)
2025-12-15 09:14:10,260 - INFO - Part 14: is_last=false, continuing to next part...
2025-12-15 09:14:10,262 - INFO - Waiting 8.1s before next part...
2025-12-15 09:14:18,347 - INFO - === Processing Part 15 ===
2025-12-15 09:14:27,728 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:14:27,729 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:14:27,730 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:14:27,731 - INFO - Using max_output_tokens: 32768
2025-12-15 09:14:27,731 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:14:27,732 - INFO - Sending prompt (length: 2594 characters)
2025-12-15 09:14:27,733 - INFO - Max output tokens: 32768
2025-12-15 09:14:27,733 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:14:27,734 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:14:27,735 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:16:00,544 - INFO - ✓ Request completed: 26543 characters received
2025-12-15 09:16:00,544 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:16:00,544 - INFO - ✓ Response completed normally
2025-12-15 09:16:00,545 - WARNING - Part 15, row 11: Extraction contains newlines (should use \n)
2025-12-15 09:16:00,545 - WARNING - Part 15, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:16:00,545 - WARNING - Part 15, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:16:00,545 - WARNING - Part 15, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:16:00,545 - WARNING - Part 15, row 15: Extraction contains newlines (should use \n)
2025-12-15 09:16:00,545 - WARNING - Part 15, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:16:00,545 - WARNING - Part 15, row 11: Extraction contains newlines (should use \n)
2025-12-15 09:16:00,546 - WARNING - Part 15, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:16:00,546 - WARNING - Part 15, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:16:00,546 - WARNING - Part 15, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:16:00,546 - WARNING - Part 15, row 15: Extraction contains newlines (should use \n)
2025-12-15 09:16:00,546 - WARNING - Part 15, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:16:00,546 - INFO - Part 15: Parsed successfully - is_last=False, rows=18
2025-12-15 09:16:00,547 - INFO - ✓ Saved part 15 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_15.json
2025-12-15 09:16:00,547 - INFO - Part 15: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_15.json (not displayed to user)
2025-12-15 09:16:00,548 - INFO - Part 15: Added 18 rows (total: 289)
2025-12-15 09:16:00,548 - INFO - Part 15: is_last=false, continuing to next part...
2025-12-15 09:16:00,548 - INFO - Waiting 8.4s before next part...
2025-12-15 09:16:08,935 - INFO - === Processing Part 16 ===
2025-12-15 09:16:21,413 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:16:21,414 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:16:21,414 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:16:21,415 - INFO - Using max_output_tokens: 32768
2025-12-15 09:16:21,415 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:16:21,415 - INFO - Sending prompt (length: 2594 characters)
2025-12-15 09:16:21,416 - INFO - Max output tokens: 32768
2025-12-15 09:16:21,416 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:16:21,417 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:16:21,417 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:17:30,649 - INFO - ✓ Request completed: 11954 characters received
2025-12-15 09:17:30,650 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:17:30,650 - INFO - ✓ Response completed normally
2025-12-15 09:17:30,652 - INFO - Part 16: Parsed successfully - is_last=True, rows=19
2025-12-15 09:17:30,654 - INFO - ✓ Saved part 16 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_16.json
2025-12-15 09:17:30,655 - INFO - Part 16: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_16.json (not displayed to user)
2025-12-15 09:17:30,656 - INFO - Part 16: Added 19 rows (total: 308)
2025-12-15 09:17:30,656 - INFO - Part 16: is_last=true, processing complete!
2025-12-15 09:17:30,658 - INFO - === Processing Summary ===
2025-12-15 09:17:30,659 - INFO - Total parts processed: 15
2025-12-15 09:17:30,660 - INFO - Total rows collected: 308
2025-12-15 09:17:30,660 - INFO - Deduplicating 308 rows...
2025-12-15 09:17:30,672 - WARNING - Removed 47 duplicate rows
2025-12-15 09:17:30,672 - INFO - Final row count after deduplication: 261
2025-12-15 09:17:30,685 - INFO - ✓ Final output saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/final_output.json
2025-12-15 09:17:30,685 - INFO -   - Total parts: 15
2025-12-15 09:17:30,685 - INFO -   - Total rows: 261
2025-12-15 09:23:53,974 - INFO - Loaded 6 predefined prompts
2025-12-15 09:24:12,484 - INFO - Loaded 3 API keys
2025-12-15 09:24:47,699 - INFO - === Starting PDF Processing ===
2025-12-15 09:24:47,701 - INFO - Model: gemini-2.5-pro
2025-12-15 09:24:47,702 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:24:47,703 - INFO - Full prompt being sent (2527 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple PARTS.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE PART of the final output
- NOT repeat rows from previous parts
- Preserve the exact order of rows across parts

====================
OUTPUT FORMAT (EXACT)
====================
{
  "part_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <our part number>
    }
  ]
}

Rules for rows:
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
PART INSTRUCTIONS
====================
This is PART {part_index} of the output.

Generate ONLY the rows that belong to this part.
Stop when you reach a safe size limit.
If more content remains after this part, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate PART {part_index}.
2025-12-15 09:24:47,708 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7
2025-12-15 09:24:47,709 - INFO - Final output will be saved to PDF directory: /home/mohammadbagher/Downloads/PDFs
2025-12-15 09:24:47,715 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,716 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,716 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,717 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,717 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,718 - WARNING - Part 1, row 9: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,718 - WARNING - Part 1, row 10: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,727 - WARNING - Part 12, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,728 - WARNING - Part 12, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,728 - WARNING - Part 12, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,729 - WARNING - Part 12, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,729 - WARNING - Part 12, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,730 - WARNING - Part 12, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,731 - WARNING - Part 12, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,732 - WARNING - Part 12, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,732 - WARNING - Part 12, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,733 - WARNING - Part 12, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,733 - WARNING - Part 12, row 20: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,734 - WARNING - Part 12, row 22: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,735 - WARNING - Part 12, row 23: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,736 - WARNING - Part 12, row 24: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,736 - WARNING - Part 12, row 25: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,737 - WARNING - Part 12, row 26: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,737 - WARNING - Part 12, row 27: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,742 - WARNING - Part 15, row 11: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,743 - WARNING - Part 15, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,743 - WARNING - Part 15, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,743 - WARNING - Part 15, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,745 - WARNING - Part 15, row 15: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,745 - WARNING - Part 15, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,749 - WARNING - Part 4, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,750 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,750 - WARNING - Part 4, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,750 - WARNING - Part 4, row 9: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,750 - WARNING - Part 4, row 10: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,751 - WARNING - Part 4, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,751 - WARNING - Part 4, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,752 - WARNING - Part 5, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,752 - WARNING - Part 5, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,753 - WARNING - Part 5, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,753 - WARNING - Part 5, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,753 - WARNING - Part 5, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,753 - WARNING - Part 5, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,753 - WARNING - Part 5, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,753 - WARNING - Part 5, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,753 - WARNING - Part 5, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,754 - WARNING - Part 5, row 26: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,754 - WARNING - Part 5, row 27: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,754 - WARNING - Part 5, row 28: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,754 - WARNING - Part 5, row 29: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,755 - WARNING - Part 7, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,756 - WARNING - Part 7, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,756 - WARNING - Part 7, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,756 - WARNING - Part 7, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,756 - WARNING - Part 7, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,756 - WARNING - Part 7, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,756 - WARNING - Part 7, row 19: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,757 - WARNING - Part 7, row 22: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,757 - WARNING - Part 7, row 23: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,758 - WARNING - Part 8, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,758 - WARNING - Part 8, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,758 - WARNING - Part 8, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,758 - WARNING - Part 8, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,758 - WARNING - Part 8, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,758 - WARNING - Part 8, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,758 - WARNING - Part 8, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,758 - WARNING - Part 8, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,759 - WARNING - Part 8, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,759 - WARNING - Part 8, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,759 - WARNING - Part 9, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,760 - WARNING - Part 9, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,760 - WARNING - Part 9, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,760 - WARNING - Part 9, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,760 - WARNING - Part 9, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,760 - WARNING - Part 9, row 9: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,760 - WARNING - Part 9, row 13: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,761 - WARNING - Part 9, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,762 - WARNING - Part 9, row 15: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,763 - WARNING - Part 9, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,763 - WARNING - Part 9, row 19: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,763 - WARNING - Part 9, row 21: Extraction contains newlines (should use \n)
2025-12-15 09:24:47,763 - INFO - Resuming from part 17 (found 16 completed parts)
2025-12-15 09:24:47,765 - INFO - Loaded part 1: 14 rows
2025-12-15 09:24:47,766 - INFO - Loaded part 2: 17 rows
2025-12-15 09:24:47,767 - INFO - Loaded part 3: 12 rows
2025-12-15 09:24:47,768 - INFO - Loaded part 4: 15 rows
2025-12-15 09:24:47,770 - INFO - Loaded part 5: 30 rows
2025-12-15 09:24:47,771 - INFO - Loaded part 6: 10 rows
2025-12-15 09:24:47,771 - INFO - Loaded part 7: 25 rows
2025-12-15 09:24:47,772 - INFO - Loaded part 8: 19 rows
2025-12-15 09:24:47,772 - INFO - Loaded part 9: 22 rows
2025-12-15 09:24:47,773 - INFO - Loaded part 10: 33 rows
2025-12-15 09:24:47,774 - INFO - Loaded part 11: 15 rows
2025-12-15 09:24:47,775 - INFO - Loaded part 12: 28 rows
2025-12-15 09:24:47,776 - INFO - Loaded part 13: 17 rows
2025-12-15 09:24:47,777 - INFO - Loaded part 14: 14 rows
2025-12-15 09:24:47,778 - INFO - Loaded part 15: 18 rows
2025-12-15 09:24:47,778 - INFO - Loaded part 16: 19 rows
2025-12-15 09:24:47,778 - INFO - === Processing Part 17 ===
2025-12-15 09:24:59,477 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:24:59,478 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:24:59,478 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:24:59,479 - INFO - Using max_output_tokens: 32768
2025-12-15 09:24:59,479 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:24:59,480 - INFO - Sending prompt (length: 2676 characters)
2025-12-15 09:24:59,480 - INFO - Max output tokens: 32768
2025-12-15 09:24:59,481 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:24:59,481 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:24:59,482 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:26:33,681 - INFO - ✓ Request completed: 24472 characters received
2025-12-15 09:26:33,681 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:26:33,682 - INFO - ✓ Response completed normally
2025-12-15 09:26:33,683 - INFO - Part 17: Parsed successfully - is_last=False, rows=15
2025-12-15 09:26:33,683 - WARNING - Part 17: Reached maximum part limit (4). Forcing is_last=true.
2025-12-15 09:26:33,685 - INFO - ✓ Saved part 17 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_17.json
2025-12-15 09:26:33,685 - INFO - Part 17: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_17.json (not displayed to user)
2025-12-15 09:26:33,685 - INFO - Part 17: Added 15 rows (total: 323)
2025-12-15 09:26:33,685 - INFO - Part 17: is_last=true, processing complete!
2025-12-15 09:26:33,686 - ERROR - ERROR: No parts were processed! Started at 17, ended at 17
2025-12-15 09:26:33,686 - ERROR - Multi-part processing returned no final output file
2025-12-15 09:30:34,110 - INFO - Loaded 6 predefined prompts
2025-12-15 09:31:03,488 - INFO - Loaded 3 API keys
2025-12-15 09:31:39,655 - INFO - === Starting PDF Processing ===
2025-12-15 09:31:39,656 - INFO - Model: gemini-2.5-pro
2025-12-15 09:31:39,657 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:31:39,658 - INFO - Full prompt being sent (2527 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple PARTS.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE PART of the final output
- NOT repeat rows from previous parts
- Preserve the exact order of rows across parts

====================
OUTPUT FORMAT (EXACT)
====================
{
  "part_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <our part number>
    }
  ]
}

Rules for rows:
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
PART INSTRUCTIONS
====================
This is PART {part_index} of the output.

Generate ONLY the rows that belong to this part.
Stop when you reach a safe size limit.
If more content remains after this part, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate PART {part_index}.
2025-12-15 09:31:39,663 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7
2025-12-15 09:31:39,665 - INFO - Final output will be saved to PDF directory: /home/mohammadbagher/Downloads/PDFs
2025-12-15 09:31:39,668 - INFO - No previous parts found, starting from part 1
2025-12-15 09:31:39,669 - INFO - === Processing Part 1 ===
2025-12-15 09:31:51,288 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:31:51,289 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:31:51,290 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:31:51,290 - INFO - Using max_output_tokens: 32768
2025-12-15 09:31:51,291 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:31:51,291 - INFO - Sending prompt (length: 2647 characters)
2025-12-15 09:31:51,292 - INFO - Max output tokens: 32768
2025-12-15 09:31:51,293 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:31:51,294 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:31:51,294 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:33:13,836 - INFO - ✓ Request completed: 30153 characters received
2025-12-15 09:33:13,837 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:33:13,838 - INFO - ✓ Response completed normally
2025-12-15 09:33:13,842 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,843 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,843 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,844 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,844 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,845 - WARNING - Part 1, row 9: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,845 - WARNING - Part 1, row 10: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,846 - WARNING - Part 1, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,846 - WARNING - Part 1, row 16: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,847 - WARNING - Part 1, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,847 - WARNING - Part 1, row 19: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,848 - WARNING - Part 1, row 20: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,848 - WARNING - Part 1, row 23: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,849 - WARNING - Part 1, row 25: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,849 - WARNING - Part 1, row 26: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,849 - WARNING - Part 1, row 27: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,850 - WARNING - Part 1, row 31: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,850 - WARNING - Part 1, row 32: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,851 - WARNING - Part 1, row 33: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,851 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,852 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,852 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,854 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,854 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,855 - WARNING - Part 1, row 9: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,855 - WARNING - Part 1, row 10: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,856 - WARNING - Part 1, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,857 - WARNING - Part 1, row 16: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,857 - WARNING - Part 1, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,858 - WARNING - Part 1, row 19: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,858 - WARNING - Part 1, row 20: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,859 - WARNING - Part 1, row 23: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,859 - WARNING - Part 1, row 25: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,860 - WARNING - Part 1, row 26: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,861 - WARNING - Part 1, row 27: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,861 - WARNING - Part 1, row 31: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,862 - WARNING - Part 1, row 32: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,862 - WARNING - Part 1, row 33: Extraction contains newlines (should use \n)
2025-12-15 09:33:13,863 - INFO - Part 1: Parsed successfully - is_last=False, rows=34
2025-12-15 09:33:13,870 - INFO - ✓ Saved part 1 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_1.json
2025-12-15 09:33:13,871 - INFO - Part 1: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_1.json (not displayed to user)
2025-12-15 09:33:13,871 - INFO - Part 1: Added 34 rows (total: 34)
2025-12-15 09:33:13,872 - INFO - Part 1: is_last=false, continuing to next part...
2025-12-15 09:33:13,874 - INFO - Waiting 8.6s before next part...
2025-12-15 09:33:22,523 - INFO - === Processing Part 2 ===
2025-12-15 09:33:33,721 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:33:33,722 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:33:33,723 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:33:33,723 - INFO - Using max_output_tokens: 32768
2025-12-15 09:33:33,724 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:33:33,724 - INFO - Sending prompt (length: 2674 characters)
2025-12-15 09:33:33,725 - INFO - Max output tokens: 32768
2025-12-15 09:33:33,725 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:33:33,726 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:33:33,726 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:34:43,832 - INFO - ✓ Request completed: 23554 characters received
2025-12-15 09:34:43,835 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:34:43,837 - INFO - ✓ Response completed normally
2025-12-15 09:34:43,843 - INFO - Part 2: Parsed successfully - is_last=False, rows=15
2025-12-15 09:34:43,851 - INFO - ✓ Saved part 2 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_2.json
2025-12-15 09:34:43,852 - INFO - Part 2: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_2.json (not displayed to user)
2025-12-15 09:34:43,852 - INFO - Part 2: Added 15 rows (total: 49)
2025-12-15 09:34:43,853 - INFO - Part 2: is_last=false, continuing to next part...
2025-12-15 09:34:43,855 - INFO - Waiting 12.3s before next part...
2025-12-15 09:34:56,195 - INFO - === Processing Part 3 ===
2025-12-15 09:35:07,371 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:35:07,372 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:35:07,372 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:35:07,373 - INFO - Using max_output_tokens: 32768
2025-12-15 09:35:07,373 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:35:07,373 - INFO - Sending prompt (length: 2674 characters)
2025-12-15 09:35:07,373 - INFO - Max output tokens: 32768
2025-12-15 09:35:07,373 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:35:07,374 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:35:07,374 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:36:24,504 - INFO - ✓ Request completed: 26083 characters received
2025-12-15 09:36:24,505 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:36:24,506 - INFO - ✓ Response completed normally
2025-12-15 09:36:24,509 - INFO - Part 3: Parsed successfully - is_last=False, rows=14
2025-12-15 09:36:24,514 - INFO - ✓ Saved part 3 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_3.json
2025-12-15 09:36:24,515 - INFO - Part 3: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_3.json (not displayed to user)
2025-12-15 09:36:24,515 - INFO - Part 3: Added 14 rows (total: 63)
2025-12-15 09:36:24,516 - INFO - Part 3: is_last=false, continuing to next part...
2025-12-15 09:36:24,517 - INFO - Waiting 12.8s before next part...
2025-12-15 09:36:37,334 - INFO - === Processing Part 4 ===
2025-12-15 09:36:49,784 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:36:49,784 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:36:49,784 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:36:49,784 - INFO - Using max_output_tokens: 32768
2025-12-15 09:36:49,784 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:36:49,784 - INFO - Sending prompt (length: 2674 characters)
2025-12-15 09:36:49,784 - INFO - Max output tokens: 32768
2025-12-15 09:36:49,784 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:36:49,785 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:36:49,785 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:40:32,165 - INFO - ✓ Request completed: 71872 characters received
2025-12-15 09:40:32,166 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:40:32,166 - INFO - ✓ Response completed normally
2025-12-15 09:40:32,170 - INFO - Part 4: Parsed successfully - is_last=True, rows=81
2025-12-15 09:40:32,174 - INFO - ✓ Saved part 4 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_4.json
2025-12-15 09:40:32,175 - INFO - Part 4: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_4.json (not displayed to user)
2025-12-15 09:40:32,175 - INFO - Part 4: Added 81 rows (total: 144)
2025-12-15 09:40:32,175 - INFO - Part 4: is_last=true, processing complete!
2025-12-15 09:40:32,176 - INFO - === Processing Summary ===
2025-12-15 09:40:32,176 - INFO - New parts processed in this run: 3
2025-12-15 09:40:32,176 - INFO - Previous parts loaded (resume): 0
2025-12-15 09:40:32,176 - INFO - Total rows collected: 144
2025-12-15 09:40:32,176 - INFO - Deduplicating 144 rows...
2025-12-15 09:40:32,182 - WARNING - Removed 15 duplicate rows using enhanced deduplication
2025-12-15 09:40:32,182 - INFO - Final row count after deduplication: 129
2025-12-15 09:40:32,188 - INFO - ✓ Final output saved to /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-15 09:40:32,188 - INFO -   - File path: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-15 09:40:32,188 - ERROR - Failed to save final output: name 'total_parts_count' is not defined
Traceback (most recent call last):
  File "/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/multi_part_processor.py", line 716, in process_multi_part
    self.logger.info(f"  - Total parts: {total_parts_count} ({total_parts_in_final} previous + {total_parts_processed} new)")
                                         ^^^^^^^^^^^^^^^^^
NameError: name 'total_parts_count' is not defined
2025-12-15 09:40:32,190 - ERROR - Multi-part processing returned no final output file
2025-12-15 09:43:07,969 - INFO - Loaded 6 predefined prompts
2025-12-15 09:43:44,911 - INFO - Loaded 3 API keys
2025-12-15 09:44:54,564 - INFO - === Starting PDF Processing ===
2025-12-15 09:44:54,564 - INFO - Model: gemini-2.5-pro
2025-12-15 09:44:54,564 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:44:54,565 - INFO - Full prompt being sent (2527 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple PARTS.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE PART of the final output
- NOT repeat rows from previous parts
- Preserve the exact order of rows across parts

====================
OUTPUT FORMAT (EXACT)
====================
{
  "part_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <our part number>
    }
  ]
}

Rules for rows:
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
PART INSTRUCTIONS
====================
This is PART {part_index} of the output.

Generate ONLY the rows that belong to this part.
Stop when you reach a safe size limit.
If more content remains after this part, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate PART {part_index}.
2025-12-15 09:44:54,566 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7
2025-12-15 09:44:54,567 - INFO - Final output will be saved to PDF directory: /home/mohammadbagher/Downloads/PDFs
2025-12-15 09:44:54,567 - INFO - No previous parts found, starting from part 1
2025-12-15 09:44:54,567 - INFO - === Processing Part 1 ===
2025-12-15 09:45:06,022 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:45:06,024 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:45:06,025 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:45:06,026 - INFO - Using max_output_tokens: 32768
2025-12-15 09:45:06,027 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:45:06,029 - INFO - Sending prompt (length: 2647 characters)
2025-12-15 09:45:06,030 - INFO - Max output tokens: 32768
2025-12-15 09:45:06,030 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:45:06,031 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:45:06,032 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:46:50,692 - INFO - ✓ Request completed: 36139 characters received
2025-12-15 09:46:50,694 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:46:50,695 - INFO - ✓ Response completed normally
2025-12-15 09:46:50,699 - WARNING - Part 1, row 0: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,700 - WARNING - Part 1, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,700 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,701 - WARNING - Part 1, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,701 - WARNING - Part 1, row 4: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,701 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,702 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,702 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,703 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,703 - WARNING - Part 1, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,703 - WARNING - Part 1, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,704 - WARNING - Part 1, row 15: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,704 - WARNING - Part 1, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,705 - WARNING - Part 1, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,705 - WARNING - Part 1, row 21: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,705 - WARNING - Part 1, row 23: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,706 - WARNING - Part 1, row 24: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,706 - WARNING - Part 1, row 25: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,707 - WARNING - Part 1, row 29: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,707 - WARNING - Part 1, row 30: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,707 - WARNING - Part 1, row 31: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,708 - WARNING - Part 1, row 35: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,708 - WARNING - Part 1, row 36: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,709 - WARNING - Part 1, row 0: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,709 - WARNING - Part 1, row 1: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,709 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,710 - WARNING - Part 1, row 3: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,710 - WARNING - Part 1, row 4: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,711 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,711 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,711 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,712 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,712 - WARNING - Part 1, row 12: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,712 - WARNING - Part 1, row 14: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,713 - WARNING - Part 1, row 15: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,713 - WARNING - Part 1, row 17: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,714 - WARNING - Part 1, row 18: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,714 - WARNING - Part 1, row 21: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,715 - WARNING - Part 1, row 23: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,715 - WARNING - Part 1, row 24: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,715 - WARNING - Part 1, row 25: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,716 - WARNING - Part 1, row 29: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,716 - WARNING - Part 1, row 30: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,717 - WARNING - Part 1, row 31: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,717 - WARNING - Part 1, row 35: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,717 - WARNING - Part 1, row 36: Extraction contains newlines (should use \n)
2025-12-15 09:46:50,718 - INFO - Part 1: Parsed successfully - is_last=False, rows=37
2025-12-15 09:46:50,725 - INFO - ✓ Saved part 1 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_1.json
2025-12-15 09:46:50,726 - INFO - Part 1: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_1.json (not displayed to user)
2025-12-15 09:46:50,727 - INFO - Part 1: Added 37 rows (total: 37)
2025-12-15 09:46:50,727 - INFO - Part 1: is_last=false, continuing to next part...
2025-12-15 09:46:50,729 - INFO - Waiting 13.9s before next part...
2025-12-15 09:47:04,598 - INFO - === Processing Part 2 ===
2025-12-15 09:47:15,018 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:47:15,019 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:47:15,020 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:47:15,020 - INFO - Using max_output_tokens: 32768
2025-12-15 09:47:15,021 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:47:15,022 - INFO - Sending prompt (length: 2674 characters)
2025-12-15 09:47:15,022 - INFO - Max output tokens: 32768
2025-12-15 09:47:15,024 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:47:15,025 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:47:15,025 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:48:26,362 - INFO - ✓ Request completed: 24485 characters received
2025-12-15 09:48:26,363 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:48:26,364 - INFO - ✓ Response completed normally
2025-12-15 09:48:26,367 - INFO - Part 2: Parsed successfully - is_last=False, rows=15
2025-12-15 09:48:26,372 - INFO - ✓ Saved part 2 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_2.json
2025-12-15 09:48:26,373 - INFO - Part 2: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_2.json (not displayed to user)
2025-12-15 09:48:26,374 - INFO - Part 2: Added 15 rows (total: 52)
2025-12-15 09:48:26,374 - INFO - Part 2: is_last=false, continuing to next part...
2025-12-15 09:48:26,376 - INFO - Waiting 12.3s before next part...
2025-12-15 09:48:38,717 - INFO - === Processing Part 3 ===
2025-12-15 09:48:48,815 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:48:48,815 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:48:48,815 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:48:48,815 - INFO - Using max_output_tokens: 32768
2025-12-15 09:48:48,815 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:48:48,816 - INFO - Sending prompt (length: 2674 characters)
2025-12-15 09:48:48,816 - INFO - Max output tokens: 32768
2025-12-15 09:48:48,816 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:48:48,816 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:48:48,817 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:50:10,236 - INFO - ✓ Request completed: 18347 characters received
2025-12-15 09:50:10,237 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:50:10,238 - INFO - ✓ Response completed normally
2025-12-15 09:50:10,241 - WARNING - Part 3, row 0: Extraction contains newlines (should use \n)
2025-12-15 09:50:10,241 - WARNING - Part 3, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:50:10,242 - WARNING - Part 3, row 5: Extraction contains newlines (should use \n)
2025-12-15 09:50:10,242 - WARNING - Part 3, row 0: Extraction contains newlines (should use \n)
2025-12-15 09:50:10,243 - WARNING - Part 3, row 2: Extraction contains newlines (should use \n)
2025-12-15 09:50:10,243 - WARNING - Part 3, row 5: Extraction contains newlines (should use \n)
2025-12-15 09:50:10,244 - INFO - Part 3: Parsed successfully - is_last=False, rows=7
2025-12-15 09:50:10,247 - INFO - ✓ Saved part 3 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_3.json
2025-12-15 09:50:10,248 - INFO - Part 3: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_3.json (not displayed to user)
2025-12-15 09:50:10,248 - INFO - Part 3: Added 7 rows (total: 59)
2025-12-15 09:50:10,250 - INFO - Part 3: is_last=false, continuing to next part...
2025-12-15 09:50:10,254 - INFO - Waiting 10.4s before next part...
2025-12-15 09:50:20,673 - INFO - === Processing Part 4 ===
2025-12-15 09:50:30,685 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 09:50:30,686 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 09:50:30,686 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 09:50:30,687 - INFO - Using max_output_tokens: 32768
2025-12-15 09:50:30,688 - INFO - Using model: gemini-2.5-pro
2025-12-15 09:50:30,688 - INFO - Sending prompt (length: 2674 characters)
2025-12-15 09:50:30,689 - INFO - Max output tokens: 32768
2025-12-15 09:50:30,689 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 09:50:30,690 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 09:50:30,690 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 09:53:24,026 - INFO - ✓ Request completed: 70075 characters received
2025-12-15 09:53:24,026 - INFO - Finish reason: STOP (normal completion)
2025-12-15 09:53:24,026 - INFO - ✓ Response completed normally
2025-12-15 09:53:24,028 - INFO - Part 4: Parsed successfully - is_last=True, rows=104
2025-12-15 09:53:24,031 - INFO - ✓ Saved part 4 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_4.json
2025-12-15 09:53:24,031 - INFO - Part 4: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_bd8375b7/part_4.json (not displayed to user)
2025-12-15 09:53:24,032 - INFO - Part 4: Added 104 rows (total: 163)
2025-12-15 09:53:24,032 - INFO - Part 4: is_last=true, processing complete!
2025-12-15 09:53:24,032 - INFO - === Processing Summary ===
2025-12-15 09:53:24,033 - INFO - New parts processed in this run: 3
2025-12-15 09:53:24,033 - INFO - Previous parts loaded (resume): 0
2025-12-15 09:53:24,034 - INFO - Total parts in final output: 3
2025-12-15 09:53:24,034 - INFO - Total rows collected: 163
2025-12-15 09:53:24,034 - INFO - Deduplicating 163 rows...
2025-12-15 09:53:24,041 - WARNING - Removed 1 duplicate rows using enhanced deduplication
2025-12-15 09:53:24,041 - INFO - Final row count after deduplication: 162
2025-12-15 09:53:24,049 - INFO - ✓ Final output saved to /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-15 09:53:24,049 - INFO -   - File path: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-15 09:53:24,050 - INFO -   - Total parts: 3 (0 previous + 3 new)
2025-12-15 09:53:24,050 - INFO -   - Total rows: 162
2025-12-15 09:53:24,050 - INFO -   - File size: 146.70 KB
2025-12-15 10:17:13,767 - INFO - Loaded 6 predefined prompts
2025-12-15 10:21:42,996 - INFO - Loaded 6 predefined prompts
2025-12-15 10:28:32,225 - INFO - Loaded 6 predefined prompts
2025-12-15 10:28:51,815 - INFO - Loaded 3 API keys
2025-12-15 10:29:33,771 - INFO - === Starting PDF Processing ===
2025-12-15 10:29:33,771 - INFO - Model: gemini-2.5-pro
2025-12-15 10:29:33,772 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:29:33,772 - INFO - Full prompt being sent (4078 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple PARTS.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE PART of the final output
- NOT repeat rows from previous parts
- Preserve the exact order of rows across parts

====================
OUTPUT FORMAT (EXACT)
====================
{
  "part_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part.>
    }
  ]
}

Rules for rows:
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
PART INSTRUCTIONS
====================
This is PART {part_index} of the output.

Generate ONLY the rows that belong to this part.
Stop when you reach a safe size limit.
If more content remains after this part, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate PART {part_index}.
2025-12-15 10:29:33,774 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa
2025-12-15 10:29:33,774 - INFO - Final output will be saved to PDF directory: /home/mohammadbagher/Downloads/PDFs
2025-12-15 10:29:33,775 - INFO - No previous parts found, starting from part 1
2025-12-15 10:29:33,775 - INFO - === Processing Part 1 ===
2025-12-15 10:29:43,097 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:29:43,097 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:29:43,097 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:29:43,097 - INFO - Using max_output_tokens: 32768
2025-12-15 10:29:43,097 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:29:43,098 - INFO - Sending prompt (length: 4109 characters)
2025-12-15 10:29:43,098 - INFO - Max output tokens: 32768
2025-12-15 10:29:43,098 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:29:43,098 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:29:43,098 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:30:41,171 - INFO - ✓ Request completed: 13702 characters received
2025-12-15 10:30:41,173 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:30:41,174 - INFO - ✓ Response completed normally
2025-12-15 10:30:41,177 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 10:30:41,177 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 10:30:41,178 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 10:30:41,178 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 10:30:41,179 - INFO - Part 1: Parsed successfully - is_last=False, rows=11
2025-12-15 10:30:41,182 - INFO - ✓ Saved part 1 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_1.json
2025-12-15 10:30:41,183 - INFO - Part 1: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_1.json (not displayed to user)
2025-12-15 10:30:41,183 - INFO - Part 1: Added 11 rows (total: 11)
2025-12-15 10:30:41,184 - INFO - Part 1: is_last=false, continuing to next part...
2025-12-15 10:30:41,185 - INFO - Waiting 11.2s before next part...
2025-12-15 10:30:52,422 - INFO - === Processing Part 2 ===
2025-12-15 10:31:01,474 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:31:01,474 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:31:01,479 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:31:01,479 - INFO - Using max_output_tokens: 32768
2025-12-15 10:31:01,480 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:31:01,480 - INFO - Sending prompt (length: 4143 characters)
2025-12-15 10:31:01,481 - INFO - Max output tokens: 32768
2025-12-15 10:31:01,481 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:31:01,483 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:31:01,485 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:32:33,557 - INFO - ✓ Request completed: 22351 characters received
2025-12-15 10:32:33,559 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:32:33,559 - INFO - ✓ Response completed normally
2025-12-15 10:32:33,562 - INFO - Part 2: Parsed successfully - is_last=False, rows=14
2025-12-15 10:32:33,567 - INFO - ✓ Saved part 2 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_2.json
2025-12-15 10:32:33,568 - INFO - Part 2: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_2.json (not displayed to user)
2025-12-15 10:32:33,568 - INFO - Part 2: Added 14 rows (total: 25)
2025-12-15 10:32:33,569 - INFO - Part 2: is_last=false, continuing to next part...
2025-12-15 10:32:33,571 - INFO - Waiting 8.8s before next part...
2025-12-15 10:32:42,404 - INFO - === Processing Part 3 ===
2025-12-15 10:32:50,951 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:32:50,951 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:32:50,952 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:32:50,953 - INFO - Using max_output_tokens: 32768
2025-12-15 10:32:50,953 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:32:50,954 - INFO - Sending prompt (length: 4143 characters)
2025-12-15 10:32:50,954 - INFO - Max output tokens: 32768
2025-12-15 10:32:50,954 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:32:50,955 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:32:50,955 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:34:30,100 - INFO - ✓ Request completed: 26706 characters received
2025-12-15 10:34:30,100 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:34:30,104 - INFO - ✓ Response completed normally
2025-12-15 10:34:30,106 - INFO - Part 3: Parsed successfully - is_last=False, rows=10
2025-12-15 10:34:30,109 - INFO - ✓ Saved part 3 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_3.json
2025-12-15 10:34:30,110 - INFO - Part 3: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_3.json (not displayed to user)
2025-12-15 10:34:30,110 - INFO - Part 3: Added 10 rows (total: 35)
2025-12-15 10:34:30,110 - INFO - Part 3: is_last=false, continuing to next part...
2025-12-15 10:34:30,111 - INFO - Waiting 14.8s before next part...
2025-12-15 10:34:44,958 - INFO - === Processing Part 4 ===
2025-12-15 10:34:57,647 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:34:57,648 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:34:57,649 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:34:57,649 - INFO - Using max_output_tokens: 32768
2025-12-15 10:34:57,650 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:34:57,650 - INFO - Sending prompt (length: 4143 characters)
2025-12-15 10:34:57,651 - INFO - Max output tokens: 32768
2025-12-15 10:34:57,651 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:34:57,652 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:34:57,652 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:37:01,774 - INFO - ✓ Request completed: 18263 characters received
2025-12-15 10:37:01,774 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:37:01,774 - INFO - ✓ Response completed normally
2025-12-15 10:37:01,775 - INFO - Part 4: Parsed successfully - is_last=False, rows=7
2025-12-15 10:37:01,776 - INFO - ✓ Saved part 4 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_4.json
2025-12-15 10:37:01,776 - INFO - Part 4: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_4.json (not displayed to user)
2025-12-15 10:37:01,776 - INFO - Part 4: Added 7 rows (total: 42)
2025-12-15 10:37:01,776 - INFO - Part 4: is_last=false, continuing to next part...
2025-12-15 10:37:01,776 - INFO - Waiting 14.5s before next part...
2025-12-15 10:37:16,230 - INFO - === Processing Part 5 ===
2025-12-15 10:37:25,290 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:37:25,290 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:37:25,290 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:37:25,290 - INFO - Using max_output_tokens: 32768
2025-12-15 10:37:25,290 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:37:25,291 - INFO - Sending prompt (length: 4143 characters)
2025-12-15 10:37:25,291 - INFO - Max output tokens: 32768
2025-12-15 10:37:25,291 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:37:25,291 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:37:25,291 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:38:54,315 - INFO - ✓ Request completed: 19104 characters received
2025-12-15 10:38:54,315 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:38:54,316 - INFO - ✓ Response completed normally
2025-12-15 10:38:54,317 - WARNING - Part 5, row 2: Extraction contains newlines (should use \n)
2025-12-15 10:38:54,317 - WARNING - Part 5, row 3: Extraction contains newlines (should use \n)
2025-12-15 10:38:54,318 - WARNING - Part 5, row 4: Extraction contains newlines (should use \n)
2025-12-15 10:38:54,318 - WARNING - Part 5, row 6: Extraction contains newlines (should use \n)
2025-12-15 10:38:54,318 - WARNING - Part 5, row 2: Extraction contains newlines (should use \n)
2025-12-15 10:38:54,318 - WARNING - Part 5, row 3: Extraction contains newlines (should use \n)
2025-12-15 10:38:54,319 - WARNING - Part 5, row 4: Extraction contains newlines (should use \n)
2025-12-15 10:38:54,319 - WARNING - Part 5, row 6: Extraction contains newlines (should use \n)
2025-12-15 10:38:54,319 - INFO - Part 5: Parsed successfully - is_last=False, rows=9
2025-12-15 10:38:54,321 - INFO - ✓ Saved part 5 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_5.json
2025-12-15 10:38:54,321 - INFO - Part 5: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_5.json (not displayed to user)
2025-12-15 10:38:54,322 - INFO - Part 5: Added 9 rows (total: 51)
2025-12-15 10:38:54,322 - INFO - Part 5: is_last=false, continuing to next part...
2025-12-15 10:38:54,323 - INFO - Waiting 11.2s before next part...
2025-12-15 10:39:05,527 - INFO - === Processing Part 6 ===
2025-12-15 10:39:14,960 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:39:14,960 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:39:14,961 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:39:14,961 - INFO - Using max_output_tokens: 32768
2025-12-15 10:39:14,962 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:39:14,962 - INFO - Sending prompt (length: 4143 characters)
2025-12-15 10:39:14,963 - INFO - Max output tokens: 32768
2025-12-15 10:39:14,964 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:39:14,965 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:39:14,965 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:40:19,006 - INFO - ✓ Request completed: 11567 characters received
2025-12-15 10:40:19,007 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:40:19,007 - INFO - ✓ Response completed normally
2025-12-15 10:40:19,008 - WARNING - Part 6, row 0: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,008 - WARNING - Part 6, row 1: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,008 - WARNING - Part 6, row 2: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,009 - WARNING - Part 6, row 4: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,009 - WARNING - Part 6, row 5: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,009 - WARNING - Part 6, row 8: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,009 - WARNING - Part 6, row 9: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,009 - WARNING - Part 6, row 10: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,010 - WARNING - Part 6, row 0: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,010 - WARNING - Part 6, row 1: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,010 - WARNING - Part 6, row 2: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,010 - WARNING - Part 6, row 4: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,011 - WARNING - Part 6, row 5: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,011 - WARNING - Part 6, row 8: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,011 - WARNING - Part 6, row 9: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,011 - WARNING - Part 6, row 10: Extraction contains newlines (should use \n)
2025-12-15 10:40:19,011 - INFO - Part 6: Parsed successfully - is_last=False, rows=14
2025-12-15 10:40:19,013 - INFO - ✓ Saved part 6 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_6.json
2025-12-15 10:40:19,013 - INFO - Part 6: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_6.json (not displayed to user)
2025-12-15 10:40:19,013 - INFO - Part 6: Added 14 rows (total: 65)
2025-12-15 10:40:19,013 - INFO - Part 6: is_last=false, continuing to next part...
2025-12-15 10:40:19,014 - INFO - Waiting 10.7s before next part...
2025-12-15 10:40:29,724 - INFO - === Processing Part 7 ===
2025-12-15 10:40:38,749 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:40:38,749 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:40:38,750 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:40:38,750 - INFO - Using max_output_tokens: 32768
2025-12-15 10:40:38,750 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:40:38,750 - INFO - Sending prompt (length: 4143 characters)
2025-12-15 10:40:38,750 - INFO - Max output tokens: 32768
2025-12-15 10:40:38,750 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:40:38,750 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:40:38,751 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:41:49,355 - INFO - ✓ Request completed: 14046 characters received
2025-12-15 10:41:49,355 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:41:49,355 - INFO - ✓ Response completed normally
2025-12-15 10:41:49,356 - INFO - Part 7: Parsed successfully - is_last=False, rows=2
2025-12-15 10:41:49,358 - INFO - ✓ Saved part 7 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_7.json
2025-12-15 10:41:49,358 - INFO - Part 7: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_7.json (not displayed to user)
2025-12-15 10:41:49,359 - INFO - Part 7: Added 2 rows (total: 67)
2025-12-15 10:41:49,359 - INFO - Part 7: is_last=false, continuing to next part...
2025-12-15 10:41:49,360 - INFO - Waiting 9.7s before next part...
2025-12-15 10:41:59,073 - INFO - === Processing Part 8 ===
2025-12-15 10:42:08,454 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:42:08,454 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:42:08,454 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:42:08,455 - INFO - Using max_output_tokens: 32768
2025-12-15 10:42:08,455 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:42:08,455 - INFO - Sending prompt (length: 4143 characters)
2025-12-15 10:42:08,455 - INFO - Max output tokens: 32768
2025-12-15 10:42:08,455 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:42:08,455 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:42:08,455 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:43:43,196 - INFO - ✓ Request completed: 19800 characters received
2025-12-15 10:43:43,197 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:43:43,197 - INFO - ✓ Response completed normally
2025-12-15 10:43:43,200 - ERROR - Part 8: JSON parse error: Expecting ',' delimiter: line 44 column 20 (char 18462)
2025-12-15 10:43:43,200 - ERROR - Part 8: Response text (first 1000 chars): {
  "part_index": 8,
  "is_last": false,
  "rows": [
    {
      "Type": "page text",
      "Extraction": "be used for mild ocular disease without rapid worsening. Dapsone can be particularly beneficial in patients with linear deposits of IgA at the BMZ. Cyclophosphamide (1-2mg/kg/day) is considered the treatment of choice for rapidly progressive or severe ocular disease 60 – alone, in combination with oral corticosteroids, or as pulse therapy. Such regimens are effective in resolving severe conjunctival inflammation and preventing recurrences and secondary scarring. Azathioprine (2 mg/kg/day) and mycophenolate mofetil (2 g/day) have also been reported to be helpful in reducing the dose of corticosteroids required for control of ocular involvement and cutaneous lesions. Systemic corticosteroids alone are generally insufficient therapy for patients with significant disease, and they are less effective for mucosal than for cutaneous disease. Patients with significant esophageal or laryng
2025-12-15 10:43:43,201 - ERROR - Part 8: Response text (last 500 chars): ,
      "Number": 533.e1,
      "Part": 1
    },
    {
      "Type": "Figure",
      "Extraction": "{\"Caption\": \"eFig. 30.5 Bullous pemphigoid - progression of disease. A Urticarial, infiltrated and annular erythematous plaques on the trunk and upper extremity. B Generalized eruption with blisters as well as numerous erosions and hemorrhagic crusts in the same patient later in the course of the disease.\", \"Panel Labels\": [\"A\", \"B\"]}",
      "Number": 533.e1,
      "Part": 1
    }
  ]
}
2025-12-15 10:43:43,201 - ERROR - Part 8: Failed to parse response
2025-12-15 10:43:43,201 - ERROR - Part 8: Response text (first 1000 chars): ```json
{
  "part_index": 8,
  "is_last": false,
  "rows": [
    {
      "Type": "page text",
      "Extraction": "be used for mild ocular disease without rapid worsening. Dapsone can be particularly beneficial in patients with linear deposits of IgA at the BMZ. Cyclophosphamide (1-2mg/kg/day) is considered the treatment of choice for rapidly progressive or severe ocular disease 60 – alone, in combination with oral corticosteroids, or as pulse therapy. Such regimens are effective in resolving severe conjunctival inflammation and preventing recurrences and secondary scarring. Azathioprine (2 mg/kg/day) and mycophenolate mofetil (2 g/day) have also been reported to be helpful in reducing the dose of corticosteroids required for control of ocular involvement and cutaneous lesions. Systemic corticosteroids alone are generally insufficient therapy for patients with significant disease, and they are less effective for mucosal than for cutaneous disease. Patients with significant esophageal o
2025-12-15 10:43:43,202 - ERROR - Part 8: Retrying same part...
2025-12-15 10:43:48,202 - INFO - === Processing Part 8 ===
2025-12-15 10:43:57,318 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:43:57,319 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:43:57,320 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:43:57,320 - INFO - Using max_output_tokens: 32768
2025-12-15 10:43:57,321 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:43:57,321 - INFO - Sending prompt (length: 4143 characters)
2025-12-15 10:43:57,322 - INFO - Max output tokens: 32768
2025-12-15 10:43:57,322 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:43:57,323 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:43:57,323 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:45:45,757 - INFO - ✓ Request completed: 17855 characters received
2025-12-15 10:45:45,758 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:45:45,758 - INFO - ✓ Response completed normally
2025-12-15 10:45:45,761 - INFO - Part 8: Parsed successfully - is_last=False, rows=6
2025-12-15 10:45:45,763 - INFO - ✓ Saved part 8 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_8.json
2025-12-15 10:45:45,763 - INFO - Part 8: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_8.json (not displayed to user)
2025-12-15 10:45:45,763 - INFO - Part 8: Added 6 rows (total: 73)
2025-12-15 10:45:45,764 - INFO - Part 8: is_last=false, continuing to next part...
2025-12-15 10:45:45,766 - INFO - Waiting 14.3s before next part...
2025-12-15 10:46:00,095 - INFO - === Processing Part 9 ===
2025-12-15 10:46:08,322 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:46:08,323 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:46:08,323 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:46:08,324 - INFO - Using max_output_tokens: 32768
2025-12-15 10:46:08,324 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:46:08,325 - INFO - Sending prompt (length: 4143 characters)
2025-12-15 10:46:08,325 - INFO - Max output tokens: 32768
2025-12-15 10:46:08,325 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:46:08,326 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:46:08,326 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:47:34,277 - INFO - ✓ Request completed: 15740 characters received
2025-12-15 10:47:34,278 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:47:34,279 - INFO - ✓ Response completed normally
2025-12-15 10:47:34,282 - INFO - Part 9: Parsed successfully - is_last=False, rows=8
2025-12-15 10:47:34,285 - INFO - ✓ Saved part 9 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_9.json
2025-12-15 10:47:34,286 - INFO - Part 9: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_9.json (not displayed to user)
2025-12-15 10:47:34,286 - INFO - Part 9: Added 8 rows (total: 81)
2025-12-15 10:47:34,287 - INFO - Part 9: is_last=false, continuing to next part...
2025-12-15 10:47:34,288 - INFO - Waiting 13.0s before next part...
2025-12-15 10:47:47,335 - INFO - === Processing Part 10 ===
2025-12-15 10:47:58,458 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:47:58,458 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:47:58,458 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:47:58,459 - INFO - Using max_output_tokens: 32768
2025-12-15 10:47:58,459 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:47:58,459 - INFO - Sending prompt (length: 4144 characters)
2025-12-15 10:47:58,459 - INFO - Max output tokens: 32768
2025-12-15 10:47:58,459 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:47:58,459 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:47:58,459 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:49:40,398 - INFO - ✓ Request completed: 29706 characters received
2025-12-15 10:49:40,398 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:49:40,398 - INFO - ✓ Response completed normally
2025-12-15 10:49:40,400 - WARNING - Part 10, row 1: Extraction contains newlines (should use \n)
2025-12-15 10:49:40,400 - WARNING - Part 10, row 2: Extraction contains newlines (should use \n)
2025-12-15 10:49:40,400 - WARNING - Part 10, row 4: Extraction contains newlines (should use \n)
2025-12-15 10:49:40,400 - WARNING - Part 10, row 7: Extraction contains newlines (should use \n)
2025-12-15 10:49:40,401 - WARNING - Part 10, row 9: Extraction contains newlines (should use \n)
2025-12-15 10:49:40,401 - WARNING - Part 10, row 10: Extraction contains newlines (should use \n)
2025-12-15 10:49:40,401 - WARNING - Part 10, row 1: Extraction contains newlines (should use \n)
2025-12-15 10:49:40,401 - WARNING - Part 10, row 2: Extraction contains newlines (should use \n)
2025-12-15 10:49:40,401 - WARNING - Part 10, row 4: Extraction contains newlines (should use \n)
2025-12-15 10:49:40,401 - WARNING - Part 10, row 7: Extraction contains newlines (should use \n)
2025-12-15 10:49:40,401 - WARNING - Part 10, row 9: Extraction contains newlines (should use \n)
2025-12-15 10:49:40,401 - WARNING - Part 10, row 10: Extraction contains newlines (should use \n)
2025-12-15 10:49:40,402 - INFO - Part 10: Parsed successfully - is_last=False, rows=17
2025-12-15 10:49:40,403 - INFO - ✓ Saved part 10 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_10.json
2025-12-15 10:49:40,403 - INFO - Part 10: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_6fe593aa/part_10.json (not displayed to user)
2025-12-15 10:49:40,403 - INFO - Part 10: Added 17 rows (total: 98)
2025-12-15 10:49:40,403 - INFO - Part 10: is_last=false, continuing to next part...
2025-12-15 10:49:40,405 - INFO - Waiting 8.4s before next part...
2025-12-15 10:49:48,831 - INFO - === Processing Part 11 ===
2025-12-15 10:49:59,981 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:49:59,982 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:49:59,982 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:49:59,983 - INFO - Using max_output_tokens: 32768
2025-12-15 10:49:59,983 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:49:59,983 - INFO - Sending prompt (length: 4145 characters)
2025-12-15 10:49:59,984 - INFO - Max output tokens: 32768
2025-12-15 10:49:59,984 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:49:59,984 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:49:59,985 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:50:26,951 - INFO - Loaded 6 predefined prompts
2025-12-15 10:50:51,139 - INFO - Loaded 3 API keys
2025-12-15 10:51:23,000 - INFO - === Starting PDF Processing ===
2025-12-15 10:51:23,000 - INFO - Model: gemini-2.5-pro
2025-12-15 10:51:23,000 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:51:23,001 - INFO - Full prompt being sent (4081 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple PARTS.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE PART of the final output
- NOT repeat rows from previous parts
- Preserve the exact order of rows across parts

====================
OUTPUT FORMAT (EXACT)
====================
{
  "chunk_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part.>
    }
  ]
}

Rules for rows:
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
PART INSTRUCTIONS
====================
This is PART {chunk_index} of the output.

Generate ONLY the rows that belong to this part.
Stop when you reach a safe size limit.
If more content remains after this part, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate PART {chunk_index}.
2025-12-15 10:51:23,002 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_972e1f47
2025-12-15 10:51:23,002 - INFO - Final output will be saved to PDF directory: /home/mohammadbagher/Downloads/PDFs
2025-12-15 10:51:23,002 - INFO - No previous parts found, starting from part 1
2025-12-15 10:51:23,003 - INFO - === Processing Part 1 ===
2025-12-15 10:51:33,999 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:51:34,000 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:51:34,001 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:51:34,001 - INFO - Using max_output_tokens: 32768
2025-12-15 10:51:34,002 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:51:34,002 - INFO - Sending prompt (length: 4191 characters)
2025-12-15 10:51:34,003 - INFO - Max output tokens: 32768
2025-12-15 10:51:34,004 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:51:34,004 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:51:34,005 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:53:33,749 - INFO - ✓ Request completed: 32040 characters received
2025-12-15 10:53:33,751 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:53:33,752 - INFO - ✓ Response completed normally
2025-12-15 10:53:33,758 - ERROR - Part 1: Missing 'part_index' field
2025-12-15 10:53:33,759 - ERROR - Part 1: Validation failed
2025-12-15 10:53:33,763 - ERROR - Part 1: Part data structure: {
  "chunk_index": 1,
  "is_last": false,
  "rows": [
    {
      "Type": "page text",
      "Extraction": "Pemphigoid Group 30 Luca Borradori and Michael Hertl",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "**Chapter Contents**\nBullous Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 517\nMucous Membrane Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . 526\nEpidermolysis Bullosa Acquisita . . . . . . . . . . . . . . . . . . . . . . . 530",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "**BULLOUS PEMPHIGOID**\n**Synonym:** Pemphigoid",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "**Key features**\n\u25a0 Bullous pemphigoid (BP) is the most common autoimmune subepidermal blistering disease, and its onset is often after 60 years of age\n\u25a0 It is usually a chronic disease, with spontaneou
2025-12-15 10:53:33,763 - ERROR - Part 1: Failed to parse response
2025-12-15 10:53:33,764 - ERROR - Part 1: Response text (first 1000 chars): ```json
{
  "chunk_index": 1,
  "is_last": false,
  "rows": [
    {
      "Type": "page text",
      "Extraction": "Pemphigoid Group 30 Luca Borradori and Michael Hertl",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "**Chapter Contents**\nBullous Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 517\nMucous Membrane Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . 526\nEpidermolysis Bullosa Acquisita . . . . . . . . . . . . . . . . . . . . . . . 530",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "**BULLOUS PEMPHIGOID**\n**Synonym:** Pemphigoid",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "**Key features**\n■ Bullous pemphigoid (BP) is the most common autoimmune subepidermal blistering disease, and its onset is often after 60 years of age\n■ It is usually a chronic disease, with spontaneous 
2025-12-15 10:53:33,764 - ERROR - Part 1: Retrying same part...
2025-12-15 10:53:38,764 - INFO - === Processing Part 1 ===
2025-12-15 10:53:48,469 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 10:53:48,469 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 10:53:48,469 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 10:53:48,469 - INFO - Using max_output_tokens: 32768
2025-12-15 10:53:48,469 - INFO - Using model: gemini-2.5-pro
2025-12-15 10:53:48,469 - INFO - Sending prompt (length: 4191 characters)
2025-12-15 10:53:48,469 - INFO - Max output tokens: 32768
2025-12-15 10:53:48,469 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 10:53:48,469 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 10:53:48,469 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 10:56:05,005 - INFO - ✓ Request completed: 52674 characters received
2025-12-15 10:56:05,006 - INFO - Finish reason: STOP (normal completion)
2025-12-15 10:56:05,007 - INFO - ✓ Response completed normally
2025-12-15 10:56:05,013 - ERROR - Part 1: Missing 'part_index' field
2025-12-15 10:56:05,014 - ERROR - Part 1: Validation failed
2025-12-15 10:56:05,017 - ERROR - Part 1: Part data structure: {
  "chunk_index": 1,
  "is_last": false,
  "rows": [
    {
      "Type": "page text",
      "Extraction": "Chapter Contents\nBullous Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 517\nMucous Membrane Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 526\nEpidermolysis Bullosa Acquisita . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 530",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "BULLOUS PEMPHIGOID\nSynonym: * Pemphigoid",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Key features\n\u25a0 Bullous pemphigoid (BP) is the most common autoimmune subepidermal blistering disease, and its onset is often after 60 years of age\n\u25a0 It is usually a chronic disease, with spontaneous exacerbations and remissions, which m
2025-12-15 10:56:05,018 - ERROR - Part 1: Failed to parse response
2025-12-15 10:56:05,019 - ERROR - Part 1: Response text (first 1000 chars): ```json
{
  "chunk_index": 1,
  "is_last": false,
  "rows": [
    {
      "Type": "page text",
      "Extraction": "Chapter Contents\nBullous Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 517\nMucous Membrane Pemphigoid. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 526\nEpidermolysis Bullosa Acquisita . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 530",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "BULLOUS PEMPHIGOID\nSynonym: * Pemphigoid",
      "Number": 517,
      "Part": 1
    },
    {
      "Type": "page text",
      "Extraction": "Key features\n■ Bullous pemphigoid (BP) is the most common autoimmune subepidermal blistering disease, and its onset is often after 60 years of age\n■ It is usually a chronic disease, with spontaneous exacerbations and remissions, which may
2025-12-15 10:56:05,019 - ERROR - Part 1: Retrying same part...
2025-12-15 10:56:10,020 - INFO - === Processing Part 1 ===
2025-12-15 11:03:20,245 - INFO - Loaded 6 predefined prompts
2025-12-15 11:03:40,825 - INFO - Loaded 3 API keys
2025-12-15 11:04:11,222 - INFO - === Starting PDF Processing ===
2025-12-15 11:04:11,222 - INFO - Model: gemini-2.5-pro
2025-12-15 11:04:11,222 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 11:04:11,223 - INFO - Full prompt being sent (4081 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple PARTS.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE PART of the final output
- NOT repeat rows from previous parts
- Preserve the exact order of rows across parts

====================
OUTPUT FORMAT (EXACT)
====================
{
  "chunk_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <The “Part” column shows that the row’s content is included in which part. Use numbers like 1 or 2 and more.
How to define the parts for each row: in the beginning of the first page of the file there is a “Chapter contents” which demonstrates the parts of the chapter recommended by the author, which we call them “author parts”. I want you to make your own suggestion for dividing the parts, which we call them “Our parts”. The rules of dividing are as follows: an “our part” is consisted of as many as consecutive “author parts” without being the final “our part” more than 10 pages. For example if the “author part”s of the chapter are 2,4,5,3,1,7,5 pages respectively, the first “our part” will be consisted of the first two “author parts”. The second “our part” will be consisted of the third and fourth and fifth “author parts”. the third “our part” will be consisted of the sixth “author part”. the fourth “our part” will be consisted of the seventh “author part”.
If an “our part” ends in the middle of a page, some of the page text will be for the previous “our part” and some of the page will be for the next “our part”. The text of such pages must be written in two separate rows. One of them is related to the previous “our part” and one of them is related to next “our part”. Your goal should be avoiding a row’s content to be consisted of the data from two different “our part”s.
And for example if you decided to divide the chapter into 2 parts, you should write “1” for the contents of the first part and write “2” for the contents of the second part.>
    }
  ]
}

Rules for rows:
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
PART INSTRUCTIONS
====================
This is PART {chunk_index} of the output.

Generate ONLY the rows that belong to this part.
Stop when you reach a safe size limit.
If more content remains after this part, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate PART {chunk_index}.
2025-12-15 11:04:11,225 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_972e1f47
2025-12-15 11:04:11,225 - INFO - Final output will be saved to PDF directory: /home/mohammadbagher/Downloads/PDFs
2025-12-15 11:04:11,226 - INFO - No previous parts found, starting from part 1
2025-12-15 11:04:11,226 - INFO - === Processing Part 1 ===
2025-12-15 11:04:21,323 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:04:21,324 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 11:04:21,325 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:04:21,326 - INFO - Using max_output_tokens: 32768
2025-12-15 11:04:21,326 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:04:21,327 - INFO - Sending prompt (length: 4194 characters)
2025-12-15 11:04:21,327 - INFO - Max output tokens: 32768
2025-12-15 11:04:21,328 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:04:21,328 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:04:21,329 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:06:51,848 - INFO - ✓ Request completed: 34631 characters received
2025-12-15 11:06:51,849 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:06:51,849 - INFO - ✓ Response completed normally
2025-12-15 11:06:51,853 - WARNING - Part 1, row 3: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,854 - WARNING - Part 1, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,854 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,855 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,855 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,855 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,856 - WARNING - Part 1, row 9: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,856 - WARNING - Part 1, row 13: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,857 - WARNING - Part 1, row 15: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,857 - WARNING - Part 1, row 16: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,857 - WARNING - Part 1, row 17: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,858 - WARNING - Part 1, row 18: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,858 - WARNING - Part 1, row 22: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,859 - WARNING - Part 1, row 24: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,859 - WARNING - Part 1, row 25: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,860 - WARNING - Part 1, row 29: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,860 - WARNING - Part 1, row 30: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,860 - WARNING - Part 1, row 31: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,861 - WARNING - Part 1, row 35: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,861 - WARNING - Part 1, row 36: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,862 - WARNING - Part 1, row 37: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,862 - WARNING - Part 1, row 3: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,862 - WARNING - Part 1, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,863 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,863 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,864 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,864 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,864 - WARNING - Part 1, row 9: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,865 - WARNING - Part 1, row 13: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,865 - WARNING - Part 1, row 15: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,866 - WARNING - Part 1, row 16: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,866 - WARNING - Part 1, row 17: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,866 - WARNING - Part 1, row 18: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,867 - WARNING - Part 1, row 22: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,867 - WARNING - Part 1, row 24: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,868 - WARNING - Part 1, row 25: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,869 - WARNING - Part 1, row 29: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,869 - WARNING - Part 1, row 30: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,869 - WARNING - Part 1, row 31: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,870 - WARNING - Part 1, row 35: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,870 - WARNING - Part 1, row 36: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,870 - WARNING - Part 1, row 37: Extraction contains newlines (should use \n)
2025-12-15 11:06:51,871 - INFO - Part 1: Parsed successfully - is_last=False, rows=38
2025-12-15 11:06:51,878 - INFO - ✓ Saved part 1 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_972e1f47/part_1.json
2025-12-15 11:06:51,878 - INFO - Part 1: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_972e1f47/part_1.json (not displayed to user)
2025-12-15 11:06:51,878 - INFO - Part 1: Added 38 rows (total: 38)
2025-12-15 11:06:51,878 - INFO - Part 1: is_last=false, continuing to next part...
2025-12-15 11:06:51,879 - INFO - Waiting 8.3s before next part...
2025-12-15 11:07:00,132 - INFO - === Processing Part 2 ===
2025-12-15 11:07:11,808 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:07:11,808 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 11:07:11,813 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:07:11,813 - INFO - Using max_output_tokens: 32768
2025-12-15 11:07:11,814 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:07:11,814 - INFO - Sending prompt (length: 4277 characters)
2025-12-15 11:07:11,815 - INFO - Max output tokens: 32768
2025-12-15 11:07:11,816 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:07:11,816 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:07:11,817 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:09:30,011 - INFO - ✓ Request completed: 37834 characters received
2025-12-15 11:09:30,012 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:09:30,013 - INFO - ✓ Response completed normally
2025-12-15 11:09:30,017 - WARNING - Part 2, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,017 - WARNING - Part 2, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,018 - WARNING - Part 2, row 8: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,018 - WARNING - Part 2, row 11: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,018 - WARNING - Part 2, row 15: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,019 - WARNING - Part 2, row 18: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,019 - WARNING - Part 2, row 20: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,020 - WARNING - Part 2, row 22: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,020 - WARNING - Part 2, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,021 - WARNING - Part 2, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,022 - WARNING - Part 2, row 8: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,022 - WARNING - Part 2, row 11: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,023 - WARNING - Part 2, row 15: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,023 - WARNING - Part 2, row 18: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,024 - WARNING - Part 2, row 20: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,025 - WARNING - Part 2, row 22: Extraction contains newlines (should use \n)
2025-12-15 11:09:30,026 - INFO - Part 2: Parsed successfully - is_last=False, rows=23
2025-12-15 11:09:30,034 - INFO - ✓ Saved part 2 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_972e1f47/part_2.json
2025-12-15 11:09:30,034 - INFO - Part 2: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_972e1f47/part_2.json (not displayed to user)
2025-12-15 11:09:30,034 - INFO - Part 2: Added 23 rows (total: 61)
2025-12-15 11:09:30,035 - INFO - Part 2: is_last=false, continuing to next part...
2025-12-15 11:09:30,036 - INFO - Waiting 13.9s before next part...
2025-12-15 11:09:43,902 - INFO - === Processing Part 3 ===
2025-12-15 11:09:53,334 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:09:53,334 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 11:09:53,334 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:09:53,335 - INFO - Using max_output_tokens: 32768
2025-12-15 11:09:53,335 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:09:53,335 - INFO - Sending prompt (length: 4277 characters)
2025-12-15 11:09:53,335 - INFO - Max output tokens: 32768
2025-12-15 11:09:53,335 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:09:53,335 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:09:53,336 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:11:11,736 - INFO - ✓ Request completed: 19544 characters received
2025-12-15 11:11:11,737 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:11:11,737 - INFO - ✓ Response completed normally
2025-12-15 11:11:11,740 - WARNING - Part 3, row 3: Extraction contains newlines (should use \n)
2025-12-15 11:11:11,741 - WARNING - Part 3, row 9: Extraction contains newlines (should use \n)
2025-12-15 11:11:11,741 - WARNING - Part 3, row 10: Extraction contains newlines (should use \n)
2025-12-15 11:11:11,742 - WARNING - Part 3, row 11: Extraction contains newlines (should use \n)
2025-12-15 11:11:11,742 - WARNING - Part 3, row 12: Extraction contains newlines (should use \n)
2025-12-15 11:11:11,742 - WARNING - Part 3, row 13: Extraction contains newlines (should use \n)
2025-12-15 11:11:11,743 - WARNING - Part 3, row 3: Extraction contains newlines (should use \n)
2025-12-15 11:11:11,744 - WARNING - Part 3, row 9: Extraction contains newlines (should use \n)
2025-12-15 11:11:11,744 - WARNING - Part 3, row 10: Extraction contains newlines (should use \n)
2025-12-15 11:11:11,745 - WARNING - Part 3, row 11: Extraction contains newlines (should use \n)
2025-12-15 11:11:11,745 - WARNING - Part 3, row 12: Extraction contains newlines (should use \n)
2025-12-15 11:11:11,746 - WARNING - Part 3, row 13: Extraction contains newlines (should use \n)
2025-12-15 11:11:11,746 - INFO - Part 3: Parsed successfully - is_last=False, rows=14
2025-12-15 11:11:11,754 - INFO - ✓ Saved part 3 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_972e1f47/part_3.json
2025-12-15 11:11:11,755 - INFO - Part 3: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_972e1f47/part_3.json (not displayed to user)
2025-12-15 11:11:11,755 - INFO - Part 3: Added 14 rows (total: 75)
2025-12-15 11:11:11,756 - INFO - Part 3: is_last=false, continuing to next part...
2025-12-15 11:11:11,759 - INFO - Waiting 10.5s before next part...
2025-12-15 11:11:22,285 - INFO - === Processing Part 4 ===
2025-12-15 11:11:33,595 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:11:33,595 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 11:11:33,595 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:11:33,595 - INFO - Using max_output_tokens: 32768
2025-12-15 11:11:33,596 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:11:33,596 - INFO - Sending prompt (length: 4277 characters)
2025-12-15 11:11:33,596 - INFO - Max output tokens: 32768
2025-12-15 11:11:33,596 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:11:33,596 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:11:33,596 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:12:37,568 - INFO - ✓ Request completed: 22883 characters received
2025-12-15 11:12:37,569 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:12:37,569 - INFO - ✓ Response completed normally
2025-12-15 11:12:37,570 - WARNING - Part 4, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:12:37,570 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:12:37,571 - WARNING - Part 4, row 6: Extraction contains newlines (should use \n)
2025-12-15 11:12:37,571 - WARNING - Part 4, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:12:37,571 - WARNING - Part 4, row 8: Extraction contains newlines (should use \n)
2025-12-15 11:12:37,571 - WARNING - Part 4, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:12:37,571 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:12:37,571 - WARNING - Part 4, row 6: Extraction contains newlines (should use \n)
2025-12-15 11:12:37,571 - WARNING - Part 4, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:12:37,571 - WARNING - Part 4, row 8: Extraction contains newlines (should use \n)
2025-12-15 11:12:37,571 - INFO - Part 4: Parsed successfully - is_last=False, rows=9
2025-12-15 11:12:37,573 - INFO - ✓ Saved part 4 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_972e1f47/part_4.json
2025-12-15 11:12:37,573 - INFO - Part 4: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_972e1f47/part_4.json (not displayed to user)
2025-12-15 11:12:37,573 - INFO - Part 4: Added 9 rows (total: 84)
2025-12-15 11:12:37,573 - INFO - Part 4: is_last=false, continuing to next part...
2025-12-15 11:12:37,574 - INFO - Waiting 14.3s before next part...
2025-12-15 11:12:51,880 - INFO - === Processing Part 5 ===
2025-12-15 11:13:01,181 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:13:01,181 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 11:13:01,182 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:13:01,182 - INFO - Using max_output_tokens: 32768
2025-12-15 11:13:01,183 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:13:01,183 - INFO - Sending prompt (length: 4277 characters)
2025-12-15 11:13:01,184 - INFO - Max output tokens: 32768
2025-12-15 11:13:01,184 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:13:01,185 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:13:01,185 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:15:02,208 - INFO - ✓ Request completed: 24698 characters received
2025-12-15 11:15:02,210 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:15:02,210 - INFO - ✓ Response completed normally
2025-12-15 11:15:02,214 - WARNING - Part 5, row 1: Extraction contains newlines (should use \n)
2025-12-15 11:15:02,214 - WARNING - Part 5, row 1: Extraction contains newlines (should use \n)
2025-12-15 11:15:02,215 - INFO - Part 5: Parsed successfully - is_last=True, rows=25
2025-12-15 11:15:02,221 - INFO - ✓ Saved part 5 to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_972e1f47/part_5.json
2025-12-15 11:15:02,222 - INFO - Part 5: Saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_972e1f47/part_5.json (not displayed to user)
2025-12-15 11:15:02,222 - INFO - Part 5: Added 25 rows (total: 109)
2025-12-15 11:15:02,223 - INFO - Part 5: is_last=true, processing complete!
2025-12-15 11:15:02,223 - INFO - === Processing Summary ===
2025-12-15 11:15:02,226 - INFO - New parts processed in this run: 4
2025-12-15 11:15:02,226 - INFO - Previous parts loaded (resume): 0
2025-12-15 11:15:02,227 - INFO - Total parts in final output: 4
2025-12-15 11:15:02,227 - INFO - Total rows collected: 109
2025-12-15 11:15:02,227 - INFO - Deduplicating 109 rows...
2025-12-15 11:15:02,233 - WARNING - Removed 1 duplicate rows using enhanced deduplication
2025-12-15 11:15:02,234 - INFO - Final row count after deduplication: 108
2025-12-15 11:15:02,234 - INFO - Sorting 108 rows by Part and Number...
2025-12-15 11:15:02,234 - INFO - Rows sorted successfully
2025-12-15 11:15:02,239 - INFO - ✓ Final output saved to /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-15 11:15:02,239 - INFO -   - File path: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-15 11:15:02,239 - INFO -   - Total parts: 4 (0 previous + 4 new)
2025-12-15 11:15:02,239 - INFO -   - Total rows: 108
2025-12-15 11:15:02,240 - INFO -   - File size: 133.28 KB
2025-12-15 11:22:29,236 - INFO - === Starting PDF Processing ===
2025-12-15 11:22:29,236 - INFO - Model: gemini-2.5-pro
2025-12-15 11:22:29,238 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 11:22:29,238 - INFO - Full prompt being sent (4530 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple CHUNKS.

IMPORTANT:
- A CHUNK is ONLY a technical split of the RESPONSE due to size limits.
- CHUNKS are identified ONLY by the field "chunk_index".
- CHUNKS have NOTHING to do with the medical or logical structure of the chapter.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE CHUNK of the final output
- NOT repeat rows from previous chunks
- Preserve the exact order of rows across chunks

====================
OUTPUT FORMAT (EXACT)
====================
{
  "chunk_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <integer>
    }
  ]
}

====================
MEANING OF chunk_index
====================
- "chunk_index" indicates ONLY the sequential number of this RESPONSE CHUNK.
- chunk_index = 1 means: first technical chunk of the output.
- chunk_index = 2 means: second technical chunk of the output.
- chunk_index has NO semantic meaning about the chapter content.
- chunk_index MUST strictly increase by 1 across responses.

====================
MEANING OF Part (VERY IMPORTANT)
====================
- "Part" represents the LOGICAL CONTENT PART of the chapter.
- "Part" is NOT related to chunk_index.
- "Part" is the result of grouping AUTHOR PARTS into YOUR OWN PARTS ("Our parts").

How to define "Part":
1) At the beginning of the chapter, there is a "Chapter contents" section that lists
   the author-defined parts ("author parts") and their page ranges.
2) You MUST group consecutive author parts into larger groups called "Our parts".
3) Each "Our part" MUST:
   - consist of consecutive author parts
   - NOT exceed 10 pages total
4) Assign integer labels starting from 1:
   - Our part 1
   - Our part 2
   - Our part 3
   - etc.

Example:
If author parts have page counts:
2, 4, 5, 3, 1, 7, 5

Then:
- Our part 1 = author parts 1 + 2
- Our part 2 = author parts 3 + 4 + 5
- Our part 3 = author part 6
- Our part 4 = author part 7

Rules for assigning "Part" in rows:
- Every row MUST have exactly ONE integer "Part" value.
- A single page MAY belong to TWO different "Part" values if an Our part boundary
  occurs in the middle of the page.
- In such cases, split the page text into TWO separate rows:
  - one row with the previous Part
  - one row with the next Part
- NEVER mix content from two different Parts inside the same row.

====================
Rules for rows
====================
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
CHUNK INSTRUCTIONS
====================
This is CHUNK {chunk_index} of the output.

Generate ONLY the rows that belong to this CHUNK.
Stop when you reach a safe size limit for a single response.
If more content remains after this CHUNK, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate CHUNK {chunk_index}.
2025-12-15 11:22:29,243 - INFO - Parts directory: /home/mohammadbagher/Downloads/PDFs/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_3513e464
2025-12-15 11:22:29,245 - INFO - Final output will be saved to PDF directory: /home/mohammadbagher/Downloads/PDFs
2025-12-15 11:22:29,246 - INFO - No previous parts found, starting from part 1
2025-12-15 11:22:29,247 - INFO - === Processing Part 1 ===
2025-12-15 11:22:40,683 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:22:40,684 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 11:22:40,684 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:22:40,685 - INFO - Using max_output_tokens: 32768
2025-12-15 11:22:40,686 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:22:40,686 - INFO - Sending prompt (length: 4643 characters)
2025-12-15 11:22:40,686 - INFO - Max output tokens: 32768
2025-12-15 11:22:40,687 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:22:40,688 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:22:40,688 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:24:49,053 - INFO - ✓ Request completed: 33036 characters received
2025-12-15 11:24:49,054 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:24:49,055 - INFO - ✓ Response completed normally
2025-12-15 11:24:49,059 - WARNING - Part 1, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,060 - WARNING - Part 1, row 1: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,060 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,061 - WARNING - Part 1, row 3: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,061 - WARNING - Part 1, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,062 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,062 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,063 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,063 - WARNING - Part 1, row 11: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,064 - WARNING - Part 1, row 16: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,064 - WARNING - Part 1, row 19: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,065 - WARNING - Part 1, row 22: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,066 - WARNING - Part 1, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,066 - WARNING - Part 1, row 1: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,067 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,067 - WARNING - Part 1, row 3: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,068 - WARNING - Part 1, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,068 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,069 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,069 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,070 - WARNING - Part 1, row 11: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,070 - WARNING - Part 1, row 16: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,071 - WARNING - Part 1, row 19: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,071 - WARNING - Part 1, row 22: Extraction contains newlines (should use \n)
2025-12-15 11:24:49,072 - INFO - Part 1: Parsed successfully - is_last=False, rows=23
2025-12-15 11:24:49,080 - INFO - ✓ Saved part 1 to /home/mohammadbagher/Downloads/PDFs/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_3513e464/part_1.json
2025-12-15 11:24:49,081 - INFO - Part 1: Saved to /home/mohammadbagher/Downloads/PDFs/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_3513e464/part_1.json (not displayed to user)
2025-12-15 11:24:49,081 - INFO - Part 1: Added 23 rows (total: 23)
2025-12-15 11:24:49,081 - INFO - Part 1: is_last=false, continuing to next part...
2025-12-15 11:24:49,083 - INFO - Waiting 14.4s before next part...
2025-12-15 11:25:03,455 - INFO - === Processing Part 2 ===
2025-12-15 11:25:14,238 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:25:14,238 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 11:25:14,239 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:25:14,240 - INFO - Using max_output_tokens: 32768
2025-12-15 11:25:14,240 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:25:14,240 - INFO - Sending prompt (length: 4726 characters)
2025-12-15 11:25:14,241 - INFO - Max output tokens: 32768
2025-12-15 11:25:14,241 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:25:14,242 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:25:14,242 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:26:37,775 - INFO - ✓ Request completed: 30638 characters received
2025-12-15 11:26:37,777 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:26:37,777 - INFO - ✓ Response completed normally
2025-12-15 11:26:37,780 - WARNING - Part 2, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,781 - WARNING - Part 2, row 1: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,782 - WARNING - Part 2, row 2: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,782 - WARNING - Part 2, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,783 - WARNING - Part 2, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,784 - WARNING - Part 2, row 8: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,785 - WARNING - Part 2, row 10: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,786 - WARNING - Part 2, row 11: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,787 - WARNING - Part 2, row 12: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,788 - WARNING - Part 2, row 16: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,789 - WARNING - Part 2, row 17: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,789 - WARNING - Part 2, row 18: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,789 - WARNING - Part 2, row 22: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,790 - WARNING - Part 2, row 23: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,790 - WARNING - Part 2, row 27: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,790 - WARNING - Part 2, row 28: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,790 - WARNING - Part 2, row 29: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,791 - WARNING - Part 2, row 31: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,791 - WARNING - Part 2, row 32: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,791 - WARNING - Part 2, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,792 - WARNING - Part 2, row 1: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,793 - WARNING - Part 2, row 2: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,793 - WARNING - Part 2, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,793 - WARNING - Part 2, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,793 - WARNING - Part 2, row 8: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,794 - WARNING - Part 2, row 10: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,794 - WARNING - Part 2, row 11: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,794 - WARNING - Part 2, row 12: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,794 - WARNING - Part 2, row 16: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,795 - WARNING - Part 2, row 17: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,795 - WARNING - Part 2, row 18: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,795 - WARNING - Part 2, row 22: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,795 - WARNING - Part 2, row 23: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,795 - WARNING - Part 2, row 27: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,795 - WARNING - Part 2, row 28: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,796 - WARNING - Part 2, row 29: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,796 - WARNING - Part 2, row 31: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,796 - WARNING - Part 2, row 32: Extraction contains newlines (should use \n)
2025-12-15 11:26:37,796 - INFO - Part 2: Parsed successfully - is_last=False, rows=34
2025-12-15 11:26:37,800 - INFO - ✓ Saved part 2 to /home/mohammadbagher/Downloads/PDFs/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_3513e464/part_2.json
2025-12-15 11:26:37,800 - INFO - Part 2: Saved to /home/mohammadbagher/Downloads/PDFs/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_3513e464/part_2.json (not displayed to user)
2025-12-15 11:26:37,800 - INFO - Part 2: Added 34 rows (total: 57)
2025-12-15 11:26:37,800 - INFO - Part 2: is_last=false, continuing to next part...
2025-12-15 11:26:37,801 - INFO - Waiting 11.7s before next part...
2025-12-15 11:26:49,523 - INFO - === Processing Part 3 ===
2025-12-15 11:27:02,567 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:27:02,567 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 11:27:02,567 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:27:02,568 - INFO - Using max_output_tokens: 32768
2025-12-15 11:27:02,568 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:27:02,568 - INFO - Sending prompt (length: 4726 characters)
2025-12-15 11:27:02,568 - INFO - Max output tokens: 32768
2025-12-15 11:27:02,568 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:27:02,569 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:27:02,569 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:29:08,779 - INFO - ✓ Request completed: 28991 characters received
2025-12-15 11:29:08,780 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:29:08,781 - INFO - ✓ Response completed normally
2025-12-15 11:29:08,785 - WARNING - Part 3, row 3: Extraction contains newlines (should use \n)
2025-12-15 11:29:08,787 - WARNING - Part 3, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:29:08,787 - WARNING - Part 3, row 10: Extraction contains newlines (should use \n)
2025-12-15 11:29:08,788 - WARNING - Part 3, row 14: Extraction contains newlines (should use \n)
2025-12-15 11:29:08,789 - WARNING - Part 3, row 16: Extraction contains newlines (should use \n)
2025-12-15 11:29:08,789 - WARNING - Part 3, row 19: Extraction contains newlines (should use \n)
2025-12-15 11:29:08,790 - WARNING - Part 3, row 3: Extraction contains newlines (should use \n)
2025-12-15 11:29:08,791 - WARNING - Part 3, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:29:08,792 - WARNING - Part 3, row 10: Extraction contains newlines (should use \n)
2025-12-15 11:29:08,793 - WARNING - Part 3, row 14: Extraction contains newlines (should use \n)
2025-12-15 11:29:08,795 - WARNING - Part 3, row 16: Extraction contains newlines (should use \n)
2025-12-15 11:29:08,795 - WARNING - Part 3, row 19: Extraction contains newlines (should use \n)
2025-12-15 11:29:08,796 - INFO - Part 3: Parsed successfully - is_last=False, rows=20
2025-12-15 11:29:08,801 - INFO - ✓ Saved part 3 to /home/mohammadbagher/Downloads/PDFs/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_3513e464/part_3.json
2025-12-15 11:29:08,804 - INFO - Part 3: Saved to /home/mohammadbagher/Downloads/PDFs/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_3513e464/part_3.json (not displayed to user)
2025-12-15 11:29:08,805 - INFO - Part 3: Added 20 rows (total: 77)
2025-12-15 11:29:08,805 - INFO - Part 3: is_last=false, continuing to next part...
2025-12-15 11:29:08,806 - INFO - Waiting 8.5s before next part...
2025-12-15 11:29:17,286 - INFO - === Processing Part 4 ===
2025-12-15 11:29:32,580 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:29:32,581 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 11:29:32,581 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:29:32,581 - INFO - Using max_output_tokens: 32768
2025-12-15 11:29:32,581 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:29:32,581 - INFO - Sending prompt (length: 4726 characters)
2025-12-15 11:29:32,581 - INFO - Max output tokens: 32768
2025-12-15 11:29:32,581 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:29:32,581 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:29:32,581 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:30:55,690 - INFO - ✓ Request completed: 25183 characters received
2025-12-15 11:30:55,691 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:30:55,691 - INFO - ✓ Response completed normally
2025-12-15 11:30:55,694 - INFO - Part 4: Parsed successfully - is_last=False, rows=9
2025-12-15 11:30:55,701 - INFO - ✓ Saved part 4 to /home/mohammadbagher/Downloads/PDFs/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_3513e464/part_4.json
2025-12-15 11:30:55,701 - INFO - Part 4: Saved to /home/mohammadbagher/Downloads/PDFs/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_3513e464/part_4.json (not displayed to user)
2025-12-15 11:30:55,702 - INFO - Part 4: Added 9 rows (total: 86)
2025-12-15 11:30:55,702 - INFO - Part 4: is_last=false, continuing to next part...
2025-12-15 11:30:55,704 - INFO - Waiting 14.8s before next part...
2025-12-15 11:31:10,503 - INFO - === Processing Part 5 ===
2025-12-15 11:31:21,131 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:31:21,131 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 11:31:21,131 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:31:21,131 - INFO - Using max_output_tokens: 32768
2025-12-15 11:31:21,131 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:31:21,131 - INFO - Sending prompt (length: 4726 characters)
2025-12-15 11:31:21,131 - INFO - Max output tokens: 32768
2025-12-15 11:31:21,131 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:31:21,131 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:31:21,132 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:33:38,172 - INFO - ✓ Request completed: 34727 characters received
2025-12-15 11:33:38,173 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:33:38,174 - INFO - ✓ Response completed normally
2025-12-15 11:33:38,178 - WARNING - Part 5, row 2: Extraction contains newlines (should use \n)
2025-12-15 11:33:38,178 - WARNING - Part 5, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:33:38,179 - WARNING - Part 5, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:33:38,179 - WARNING - Part 5, row 9: Extraction contains newlines (should use \n)
2025-12-15 11:33:38,180 - WARNING - Part 5, row 10: Extraction contains newlines (should use \n)
2025-12-15 11:33:38,181 - WARNING - Part 5, row 2: Extraction contains newlines (should use \n)
2025-12-15 11:33:38,182 - WARNING - Part 5, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:33:38,182 - WARNING - Part 5, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:33:38,183 - WARNING - Part 5, row 9: Extraction contains newlines (should use \n)
2025-12-15 11:33:38,183 - WARNING - Part 5, row 10: Extraction contains newlines (should use \n)
2025-12-15 11:33:38,184 - INFO - Part 5: Parsed successfully - is_last=True, rows=29
2025-12-15 11:33:38,204 - INFO - ✓ Saved part 5 to /home/mohammadbagher/Downloads/PDFs/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_3513e464/part_5.json
2025-12-15 11:33:38,204 - INFO - Part 5: Saved to /home/mohammadbagher/Downloads/PDFs/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_3513e464/part_5.json (not displayed to user)
2025-12-15 11:33:38,205 - INFO - Part 5: Added 29 rows (total: 115)
2025-12-15 11:33:38,206 - INFO - Part 5: is_last=true, processing complete!
2025-12-15 11:33:38,208 - INFO - === Processing Summary ===
2025-12-15 11:33:38,212 - INFO - New parts processed in this run: 4
2025-12-15 11:33:38,213 - INFO - Previous parts loaded (resume): 0
2025-12-15 11:33:38,214 - INFO - Total parts in final output: 4
2025-12-15 11:33:38,215 - INFO - Total rows collected: 115
2025-12-15 11:33:38,216 - INFO - Deduplicating 115 rows...
2025-12-15 11:33:38,245 - WARNING - Removed 10 duplicate rows using enhanced deduplication
2025-12-15 11:33:38,248 - INFO - Final row count after deduplication: 105
2025-12-15 11:33:38,250 - INFO - Sorting 105 rows by Part and Number...
2025-12-15 11:33:38,251 - INFO - Rows sorted successfully
2025-12-15 11:33:38,277 - INFO - ✓ Final output saved to /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-15 11:33:38,278 - INFO -   - File path: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-15 11:33:38,278 - INFO -   - Total parts: 4 (0 previous + 4 new)
2025-12-15 11:33:38,279 - INFO -   - Total rows: 105
2025-12-15 11:33:38,279 - INFO -   - File size: 144.29 KB
2025-12-15 11:41:04,627 - INFO - Loaded 6 predefined prompts
2025-12-15 11:47:35,095 - INFO - Loaded 6 predefined prompts
2025-12-15 11:47:57,909 - INFO - Loaded 3 API keys
2025-12-15 11:49:08,423 - INFO - === Starting PDF Processing ===
2025-12-15 11:49:08,424 - INFO - Model: gemini-2.5-pro
2025-12-15 11:49:08,425 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-29-6-22.pdf
2025-12-15 11:49:08,425 - INFO - Full prompt being sent (5469 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple CHUNKS.

IMPORTANT:
- A CHUNK is ONLY a technical split of the RESPONSE due to size limits.
- CHUNKS are identified ONLY by the field "chunk_index".
- CHUNKS have NOTHING to do with the medical or logical structure of the chapter.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE CHUNK of the final output
- NOT repeat rows from previous chunks
- Preserve the exact order of rows across chunks

====================
OUTPUT FORMAT (EXACT)
====================
{
  "chunk_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <integer>
    }
  ]
}

====================
MEANING OF chunk_index
====================
- "chunk_index" indicates ONLY the sequential number of this RESPONSE CHUNK.
- chunk_index = 1 means: first technical chunk of the output.
- chunk_index = 2 means: second technical chunk of the output.
- chunk_index has NO semantic meaning about the chapter content.
- chunk_index MUST strictly increase by 1 across responses.

====================
MEANING OF Part (VERY IMPORTANT)
====================
- "Part" represents the LOGICAL CONTENT PART of the chapter.
- "Part" is NOT related to chunk_index.
- "Part" is the result of grouping AUTHOR PARTS into YOUR OWN PARTS ("Our parts").

How to define "Part":
1) At the beginning of the chapter, there is a "Chapter contents" section that lists
   the author-defined parts ("author parts") and their page ranges.
2) You MUST group consecutive author parts into larger groups called "Our parts".
3) Each "Our part" MUST:
   - consist of consecutive author parts
   - NOT exceed 10 pages total
4) Assign integer labels starting from 1:
   - Our part 1
   - Our part 2
   - Our part 3
   - etc.

Example:
If author parts have page counts:
2, 4, 5, 3, 1, 7, 5

Then:
- Our part 1 = author parts 1 + 2
- Our part 2 = author parts 3 + 4 + 5
- Our part 3 = author part 6
- Our part 4 = author part 7

Rules for assigning "Part" in rows:
- Every row MUST have exactly ONE integer "Part" value.
- A single page MAY belong to TWO different "Part" values if an Our part boundary
  occurs in the middle of the page.
- In such cases, split the page text into TWO separate rows:
  - one row with the previous Part
  - one row with the next Part
- NEVER mix content from two different Parts inside the same row.
====================
PAGE-BY-PAGE FORWARD-ONLY PROCESSING (CRITICAL)
====================
You MUST process the document STRICTLY page by page, in ascending page order.

- Always start from the lowest-numbered page that has NOT yet been processed.
- NEVER go back to a previous page.
- NEVER re-extract or regenerate content from any page that has already appeared
  in earlier chunks.
- Once a page (or a portion of a page) is output in any chunk, it is considered FINAL.
- Subsequent chunks MUST continue ONLY from the next unprocessed page or page segment.

Important clarifications:
- If a page is split across two different "Part" values, you may output that page
  in TWO rows, but ONLY ONCE and ONLY in forward order.
- You MUST NOT repeat a page, a paragraph, a figure, or a table that has already
  been output in any previous chunk.
- If you are unsure whether a page has already been processed, assume it HAS
  and move forward.

====================
Rules for rows
====================
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
CHUNK INSTRUCTIONS
====================
This is CHUNK {chunk_index} of the output.

Generate ONLY the rows that belong to this CHUNK.
Stop when you reach a safe size limit for a single response.
If more content remains after this CHUNK, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate CHUNK {chunk_index}.
2025-12-15 11:49:08,432 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-29-6-22.pdf_1e3d158e
2025-12-15 11:49:08,433 - INFO - Final output will be saved to current directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project
2025-12-15 11:49:08,439 - INFO - === Processing Part 1 ===
2025-12-15 11:49:14,919 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:49:14,920 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-29-6-22.pdf
2025-12-15 11:49:14,921 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:49:14,921 - INFO - Using max_output_tokens: 32768
2025-12-15 11:49:14,922 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:49:14,922 - INFO - Sending prompt (length: 5582 characters)
2025-12-15 11:49:14,923 - INFO - Max output tokens: 32768
2025-12-15 11:49:14,923 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:49:14,923 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:49:14,924 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:51:01,495 - INFO - ✓ Request completed: 26978 characters received
2025-12-15 11:51:01,495 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:51:01,496 - INFO - ✓ Response completed normally
2025-12-15 11:51:01,496 - WARNING - Part 1, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:51:01,496 - WARNING - Part 1, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:51:01,497 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:51:01,497 - WARNING - Part 1, row 10: Extraction contains newlines (should use \n)
2025-12-15 11:51:01,497 - WARNING - Part 1, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:51:01,497 - WARNING - Part 1, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:51:01,497 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:51:01,497 - WARNING - Part 1, row 10: Extraction contains newlines (should use \n)
2025-12-15 11:51:01,497 - INFO - Part 1: Parsed successfully - is_last=False, rows=11
2025-12-15 11:51:01,500 - INFO - Part 1: Added 11 rows (total: 11)
2025-12-15 11:51:01,500 - INFO - Part 1: is_last=false, continuing to next part...
2025-12-15 11:51:01,500 - INFO - Waiting 11.1s before next part...
2025-12-15 11:51:12,643 - INFO - === Processing Part 2 ===
2025-12-15 11:51:19,095 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:51:19,095 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-29-6-22.pdf
2025-12-15 11:51:19,096 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:51:19,097 - INFO - Using max_output_tokens: 32768
2025-12-15 11:51:19,097 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:51:19,098 - INFO - Sending prompt (length: 5665 characters)
2025-12-15 11:51:19,098 - INFO - Max output tokens: 32768
2025-12-15 11:51:19,099 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:51:19,099 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:51:19,100 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:52:41,751 - INFO - ✓ Request completed: 26253 characters received
2025-12-15 11:52:41,752 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:52:41,753 - INFO - ✓ Response completed normally
2025-12-15 11:52:41,756 - WARNING - Part 2, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,757 - WARNING - Part 2, row 2: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,757 - WARNING - Part 2, row 3: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,758 - WARNING - Part 2, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,759 - WARNING - Part 2, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,760 - WARNING - Part 2, row 11: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,761 - WARNING - Part 2, row 12: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,762 - WARNING - Part 2, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,763 - WARNING - Part 2, row 2: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,763 - WARNING - Part 2, row 3: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,764 - WARNING - Part 2, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,765 - WARNING - Part 2, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,765 - WARNING - Part 2, row 11: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,766 - WARNING - Part 2, row 12: Extraction contains newlines (should use \n)
2025-12-15 11:52:41,766 - INFO - Part 2: Parsed successfully - is_last=False, rows=14
2025-12-15 11:52:41,769 - INFO - Part 2: Added 14 rows (total: 25)
2025-12-15 11:52:41,770 - INFO - Part 2: is_last=false, continuing to next part...
2025-12-15 11:52:41,771 - INFO - Waiting 13.8s before next part...
2025-12-15 11:52:55,559 - INFO - === Processing Part 3 ===
2025-12-15 11:53:02,910 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:53:02,911 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-29-6-22.pdf
2025-12-15 11:53:02,911 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:53:02,912 - INFO - Using max_output_tokens: 32768
2025-12-15 11:53:02,912 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:53:02,913 - INFO - Sending prompt (length: 5665 characters)
2025-12-15 11:53:02,913 - INFO - Max output tokens: 32768
2025-12-15 11:53:02,914 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:53:02,914 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:53:02,914 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:54:23,981 - INFO - ✓ Request completed: 28132 characters received
2025-12-15 11:54:23,985 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:54:23,988 - INFO - ✓ Response completed normally
2025-12-15 11:54:23,994 - WARNING - Part 3, row 2: Extraction contains newlines (should use \n)
2025-12-15 11:54:23,996 - WARNING - Part 3, row 3: Extraction contains newlines (should use \n)
2025-12-15 11:54:23,997 - WARNING - Part 3, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:54:23,998 - WARNING - Part 3, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:54:23,998 - WARNING - Part 3, row 11: Extraction contains newlines (should use \n)
2025-12-15 11:54:23,999 - WARNING - Part 3, row 12: Extraction contains newlines (should use \n)
2025-12-15 11:54:24,000 - WARNING - Part 3, row 2: Extraction contains newlines (should use \n)
2025-12-15 11:54:24,002 - WARNING - Part 3, row 3: Extraction contains newlines (should use \n)
2025-12-15 11:54:24,004 - WARNING - Part 3, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:54:24,005 - WARNING - Part 3, row 7: Extraction contains newlines (should use \n)
2025-12-15 11:54:24,006 - WARNING - Part 3, row 11: Extraction contains newlines (should use \n)
2025-12-15 11:54:24,007 - WARNING - Part 3, row 12: Extraction contains newlines (should use \n)
2025-12-15 11:54:24,007 - INFO - Part 3: Parsed successfully - is_last=False, rows=14
2025-12-15 11:54:24,016 - INFO - Part 3: Added 14 rows (total: 39)
2025-12-15 11:54:24,016 - INFO - Part 3: is_last=false, continuing to next part...
2025-12-15 11:54:24,021 - INFO - Waiting 14.6s before next part...
2025-12-15 11:54:38,593 - INFO - === Processing Part 4 ===
2025-12-15 11:54:44,648 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:54:44,649 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-29-6-22.pdf
2025-12-15 11:54:44,649 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:54:44,650 - INFO - Using max_output_tokens: 32768
2025-12-15 11:54:44,651 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:54:44,652 - INFO - Sending prompt (length: 5665 characters)
2025-12-15 11:54:44,652 - INFO - Max output tokens: 32768
2025-12-15 11:54:44,653 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:54:44,653 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:54:44,654 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 11:56:55,761 - INFO - ✓ Request completed: 29462 characters received
2025-12-15 11:56:55,762 - INFO - Finish reason: STOP (normal completion)
2025-12-15 11:56:55,763 - INFO - ✓ Response completed normally
2025-12-15 11:56:55,767 - WARNING - Part 4, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:56:55,767 - WARNING - Part 4, row 2: Extraction contains newlines (should use \n)
2025-12-15 11:56:55,768 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:56:55,768 - WARNING - Part 4, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:56:55,769 - WARNING - Part 4, row 0: Extraction contains newlines (should use \n)
2025-12-15 11:56:55,769 - WARNING - Part 4, row 2: Extraction contains newlines (should use \n)
2025-12-15 11:56:55,769 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-15 11:56:55,770 - WARNING - Part 4, row 5: Extraction contains newlines (should use \n)
2025-12-15 11:56:55,770 - INFO - Part 4: Parsed successfully - is_last=False, rows=7
2025-12-15 11:56:55,773 - INFO - Part 4: Added 7 rows (total: 46)
2025-12-15 11:56:55,773 - INFO - Part 4: is_last=false, continuing to next part...
2025-12-15 11:56:55,775 - INFO - Waiting 13.1s before next part...
2025-12-15 11:57:08,919 - INFO - === Processing Part 5 ===
2025-12-15 11:57:48,936 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 11:57:48,936 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-29-6-22.pdf
2025-12-15 11:57:48,937 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 11:57:48,937 - INFO - Using max_output_tokens: 32768
2025-12-15 11:57:48,938 - INFO - Using model: gemini-2.5-pro
2025-12-15 11:57:48,938 - INFO - Sending prompt (length: 5665 characters)
2025-12-15 11:57:48,939 - INFO - Max output tokens: 32768
2025-12-15 11:57:48,939 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 11:57:48,940 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 11:57:48,940 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 12:00:40,496 - INFO - ✓ Request completed: 71174 characters received
2025-12-15 12:00:40,496 - INFO - Finish reason: STOP (normal completion)
2025-12-15 12:00:40,496 - INFO - ✓ Response completed normally
2025-12-15 12:00:40,498 - WARNING - Part 5, row 0: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,498 - WARNING - Part 5, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,498 - WARNING - Part 5, row 7: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,498 - WARNING - Part 5, row 8: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,498 - WARNING - Part 5, row 10: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 13: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 15: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 17: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 19: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 20: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 22: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 23: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 0: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 7: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 8: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 10: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,499 - WARNING - Part 5, row 13: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,500 - WARNING - Part 5, row 15: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,500 - WARNING - Part 5, row 17: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,500 - WARNING - Part 5, row 19: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,500 - WARNING - Part 5, row 20: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,500 - WARNING - Part 5, row 22: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,500 - WARNING - Part 5, row 23: Extraction contains newlines (should use \n)
2025-12-15 12:00:40,500 - INFO - Part 5: Parsed successfully - is_last=True, rows=24
2025-12-15 12:00:40,501 - INFO - Part 5: Added 24 rows (total: 70)
2025-12-15 12:00:40,501 - INFO - Part 5: is_last=true, processing complete!
2025-12-15 12:00:40,502 - INFO - === Processing Summary ===
2025-12-15 12:00:40,502 - INFO - Parts processed: 4
2025-12-15 12:00:40,502 - INFO - Total parts in final output: 4
2025-12-15 12:00:40,502 - INFO - Total rows collected: 70
2025-12-15 12:00:40,502 - INFO - Deduplicating 70 rows...
2025-12-15 12:00:40,508 - WARNING - Removed 12 duplicate rows using enhanced deduplication
2025-12-15 12:00:40,508 - INFO - Final row count after deduplication: 58
2025-12-15 12:00:40,508 - INFO - Sorting 58 rows by Number (as float)...
2025-12-15 12:00:40,508 - INFO - Rows sorted successfully
2025-12-15 12:00:40,511 - INFO - ✓ Final JSON output saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-29-6-22_final_output.json
2025-12-15 12:00:40,512 - INFO -   - File path: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-29-6-22_final_output.json
2025-12-15 12:00:40,512 - INFO -   - Total parts: 4
2025-12-15 12:00:40,512 - INFO -   - Total rows: 58
2025-12-15 12:00:40,512 - INFO -   - File size: 138.16 KB
2025-12-15 12:00:40,524 - INFO - ✓ Final CSV output saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-29-6-22_final_output.csv
2025-12-15 12:00:40,524 - INFO -   - File path: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-29-6-22_final_output.csv
2025-12-15 12:00:40,524 - INFO -   - Total rows: 58
2025-12-15 12:00:40,525 - INFO -   - File size: 133.01 KB
2025-12-15 12:21:45,352 - INFO - === Starting PDF Processing ===
2025-12-15 12:21:45,352 - INFO - Model: gemini-2.5-pro
2025-12-15 12:21:45,352 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 12:21:45,352 - INFO - Full prompt being sent (5469 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple CHUNKS.

IMPORTANT:
- A CHUNK is ONLY a technical split of the RESPONSE due to size limits.
- CHUNKS are identified ONLY by the field "chunk_index".
- CHUNKS have NOTHING to do with the medical or logical structure of the chapter.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE CHUNK of the final output
- NOT repeat rows from previous chunks
- Preserve the exact order of rows across chunks

====================
OUTPUT FORMAT (EXACT)
====================
{
  "chunk_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <integer>
    }
  ]
}

====================
MEANING OF chunk_index
====================
- "chunk_index" indicates ONLY the sequential number of this RESPONSE CHUNK.
- chunk_index = 1 means: first technical chunk of the output.
- chunk_index = 2 means: second technical chunk of the output.
- chunk_index has NO semantic meaning about the chapter content.
- chunk_index MUST strictly increase by 1 across responses.

====================
MEANING OF Part (VERY IMPORTANT)
====================
- "Part" represents the LOGICAL CONTENT PART of the chapter.
- "Part" is NOT related to chunk_index.
- "Part" is the result of grouping AUTHOR PARTS into YOUR OWN PARTS ("Our parts").

How to define "Part":
1) At the beginning of the chapter, there is a "Chapter contents" section that lists
   the author-defined parts ("author parts") and their page ranges.
2) You MUST group consecutive author parts into larger groups called "Our parts".
3) Each "Our part" MUST:
   - consist of consecutive author parts
   - NOT exceed 10 pages total
4) Assign integer labels starting from 1:
   - Our part 1
   - Our part 2
   - Our part 3
   - etc.

Example:
If author parts have page counts:
2, 4, 5, 3, 1, 7, 5

Then:
- Our part 1 = author parts 1 + 2
- Our part 2 = author parts 3 + 4 + 5
- Our part 3 = author part 6
- Our part 4 = author part 7

Rules for assigning "Part" in rows:
- Every row MUST have exactly ONE integer "Part" value.
- A single page MAY belong to TWO different "Part" values if an Our part boundary
  occurs in the middle of the page.
- In such cases, split the page text into TWO separate rows:
  - one row with the previous Part
  - one row with the next Part
- NEVER mix content from two different Parts inside the same row.
====================
PAGE-BY-PAGE FORWARD-ONLY PROCESSING (CRITICAL)
====================
You MUST process the document STRICTLY page by page, in ascending page order.

- Always start from the lowest-numbered page that has NOT yet been processed.
- NEVER go back to a previous page.
- NEVER re-extract or regenerate content from any page that has already appeared
  in earlier chunks.
- Once a page (or a portion of a page) is output in any chunk, it is considered FINAL.
- Subsequent chunks MUST continue ONLY from the next unprocessed page or page segment.

Important clarifications:
- If a page is split across two different "Part" values, you may output that page
  in TWO rows, but ONLY ONCE and ONLY in forward order.
- You MUST NOT repeat a page, a paragraph, a figure, or a table that has already
  been output in any previous chunk.
- If you are unsure whether a page has already been processed, assume it HAS
  and move forward.

====================
Rules for rows
====================
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
CHUNK INSTRUCTIONS
====================
This is CHUNK {chunk_index} of the output.

Generate ONLY the rows that belong to this CHUNK.
Stop when you reach a safe size limit for a single response.
If more content remains after this CHUNK, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate CHUNK {chunk_index}.
2025-12-15 12:21:45,354 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_1e3d158e
2025-12-15 12:21:45,354 - INFO - Final output will be saved to current directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project
2025-12-15 12:21:45,354 - INFO - === Processing Part 1 ===
2025-12-15 12:21:54,872 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 12:21:54,873 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 12:21:54,875 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 12:21:54,875 - INFO - Using max_output_tokens: 32768
2025-12-15 12:21:54,876 - INFO - Using model: gemini-2.5-pro
2025-12-15 12:21:54,876 - INFO - Sending prompt (length: 5582 characters)
2025-12-15 12:21:54,877 - INFO - Max output tokens: 32768
2025-12-15 12:21:54,877 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 12:21:54,878 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 12:21:54,878 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 12:23:32,129 - INFO - ✓ Request completed: 24609 characters received
2025-12-15 12:23:32,131 - INFO - Finish reason: STOP (normal completion)
2025-12-15 12:23:32,131 - INFO - ✓ Response completed normally
2025-12-15 12:23:32,134 - WARNING - Part 1, row 0: Extraction contains newlines (should use \n)
2025-12-15 12:23:32,135 - WARNING - Part 1, row 4: Extraction contains newlines (should use \n)
2025-12-15 12:23:32,135 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 12:23:32,136 - WARNING - Part 1, row 0: Extraction contains newlines (should use \n)
2025-12-15 12:23:32,137 - WARNING - Part 1, row 4: Extraction contains newlines (should use \n)
2025-12-15 12:23:32,137 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-15 12:23:32,137 - INFO - Part 1: Parsed successfully - is_last=False, rows=10
2025-12-15 12:23:32,140 - INFO - Part 1: Added 10 rows (total: 10)
2025-12-15 12:23:32,141 - INFO - Part 1: is_last=false, continuing to next part...
2025-12-15 12:23:32,142 - INFO - Waiting 9.1s before next part...
2025-12-15 12:23:41,246 - INFO - === Processing Part 2 ===
2025-12-15 12:23:50,605 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 12:23:50,606 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 12:23:50,607 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 12:23:50,607 - INFO - Using max_output_tokens: 32768
2025-12-15 12:23:50,608 - INFO - Using model: gemini-2.5-pro
2025-12-15 12:23:50,608 - INFO - Sending prompt (length: 5665 characters)
2025-12-15 12:23:50,609 - INFO - Max output tokens: 32768
2025-12-15 12:23:50,609 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 12:23:50,610 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 12:23:50,610 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 12:25:24,849 - INFO - ✓ Request completed: 23784 characters received
2025-12-15 12:25:24,850 - INFO - Finish reason: STOP (normal completion)
2025-12-15 12:25:24,851 - INFO - ✓ Response completed normally
2025-12-15 12:25:24,854 - WARNING - Part 2, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:25:24,855 - WARNING - Part 2, row 5: Extraction contains newlines (should use \n)
2025-12-15 12:25:24,855 - WARNING - Part 2, row 9: Extraction contains newlines (should use \n)
2025-12-15 12:25:24,856 - WARNING - Part 2, row 12: Extraction contains newlines (should use \n)
2025-12-15 12:25:24,856 - WARNING - Part 2, row 14: Extraction contains newlines (should use \n)
2025-12-15 12:25:24,857 - WARNING - Part 2, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:25:24,857 - WARNING - Part 2, row 5: Extraction contains newlines (should use \n)
2025-12-15 12:25:24,857 - WARNING - Part 2, row 9: Extraction contains newlines (should use \n)
2025-12-15 12:25:24,858 - WARNING - Part 2, row 12: Extraction contains newlines (should use \n)
2025-12-15 12:25:24,858 - WARNING - Part 2, row 14: Extraction contains newlines (should use \n)
2025-12-15 12:25:24,859 - INFO - Part 2: Parsed successfully - is_last=False, rows=15
2025-12-15 12:25:24,861 - INFO - Part 2: Added 15 rows (total: 25)
2025-12-15 12:25:24,862 - INFO - Part 2: is_last=false, continuing to next part...
2025-12-15 12:25:24,864 - INFO - Waiting 13.5s before next part...
2025-12-15 12:25:38,353 - INFO - === Processing Part 3 ===
2025-12-15 12:25:48,777 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 12:25:48,777 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 12:25:48,778 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 12:25:48,779 - INFO - Using max_output_tokens: 32768
2025-12-15 12:25:48,779 - INFO - Using model: gemini-2.5-pro
2025-12-15 12:25:48,781 - INFO - Sending prompt (length: 5665 characters)
2025-12-15 12:25:48,782 - INFO - Max output tokens: 32768
2025-12-15 12:25:48,783 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 12:25:48,783 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 12:25:48,784 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 12:27:40,215 - INFO - ✓ Request completed: 17510 characters received
2025-12-15 12:27:40,216 - INFO - Finish reason: STOP (normal completion)
2025-12-15 12:27:40,217 - INFO - ✓ Response completed normally
2025-12-15 12:27:40,220 - INFO - Part 3: Parsed successfully - is_last=False, rows=13
2025-12-15 12:27:40,223 - INFO - Part 3: Added 13 rows (total: 38)
2025-12-15 12:27:40,224 - INFO - Part 3: is_last=false, continuing to next part...
2025-12-15 12:27:40,225 - INFO - Waiting 10.0s before next part...
2025-12-15 12:27:50,232 - INFO - === Processing Part 4 ===
2025-12-15 12:28:00,879 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 12:28:00,880 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 12:28:00,881 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 12:28:00,882 - INFO - Using max_output_tokens: 32768
2025-12-15 12:28:00,882 - INFO - Using model: gemini-2.5-pro
2025-12-15 12:28:00,883 - INFO - Sending prompt (length: 5665 characters)
2025-12-15 12:28:00,883 - INFO - Max output tokens: 32768
2025-12-15 12:28:00,884 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 12:28:00,884 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 12:28:00,885 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 12:29:23,878 - INFO - ✓ Request completed: 20063 characters received
2025-12-15 12:29:23,879 - INFO - Finish reason: STOP (normal completion)
2025-12-15 12:29:23,880 - INFO - ✓ Response completed normally
2025-12-15 12:29:23,883 - WARNING - Part 4, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,883 - WARNING - Part 4, row 3: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,884 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,884 - WARNING - Part 4, row 5: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,885 - WARNING - Part 4, row 6: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,885 - WARNING - Part 4, row 7: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,885 - WARNING - Part 4, row 9: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,886 - WARNING - Part 4, row 10: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,886 - WARNING - Part 4, row 13: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,887 - WARNING - Part 4, row 14: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,887 - WARNING - Part 4, row 15: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,888 - WARNING - Part 4, row 16: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,888 - WARNING - Part 4, row 17: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,889 - WARNING - Part 4, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,890 - WARNING - Part 4, row 3: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,891 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,891 - WARNING - Part 4, row 5: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,892 - WARNING - Part 4, row 6: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,892 - WARNING - Part 4, row 7: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,893 - WARNING - Part 4, row 9: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,893 - WARNING - Part 4, row 10: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,894 - WARNING - Part 4, row 13: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,894 - WARNING - Part 4, row 14: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,895 - WARNING - Part 4, row 15: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,895 - WARNING - Part 4, row 16: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,895 - WARNING - Part 4, row 17: Extraction contains newlines (should use \n)
2025-12-15 12:29:23,896 - INFO - Part 4: Parsed successfully - is_last=False, rows=18
2025-12-15 12:29:23,899 - INFO - Part 4: Added 18 rows (total: 56)
2025-12-15 12:29:23,900 - INFO - Part 4: is_last=false, continuing to next part...
2025-12-15 12:29:23,904 - INFO - Waiting 11.8s before next part...
2025-12-15 12:29:35,662 - INFO - === Processing Part 5 ===
2025-12-15 12:29:45,935 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 12:29:45,935 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 12:29:45,936 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 12:29:45,936 - INFO - Using max_output_tokens: 32768
2025-12-15 12:29:45,936 - INFO - Using model: gemini-2.5-pro
2025-12-15 12:29:45,936 - INFO - Sending prompt (length: 5665 characters)
2025-12-15 12:29:45,936 - INFO - Max output tokens: 32768
2025-12-15 12:29:45,936 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 12:29:45,937 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 12:29:45,937 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 12:30:50,771 - INFO - ✓ Request completed: 6765 characters received
2025-12-15 12:30:50,772 - INFO - Finish reason: STOP (normal completion)
2025-12-15 12:30:50,773 - INFO - ✓ Response completed normally
2025-12-15 12:30:50,775 - INFO - Part 5: Parsed successfully - is_last=True, rows=18
2025-12-15 12:30:50,777 - INFO - Part 5: Added 18 rows (total: 74)
2025-12-15 12:30:50,778 - INFO - Part 5: is_last=true, processing complete!
2025-12-15 12:30:50,780 - INFO - === Processing Summary ===
2025-12-15 12:30:50,781 - INFO - Parts processed: 4
2025-12-15 12:30:50,782 - INFO - Total parts in final output: 4
2025-12-15 12:30:50,783 - INFO - Total rows collected: 74
2025-12-15 12:30:50,783 - INFO - Deduplicating 74 rows...
2025-12-15 12:30:50,793 - INFO - Final row count after deduplication: 74
2025-12-15 12:30:50,794 - INFO - Sorting 74 rows by Number (as float)...
2025-12-15 12:30:50,795 - INFO - Rows sorted successfully
2025-12-15 12:30:50,802 - INFO - ✓ Final JSON output saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-15 12:30:50,803 - INFO -   - File path: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-15 12:30:50,803 - INFO -   - Total parts: 4
2025-12-15 12:30:50,803 - INFO -   - Total rows: 74
2025-12-15 12:30:50,803 - INFO -   - File size: 91.28 KB
2025-12-15 12:30:50,812 - INFO - ✓ Final CSV output saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.csv
2025-12-15 12:30:50,813 - INFO -   - File path: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.csv
2025-12-15 12:30:50,813 - INFO -   - Total rows: 74
2025-12-15 12:30:50,813 - INFO -   - File size: 85.01 KB
2025-12-15 12:39:09,132 - INFO - === Starting PDF Processing ===
2025-12-15 12:39:09,132 - INFO - Model: gemini-2.5-pro
2025-12-15 12:39:09,133 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 12:39:09,133 - INFO - Full prompt being sent (5009 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple CHUNKS.

IMPORTANT:
- A CHUNK is ONLY a technical split of the RESPONSE due to size limits.
- CHUNKS are identified ONLY by the field "chunk_index".
- CHUNKS have NOTHING to do with the medical or logical structure of the chapter.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE CHUNK of the final output
- NOT repeat rows from previous chunks
- Preserve the exact order of rows across chunks

====================
OUTPUT FORMAT (EXACT)
====================
{
  "chunk_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <integer>
    }
  ]
}

====================
MEANING OF chunk_index
====================
- "chunk_index" indicates ONLY the sequential number of this RESPONSE CHUNK.
- chunk_index = 1 means: first technical chunk of the output.
- chunk_index = 2 means: second technical chunk of the output.
- chunk_index has NO semantic meaning about the chapter content.
- chunk_index MUST strictly increase by 1 across responses.

====================
MEANING OF Part (VERY IMPORTANT)
====================
- "Part" represents the LOGICAL CONTENT PART of the chapter.
- "Part" is NOT related to chunk_index.
- "Part" is the result of grouping AUTHOR PARTS into YOUR OWN PARTS ("Our parts").

How to define "Part":
1) At the beginning of the chapter, there is a "Chapter contents" section that lists
   the author-defined parts ("author parts") and their page ranges.
2) You MUST group consecutive author parts into larger groups called "Our parts".
3) Each "Our part" MUST:
   - consist of consecutive author parts
   - NOT exceed 10 pages total
4) Assign integer labels starting from 1:
   - Our part 1
   - Our part 2
   - Our part 3
   - etc.

Example:
If author parts have page counts:
2, 4, 5, 3, 1, 7, 5

Then:
- Our part 1 = author parts 1 + 2
- Our part 2 = author parts 3 + 4 + 5
- Our part 3 = author part 6
- Our part 4 = author part 7

Rules for assigning "Part" in rows:
- Every row MUST have exactly ONE integer "Part" value.
- A single page MAY belong to TWO different "Part" values if an Our part boundary
  occurs in the middle of the page.
- In such cases, split the page text into TWO separate rows:
  - one row with the previous Part
  - one row with the next Part
- NEVER mix content from two different Parts inside the same row.
====================
PAGE-BY-PAGE FORWARD-ONLY PROCESSING (CRITICAL)
====================
You MUST process the document STRICTLY page by page, in ascending page order.
- NEVER go back to a previous page.
- NEVER re-extract or regenerate content from any page that has already appeared
  in earlier chunks.
- Once a page (or a portion of a page) is output in any chunk, it is considered FINAL.
- Subsequent chunks MUST continue ONLY from the next unprocessed page or page segment.
====================
Rules for rows
====================
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.

====================
CHUNK INSTRUCTIONS
====================
This is CHUNK {chunk_index} of the output.

Generate ONLY the rows that belong to this CHUNK.
Stop when you reach a safe size limit for a single response.
If more content remains after this CHUNK, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate CHUNK {chunk_index}.
2025-12-15 12:39:09,134 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_012f30bc
2025-12-15 12:39:09,134 - INFO - Final output will be saved to current directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project
2025-12-15 12:39:09,135 - INFO - === Processing Part 1 ===
2025-12-15 12:39:18,265 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 12:39:18,265 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 12:39:18,266 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 12:39:18,266 - INFO - Using max_output_tokens: 32768
2025-12-15 12:39:18,266 - INFO - Using model: gemini-2.5-pro
2025-12-15 12:39:18,266 - INFO - Sending prompt (length: 5122 characters)
2025-12-15 12:39:18,267 - INFO - Max output tokens: 32768
2025-12-15 12:39:18,267 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 12:39:18,267 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 12:39:18,267 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 12:40:43,242 - INFO - ✓ Request completed: 27722 characters received
2025-12-15 12:40:43,243 - INFO - Finish reason: STOP (normal completion)
2025-12-15 12:40:43,243 - INFO - ✓ Response completed normally
2025-12-15 12:40:43,244 - WARNING - Part 1, row 0: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,244 - WARNING - Part 1, row 1: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,244 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,244 - WARNING - Part 1, row 3: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,244 - WARNING - Part 1, row 4: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,244 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - WARNING - Part 1, row 9: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - WARNING - Part 1, row 14: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - WARNING - Part 1, row 17: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - WARNING - Part 1, row 0: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - WARNING - Part 1, row 1: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - WARNING - Part 1, row 3: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - WARNING - Part 1, row 4: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - WARNING - Part 1, row 9: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - WARNING - Part 1, row 14: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - WARNING - Part 1, row 17: Extraction contains newlines (should use \n)
2025-12-15 12:40:43,245 - INFO - Part 1: Parsed successfully - is_last=False, rows=18
2025-12-15 12:40:43,246 - INFO - Part 1: Added 18 rows (total: 18)
2025-12-15 12:40:43,246 - INFO - Part 1: is_last=false, continuing to next part...
2025-12-15 12:40:43,247 - INFO - Waiting 8.6s before next part...
2025-12-15 12:40:51,862 - INFO - === Processing Part 2 ===
2025-12-15 12:41:01,509 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 12:41:01,509 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 12:41:01,509 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 12:41:01,510 - INFO - Using max_output_tokens: 32768
2025-12-15 12:41:01,510 - INFO - Using model: gemini-2.5-pro
2025-12-15 12:41:01,510 - INFO - Sending prompt (length: 5205 characters)
2025-12-15 12:41:01,510 - INFO - Max output tokens: 32768
2025-12-15 12:41:01,510 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 12:41:01,510 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 12:41:01,510 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 12:42:18,900 - INFO - ✓ Request completed: 22776 characters received
2025-12-15 12:42:18,903 - INFO - Finish reason: STOP (normal completion)
2025-12-15 12:42:18,905 - INFO - ✓ Response completed normally
2025-12-15 12:42:18,909 - WARNING - Part 2, row 0: Extraction contains newlines (should use \n)
2025-12-15 12:42:18,910 - WARNING - Part 2, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:42:18,910 - WARNING - Part 2, row 6: Extraction contains newlines (should use \n)
2025-12-15 12:42:18,912 - WARNING - Part 2, row 9: Extraction contains newlines (should use \n)
2025-12-15 12:42:18,912 - WARNING - Part 2, row 12: Extraction contains newlines (should use \n)
2025-12-15 12:42:18,913 - WARNING - Part 2, row 0: Extraction contains newlines (should use \n)
2025-12-15 12:42:18,913 - WARNING - Part 2, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:42:18,914 - WARNING - Part 2, row 6: Extraction contains newlines (should use \n)
2025-12-15 12:42:18,914 - WARNING - Part 2, row 9: Extraction contains newlines (should use \n)
2025-12-15 12:42:18,915 - WARNING - Part 2, row 12: Extraction contains newlines (should use \n)
2025-12-15 12:42:18,916 - INFO - Part 2: Parsed successfully - is_last=False, rows=16
2025-12-15 12:42:18,919 - INFO - Part 2: Added 16 rows (total: 34)
2025-12-15 12:42:18,920 - INFO - Part 2: is_last=false, continuing to next part...
2025-12-15 12:42:18,921 - INFO - Waiting 10.4s before next part...
2025-12-15 12:42:29,304 - INFO - === Processing Part 3 ===
2025-12-15 12:42:38,693 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 12:42:38,694 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 12:42:38,695 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 12:42:38,696 - INFO - Using max_output_tokens: 32768
2025-12-15 12:42:38,696 - INFO - Using model: gemini-2.5-pro
2025-12-15 12:42:38,697 - INFO - Sending prompt (length: 5205 characters)
2025-12-15 12:42:38,697 - INFO - Max output tokens: 32768
2025-12-15 12:42:38,698 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 12:42:38,698 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 12:42:38,699 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 12:43:55,980 - INFO - ✓ Request completed: 23834 characters received
2025-12-15 12:43:55,982 - INFO - Finish reason: STOP (normal completion)
2025-12-15 12:43:55,982 - INFO - ✓ Response completed normally
2025-12-15 12:43:55,986 - WARNING - Part 3, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:43:55,986 - WARNING - Part 3, row 5: Extraction contains newlines (should use \n)
2025-12-15 12:43:55,987 - WARNING - Part 3, row 9: Extraction contains newlines (should use \n)
2025-12-15 12:43:55,987 - WARNING - Part 3, row 12: Extraction contains newlines (should use \n)
2025-12-15 12:43:55,988 - WARNING - Part 3, row 14: Extraction contains newlines (should use \n)
2025-12-15 12:43:55,988 - WARNING - Part 3, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:43:55,989 - WARNING - Part 3, row 5: Extraction contains newlines (should use \n)
2025-12-15 12:43:55,990 - WARNING - Part 3, row 9: Extraction contains newlines (should use \n)
2025-12-15 12:43:55,990 - WARNING - Part 3, row 12: Extraction contains newlines (should use \n)
2025-12-15 12:43:55,992 - WARNING - Part 3, row 14: Extraction contains newlines (should use \n)
2025-12-15 12:43:55,992 - INFO - Part 3: Parsed successfully - is_last=False, rows=15
2025-12-15 12:43:55,995 - INFO - Part 3: Added 15 rows (total: 49)
2025-12-15 12:43:55,995 - INFO - Part 3: is_last=false, continuing to next part...
2025-12-15 12:43:55,997 - INFO - Waiting 12.9s before next part...
2025-12-15 12:44:08,849 - INFO - === Processing Part 4 ===
2025-12-15 12:44:22,609 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 12:44:22,609 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 12:44:22,610 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 12:44:22,611 - INFO - Using max_output_tokens: 32768
2025-12-15 12:44:22,612 - INFO - Using model: gemini-2.5-pro
2025-12-15 12:44:22,613 - INFO - Sending prompt (length: 5205 characters)
2025-12-15 12:44:22,613 - INFO - Max output tokens: 32768
2025-12-15 12:44:22,614 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 12:44:22,614 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 12:44:22,615 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 12:46:04,327 - INFO - ✓ Request completed: 34231 characters received
2025-12-15 12:46:04,328 - INFO - Finish reason: STOP (normal completion)
2025-12-15 12:46:04,329 - INFO - ✓ Response completed normally
2025-12-15 12:46:04,332 - WARNING - Part 4, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,333 - WARNING - Part 4, row 3: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,333 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,334 - WARNING - Part 4, row 5: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,334 - WARNING - Part 4, row 7: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,334 - WARNING - Part 4, row 10: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,335 - WARNING - Part 4, row 12: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,335 - WARNING - Part 4, row 13: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,336 - WARNING - Part 4, row 14: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,337 - WARNING - Part 4, row 15: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,337 - WARNING - Part 4, row 16: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,337 - WARNING - Part 4, row 2: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,338 - WARNING - Part 4, row 3: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,339 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,339 - WARNING - Part 4, row 5: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,339 - WARNING - Part 4, row 7: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,340 - WARNING - Part 4, row 10: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,340 - WARNING - Part 4, row 12: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,341 - WARNING - Part 4, row 13: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,341 - WARNING - Part 4, row 14: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,341 - WARNING - Part 4, row 15: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,342 - WARNING - Part 4, row 16: Extraction contains newlines (should use \n)
2025-12-15 12:46:04,342 - INFO - Part 4: Parsed successfully - is_last=False, rows=17
2025-12-15 12:46:04,344 - INFO - Part 4: Added 17 rows (total: 66)
2025-12-15 12:46:04,345 - INFO - Part 4: is_last=false, continuing to next part...
2025-12-15 12:46:04,346 - INFO - Waiting 8.6s before next part...
2025-12-15 12:46:12,985 - INFO - === Processing Part 5 ===
2025-12-15 12:46:21,478 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 12:46:21,478 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 12:46:21,479 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 12:46:21,480 - INFO - Using max_output_tokens: 32768
2025-12-15 12:46:21,480 - INFO - Using model: gemini-2.5-pro
2025-12-15 12:46:21,481 - INFO - Sending prompt (length: 5205 characters)
2025-12-15 12:46:21,481 - INFO - Max output tokens: 32768
2025-12-15 12:46:21,482 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 12:46:21,482 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 12:46:21,483 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 12:47:36,031 - INFO - ✓ Request completed: 15729 characters received
2025-12-15 12:47:36,032 - INFO - Finish reason: STOP (normal completion)
2025-12-15 12:47:36,033 - INFO - ✓ Response completed normally
2025-12-15 12:47:36,037 - WARNING - Part 5, row 3: Extraction contains newlines (should use \n)
2025-12-15 12:47:36,038 - WARNING - Part 5, row 4: Extraction contains newlines (should use \n)
2025-12-15 12:47:36,038 - WARNING - Part 5, row 5: Extraction contains newlines (should use \n)
2025-12-15 12:47:36,039 - WARNING - Part 5, row 3: Extraction contains newlines (should use \n)
2025-12-15 12:47:36,039 - WARNING - Part 5, row 4: Extraction contains newlines (should use \n)
2025-12-15 12:47:36,040 - WARNING - Part 5, row 5: Extraction contains newlines (should use \n)
2025-12-15 12:47:36,040 - INFO - Part 5: Parsed successfully - is_last=True, rows=24
2025-12-15 12:47:36,043 - INFO - Part 5: Added 24 rows (total: 90)
2025-12-15 12:47:36,044 - INFO - Part 5: is_last=true, processing complete!
2025-12-15 12:47:36,045 - INFO - === Processing Summary ===
2025-12-15 12:47:36,046 - INFO - Parts processed: 4
2025-12-15 12:47:36,046 - INFO - Total parts in final output: 4
2025-12-15 12:47:36,047 - INFO - Total rows collected: 90
2025-12-15 12:47:36,048 - INFO - Deduplicating 90 rows...
2025-12-15 12:47:36,066 - WARNING - Removed 1 duplicate rows using enhanced deduplication
2025-12-15 12:47:36,069 - INFO - Final row count after deduplication: 89
2025-12-15 12:47:36,070 - INFO - Sorting 89 rows by Number (as float)...
2025-12-15 12:47:36,071 - INFO - Rows sorted successfully
2025-12-15 12:47:36,091 - INFO - ✓ Final JSON output saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-15 12:47:36,092 - INFO -   - File path: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-15 12:47:36,092 - INFO -   - Total parts: 4
2025-12-15 12:47:36,095 - INFO -   - Total rows: 89
2025-12-15 12:47:36,096 - INFO -   - File size: 118.96 KB
2025-12-15 12:47:36,110 - INFO - ✓ Final CSV output saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.csv
2025-12-15 12:47:36,111 - INFO -   - File path: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.csv
2025-12-15 12:47:36,111 - INFO -   - Total rows: 89
2025-12-15 12:47:36,111 - INFO -   - File size: 111.25 KB
2025-12-15 13:49:41,853 - INFO - Loaded 6 predefined prompts
2025-12-15 13:50:46,663 - INFO - Processing Part 1 with second-stage prompt...
2025-12-15 13:50:46,664 - ERROR - No API key available
2025-12-15 13:50:46,664 - ERROR - No response for Part 1, aborting post-process
2025-12-15 13:52:06,504 - INFO - Loaded 3 API keys
2025-12-15 13:53:01,654 - INFO - Processing Part 1 with second-stage prompt...
2025-12-15 13:54:23,272 - INFO - Text processed successfully with gemini-2.5-flash
2025-12-15 13:54:23,276 - ERROR - Failed to parse JSON response in post-processor
2025-12-15 13:54:23,277 - ERROR - Failed to parse JSON for Part 1, aborting
2025-12-15 13:58:39,337 - INFO - Processing Part 1 with second-stage prompt...
2025-12-15 14:00:04,572 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-15 14:00:04,573 - ERROR - Failed to parse JSON response in post-processor
2025-12-15 14:00:04,575 - ERROR - Failed to parse JSON for Part 1, aborting
2025-12-15 14:00:58,266 - INFO - Loaded 6 predefined prompts
2025-12-15 14:01:21,500 - INFO - Loaded 3 API keys
2025-12-15 14:02:54,425 - INFO - Processing Part 1 with second-stage prompt...
2025-12-15 14:03:04,542 - INFO - Processing Part 1 with second-stage prompt...
2025-12-15 14:04:28,173 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-15 14:04:28,179 - INFO - Processing Part 2 with second-stage prompt...
2025-12-15 14:05:07,354 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-15 14:05:07,359 - INFO - Processing Part 2 with second-stage prompt...
2025-12-15 14:06:21,765 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-15 14:06:21,770 - INFO - Processing Part 3 with second-stage prompt...
2025-12-15 14:07:13,355 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-15 14:07:13,355 - ERROR - Failed to parse JSON response in post-processor
2025-12-15 14:07:13,355 - ERROR - Failed to parse JSON for Part 2, aborting
2025-12-15 14:07:46,110 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-15 14:07:46,125 - INFO - Post-processed JSON saved to: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed.json
2025-12-15 14:20:30,838 - INFO - Loaded 6 predefined prompts
2025-12-15 14:22:43,650 - INFO - Loaded 3 API keys
2025-12-15 14:23:48,849 - INFO - Processing Part 1 with second-stage prompt...
2025-12-15 14:25:44,731 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-15 14:25:44,736 - INFO - Processing Part 2 with second-stage prompt...
2025-12-15 14:27:26,765 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-15 14:27:26,768 - INFO - Processing Part 3 with second-stage prompt...
2025-12-15 14:27:27,340 - ERROR - Text processing failed: 429 Resource has been exhausted (e.g. check quota).
2025-12-15 14:27:27,342 - ERROR - No response for Part 3, aborting post-process
2025-12-15 14:30:09,494 - INFO - === Starting PDF Processing ===
2025-12-15 14:30:09,495 - INFO - Model: gemini-2.5-pro
2025-12-15 14:30:09,496 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 14:30:09,496 - INFO - Full prompt being sent (6000 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple CHUNKS.

IMPORTANT:
- A CHUNK is ONLY a technical split of the RESPONSE due to size limits.
- CHUNKS are identified ONLY by the field "chunk_index".
- CHUNKS have NOTHING to do with the medical or logical structure of the chapter.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE CHUNK of the final output
- NOT repeat rows from previous chunks
- Preserve the exact order of rows across chunks

====================
OUTPUT FORMAT (EXACT)
====================
{
  "chunk_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <integer>
    }
  ]
}

====================
MEANING OF chunk_index
====================
- "chunk_index" indicates ONLY the sequential number of this RESPONSE CHUNK.
- chunk_index = 1 means: first technical chunk of the output.
- chunk_index = 2 means: second technical chunk of the output.
- chunk_index has NO semantic meaning about the chapter content.
- chunk_index MUST strictly increase by 1 across responses.

====================
MEANING OF Part (VERY IMPORTANT)
====================
- "Part" represents the LOGICAL CONTENT PART of the chapter.
- "Part" is NOT related to chunk_index.
- "Part" is the result of grouping AUTHOR PARTS into YOUR OWN PARTS ("Our parts").

How to define "Part":
1) At the beginning of the chapter, there is a "Chapter contents" section that lists
   the author-defined parts ("author parts") and their first page.
2) You MUST group consecutive author parts into larger groups called "Our parts".
3) Each "Our part" MUST:
   - consist of consecutive author parts
   - NOT exceed 10 pages total
4) Assign integer labels starting from 1:
   - Our part 1
   - Our part 2
   - Our part 3
   - etc.

Example:
If author parts have page counts:
2, 4, 5, 3, 1, 7, 5

Then:
- Our part 1 = author parts 1 + 2 (in this example it is wrong to add the third author part because this way the first our part will be 11 pages which is more than 10 pages.)
- Our part 2 = author parts 3 + 4 + 5 (it is correct because they are 9 pages together which is less than 10 pages.)
- Our part 3 = author part 6
- Our part 4 = author part 7

Rules for assigning "Part" in rows:
- Every row MUST have exactly ONE integer "Part" value.
- A single page MAY belong to TWO different "Part" values if an Our part boundary
  occurs in the middle of the page.
- In such cases, split the page text into TWO separate rows:
  - one row with the previous Part value
  - one row with the next Part value
- NEVER mix content from two different Parts inside the same row.
- NEVER change Part value before an author part ends.
====================
PAGE-BY-PAGE FORWARD-ONLY PROCESSING (CRITICAL)
====================
You MUST process the document STRICTLY page by page, in ascending page order.
- NEVER go back to a previous page.
- NEVER re-extract or regenerate content from any page that has already appeared
  in earlier chunks.
- Once a page (or a portion of a page) is output in any chunk, it is considered FINAL.
- Subsequent chunks MUST continue ONLY from the next unprocessed page or page segment.
====================
Rules for rows
====================
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.
====================
Rules for eFig and eTable
====================
- eFigs and eTables are some contents added after the chapter ends. They are not necessarily related contextually to the last our part. They can be related each of the previous our parts.
- you must find that each eFig and eTable belongs to which one of the our parts. 
- so when you are working on each chunk you must also check and find and include the eFigs and eTables that are related contextually to this chunk. Write the correct our part value for each eFig and eTable.
  


====================
CHUNK INSTRUCTIONS
====================
This is CHUNK {chunk_index} of the output.

Generate ONLY the rows that belong to this CHUNK.
Stop when you reach a safe size limit for a single response.
If more content remains after this CHUNK, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate CHUNK {chunk_index}.
2025-12-15 14:30:09,505 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_e5082c0d
2025-12-15 14:30:09,507 - INFO - Final output will be saved to current directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project
2025-12-15 14:30:09,508 - INFO - === Processing Part 1 ===
2025-12-15 14:30:23,936 - INFO - PDF uploaded successfully with API key: bagher
2025-12-15 14:30:23,936 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-15 14:30:23,937 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-15 14:30:23,937 - INFO - Using max_output_tokens: 32768
2025-12-15 14:30:23,938 - INFO - Using model: gemini-2.5-pro
2025-12-15 14:30:23,938 - INFO - Sending prompt (length: 6113 characters)
2025-12-15 14:30:23,938 - INFO - Max output tokens: 32768
2025-12-15 14:30:23,939 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-15 14:30:23,939 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-15 14:30:23,940 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-15 14:30:25,674 - ERROR - ================================================================================
2025-12-15 14:30:25,674 - ERROR - 🔴 RATE LIMIT ERROR (429) - COMPLETE DETAILS
2025-12-15 14:30:25,675 - ERROR - ================================================================================
2025-12-15 14:30:25,675 - ERROR - Error Type: ResourceExhausted
2025-12-15 14:30:25,676 - ERROR - Status Code: 429
2025-12-15 14:30:25,676 - ERROR - Error Message: 429 Resource has been exhausted (e.g. check quota).
2025-12-15 14:30:25,677 - ERROR - 
2025-12-15 14:30:25,677 - ERROR - 📊 CONCURRENCY INFORMATION:
2025-12-15 14:30:25,677 - ERROR -   Process ID (PID): 27530
2025-12-15 14:30:25,678 - ERROR -   Process Name: run.py
2025-12-15 14:30:25,678 - ERROR -   Thread ID: 127549224711744
2025-12-15 14:30:25,679 - ERROR -   Thread Name: Thread-6 (worker)
2025-12-15 14:30:25,679 - ERROR -   Worker ID: 127549371410240
2025-12-15 14:30:25,680 - ERROR - 
2025-12-15 14:30:25,680 - ERROR - 🔍 FULL ERROR REPRESENTATION:
2025-12-15 14:30:25,681 - ERROR -   ResourceExhausted('Resource has been exhausted (e.g. check quota).')
2025-12-15 14:30:25,682 - ERROR - ================================================================================
2025-12-15 14:30:25,683 - WARNING - ⚠️ Rate limit hit (429) - Attempt 1/3
2025-12-15 14:30:25,684 - WARNING -    Waiting 60.0s before retry... (Error count: 1/5)
2025-12-15 14:31:26,121 - ERROR - ================================================================================
2025-12-15 14:31:26,121 - ERROR - 🔴 RATE LIMIT ERROR (429) - COMPLETE DETAILS
2025-12-15 14:31:26,121 - ERROR - ================================================================================
2025-12-15 14:31:26,121 - ERROR - Error Type: ResourceExhausted
2025-12-15 14:31:26,121 - ERROR - Status Code: 429
2025-12-15 14:31:26,121 - ERROR - Error Message: 429 Resource has been exhausted (e.g. check quota).
2025-12-15 14:31:26,121 - ERROR - 
2025-12-15 14:31:26,121 - ERROR - 📊 CONCURRENCY INFORMATION:
2025-12-15 14:31:26,121 - ERROR -   Process ID (PID): 27530
2025-12-15 14:31:26,121 - ERROR -   Process Name: run.py
2025-12-15 14:31:26,122 - ERROR -   Thread ID: 127549224711744
2025-12-15 14:31:26,122 - ERROR -   Thread Name: Thread-6 (worker)
2025-12-15 14:31:26,122 - ERROR -   Worker ID: 127549371410240
2025-12-15 14:31:26,122 - ERROR - 
2025-12-15 14:31:26,122 - ERROR - 🔍 FULL ERROR REPRESENTATION:
2025-12-15 14:31:26,122 - ERROR -   ResourceExhausted('Resource has been exhausted (e.g. check quota).')
2025-12-15 14:31:26,122 - ERROR - ================================================================================
2025-12-15 14:31:26,122 - WARNING - ⚠️ Rate limit hit (429) - Attempt 2/3
2025-12-15 14:31:26,122 - WARNING -    Waiting 90.0s before retry... (Error count: 2/5)
2025-12-16 08:11:14,862 - INFO - Loaded 6 predefined prompts
2025-12-16 08:13:16,247 - INFO - Loaded 3 API keys
2025-12-16 08:14:03,336 - INFO - === Starting PDF Processing ===
2025-12-16 08:14:03,337 - INFO - Model: gemini-2.5-pro
2025-12-16 08:14:03,337 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 08:14:03,337 - INFO - Full prompt being sent (6000 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple CHUNKS.

IMPORTANT:
- A CHUNK is ONLY a technical split of the RESPONSE due to size limits.
- CHUNKS are identified ONLY by the field "chunk_index".
- CHUNKS have NOTHING to do with the medical or logical structure of the chapter.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE CHUNK of the final output
- NOT repeat rows from previous chunks
- Preserve the exact order of rows across chunks

====================
OUTPUT FORMAT (EXACT)
====================
{
  "chunk_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <integer>
    }
  ]
}

====================
MEANING OF chunk_index
====================
- "chunk_index" indicates ONLY the sequential number of this RESPONSE CHUNK.
- chunk_index = 1 means: first technical chunk of the output.
- chunk_index = 2 means: second technical chunk of the output.
- chunk_index has NO semantic meaning about the chapter content.
- chunk_index MUST strictly increase by 1 across responses.

====================
MEANING OF Part (VERY IMPORTANT)
====================
- "Part" represents the LOGICAL CONTENT PART of the chapter.
- "Part" is NOT related to chunk_index.
- "Part" is the result of grouping AUTHOR PARTS into YOUR OWN PARTS ("Our parts").

How to define "Part":
1) At the beginning of the chapter, there is a "Chapter contents" section that lists
   the author-defined parts ("author parts") and their first page.
2) You MUST group consecutive author parts into larger groups called "Our parts".
3) Each "Our part" MUST:
   - consist of consecutive author parts
   - NOT exceed 10 pages total
4) Assign integer labels starting from 1:
   - Our part 1
   - Our part 2
   - Our part 3
   - etc.

Example:
If author parts have page counts:
2, 4, 5, 3, 1, 7, 5

Then:
- Our part 1 = author parts 1 + 2 (in this example it is wrong to add the third author part because this way the first our part will be 11 pages which is more than 10 pages.)
- Our part 2 = author parts 3 + 4 + 5 (it is correct because they are 9 pages together which is less than 10 pages.)
- Our part 3 = author part 6
- Our part 4 = author part 7

Rules for assigning "Part" in rows:
- Every row MUST have exactly ONE integer "Part" value.
- A single page MAY belong to TWO different "Part" values if an Our part boundary
  occurs in the middle of the page.
- In such cases, split the page text into TWO separate rows:
  - one row with the previous Part value
  - one row with the next Part value
- NEVER mix content from two different Parts inside the same row.
- NEVER change Part value before an author part ends.
====================
PAGE-BY-PAGE FORWARD-ONLY PROCESSING (CRITICAL)
====================
You MUST process the document STRICTLY page by page, in ascending page order.
- NEVER go back to a previous page.
- NEVER re-extract or regenerate content from any page that has already appeared
  in earlier chunks.
- Once a page (or a portion of a page) is output in any chunk, it is considered FINAL.
- Subsequent chunks MUST continue ONLY from the next unprocessed page or page segment.
====================
Rules for rows
====================
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.
====================
Rules for eFig and eTable
====================
- eFigs and eTables are some contents added after the chapter ends. They are not necessarily related contextually to the last our part. They can be related each of the previous our parts.
- you must find that each eFig and eTable belongs to which one of the our parts. 
- so when you are working on each chunk you must also check and find and include the eFigs and eTables that are related contextually to this chunk. Write the correct our part value for each eFig and eTable.
  


====================
CHUNK INSTRUCTIONS
====================
This is CHUNK {chunk_index} of the output.

Generate ONLY the rows that belong to this CHUNK.
Stop when you reach a safe size limit for a single response.
If more content remains after this CHUNK, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate CHUNK {chunk_index}.
2025-12-16 08:14:03,339 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_e5082c0d
2025-12-16 08:14:03,339 - INFO - Final output will be saved to current directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project
2025-12-16 08:14:03,339 - INFO - === Processing Part 1 ===
2025-12-16 08:14:15,419 - INFO - PDF uploaded successfully with API key: bagher
2025-12-16 08:14:15,419 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 08:14:15,420 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-16 08:14:15,421 - INFO - Using max_output_tokens: 32768
2025-12-16 08:14:15,421 - INFO - Using model: gemini-2.5-pro
2025-12-16 08:14:15,422 - INFO - Sending prompt (length: 6113 characters)
2025-12-16 08:14:15,422 - INFO - Max output tokens: 32768
2025-12-16 08:14:15,423 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-16 08:14:15,424 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-16 08:14:15,424 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-16 08:15:59,677 - INFO - ✓ Request completed: 38564 characters received
2025-12-16 08:15:59,678 - INFO - Finish reason: STOP (normal completion)
2025-12-16 08:15:59,679 - INFO - ✓ Response completed normally
2025-12-16 08:15:59,683 - WARNING - Part 1, row 0: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,685 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,686 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,686 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,687 - WARNING - Part 1, row 14: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,687 - WARNING - Part 1, row 17: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,688 - WARNING - Part 1, row 21: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,688 - WARNING - Part 1, row 0: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,689 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,689 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,690 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,690 - WARNING - Part 1, row 14: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,691 - WARNING - Part 1, row 17: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,691 - WARNING - Part 1, row 21: Extraction contains newlines (should use \n)
2025-12-16 08:15:59,692 - INFO - Part 1: Parsed successfully - is_last=False, rows=22
2025-12-16 08:15:59,695 - INFO - Part 1: Added 22 rows (total: 22)
2025-12-16 08:15:59,696 - INFO - Part 1: is_last=false, continuing to next part...
2025-12-16 08:15:59,697 - INFO - Waiting 11.8s before next part...
2025-12-16 08:16:11,464 - INFO - === Processing Part 2 ===
2025-12-16 08:16:24,201 - INFO - PDF uploaded successfully with API key: bagher
2025-12-16 08:16:24,202 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 08:16:24,203 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-16 08:16:24,203 - INFO - Using max_output_tokens: 32768
2025-12-16 08:16:24,204 - INFO - Using model: gemini-2.5-pro
2025-12-16 08:16:24,204 - INFO - Sending prompt (length: 6196 characters)
2025-12-16 08:16:24,205 - INFO - Max output tokens: 32768
2025-12-16 08:16:24,205 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-16 08:16:24,206 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-16 08:16:24,206 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-16 08:18:33,302 - INFO - ✓ Request completed: 28597 characters received
2025-12-16 08:18:33,303 - INFO - Finish reason: STOP (normal completion)
2025-12-16 08:18:33,307 - INFO - ✓ Response completed normally
2025-12-16 08:18:33,311 - WARNING - Part 2, row 4: Extraction contains newlines (should use \n)
2025-12-16 08:18:33,312 - WARNING - Part 2, row 7: Extraction contains newlines (should use \n)
2025-12-16 08:18:33,313 - WARNING - Part 2, row 10: Extraction contains newlines (should use \n)
2025-12-16 08:18:33,313 - WARNING - Part 2, row 14: Extraction contains newlines (should use \n)
2025-12-16 08:18:33,313 - WARNING - Part 2, row 16: Extraction contains newlines (should use \n)
2025-12-16 08:18:33,314 - WARNING - Part 2, row 19: Extraction contains newlines (should use \n)
2025-12-16 08:18:33,314 - WARNING - Part 2, row 4: Extraction contains newlines (should use \n)
2025-12-16 08:18:33,315 - WARNING - Part 2, row 7: Extraction contains newlines (should use \n)
2025-12-16 08:18:33,318 - WARNING - Part 2, row 10: Extraction contains newlines (should use \n)
2025-12-16 08:18:33,320 - WARNING - Part 2, row 14: Extraction contains newlines (should use \n)
2025-12-16 08:18:33,321 - WARNING - Part 2, row 16: Extraction contains newlines (should use \n)
2025-12-16 08:18:33,324 - WARNING - Part 2, row 19: Extraction contains newlines (should use \n)
2025-12-16 08:18:33,324 - INFO - Part 2: Parsed successfully - is_last=False, rows=20
2025-12-16 08:18:33,329 - INFO - Part 2: Added 20 rows (total: 42)
2025-12-16 08:18:33,330 - INFO - Part 2: is_last=false, continuing to next part...
2025-12-16 08:18:33,333 - INFO - Waiting 9.5s before next part...
2025-12-16 08:18:42,846 - INFO - === Processing Part 3 ===
2025-12-16 08:18:55,139 - INFO - PDF uploaded successfully with API key: bagher
2025-12-16 08:18:55,141 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 08:18:55,144 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-16 08:18:55,146 - INFO - Using max_output_tokens: 32768
2025-12-16 08:18:55,150 - INFO - Using model: gemini-2.5-pro
2025-12-16 08:18:55,151 - INFO - Sending prompt (length: 6196 characters)
2025-12-16 08:18:55,151 - INFO - Max output tokens: 32768
2025-12-16 08:18:55,152 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-16 08:18:55,152 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-16 08:18:55,155 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-16 08:20:40,431 - INFO - ✓ Request completed: 28316 characters received
2025-12-16 08:20:40,433 - INFO - Finish reason: STOP (normal completion)
2025-12-16 08:20:40,433 - INFO - ✓ Response completed normally
2025-12-16 08:20:40,437 - WARNING - Part 3, row 4: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,438 - WARNING - Part 3, row 6: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,439 - WARNING - Part 3, row 9: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,439 - WARNING - Part 3, row 11: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,440 - WARNING - Part 3, row 12: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,440 - WARNING - Part 3, row 13: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,440 - WARNING - Part 3, row 14: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,441 - WARNING - Part 3, row 4: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,442 - WARNING - Part 3, row 6: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,442 - WARNING - Part 3, row 9: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,443 - WARNING - Part 3, row 11: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,443 - WARNING - Part 3, row 12: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,444 - WARNING - Part 3, row 13: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,444 - WARNING - Part 3, row 14: Extraction contains newlines (should use \n)
2025-12-16 08:20:40,445 - INFO - Part 3: Parsed successfully - is_last=False, rows=25
2025-12-16 08:20:40,450 - INFO - Part 3: Added 25 rows (total: 67)
2025-12-16 08:20:40,451 - INFO - Part 3: is_last=false, continuing to next part...
2025-12-16 08:20:40,455 - INFO - Waiting 9.1s before next part...
2025-12-16 08:20:49,538 - INFO - === Processing Part 4 ===
2025-12-16 08:21:01,542 - INFO - PDF uploaded successfully with API key: bagher
2025-12-16 08:21:01,542 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 08:21:01,543 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-16 08:21:01,544 - INFO - Using max_output_tokens: 32768
2025-12-16 08:21:01,544 - INFO - Using model: gemini-2.5-pro
2025-12-16 08:21:01,544 - INFO - Sending prompt (length: 6196 characters)
2025-12-16 08:21:01,545 - INFO - Max output tokens: 32768
2025-12-16 08:21:01,546 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-16 08:21:01,546 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-16 08:21:01,547 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-16 08:22:28,406 - INFO - ✓ Request completed: 24451 characters received
2025-12-16 08:22:28,407 - INFO - Finish reason: STOP (normal completion)
2025-12-16 08:22:28,408 - INFO - ✓ Response completed normally
2025-12-16 08:22:28,411 - WARNING - Part 4, row 1: Extraction contains newlines (should use \n)
2025-12-16 08:22:28,411 - WARNING - Part 4, row 2: Extraction contains newlines (should use \n)
2025-12-16 08:22:28,412 - WARNING - Part 4, row 6: Extraction contains newlines (should use \n)
2025-12-16 08:22:28,412 - WARNING - Part 4, row 7: Extraction contains newlines (should use \n)
2025-12-16 08:22:28,413 - WARNING - Part 4, row 1: Extraction contains newlines (should use \n)
2025-12-16 08:22:28,413 - WARNING - Part 4, row 2: Extraction contains newlines (should use \n)
2025-12-16 08:22:28,413 - WARNING - Part 4, row 6: Extraction contains newlines (should use \n)
2025-12-16 08:22:28,414 - WARNING - Part 4, row 7: Extraction contains newlines (should use \n)
2025-12-16 08:22:28,414 - INFO - Part 4: Parsed successfully - is_last=False, rows=8
2025-12-16 08:22:28,417 - INFO - Part 4: Added 8 rows (total: 75)
2025-12-16 08:22:28,417 - INFO - Part 4: is_last=false, continuing to next part...
2025-12-16 08:22:28,418 - INFO - Waiting 11.2s before next part...
2025-12-16 08:22:39,584 - INFO - === Processing Part 5 ===
2025-12-16 08:22:50,694 - INFO - PDF uploaded successfully with API key: bagher
2025-12-16 08:22:50,695 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 08:22:50,696 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-16 08:22:50,696 - INFO - Using max_output_tokens: 32768
2025-12-16 08:22:50,697 - INFO - Using model: gemini-2.5-pro
2025-12-16 08:22:50,697 - INFO - Sending prompt (length: 6196 characters)
2025-12-16 08:22:50,699 - INFO - Max output tokens: 32768
2025-12-16 08:22:50,702 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-16 08:22:50,703 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-16 08:22:50,705 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-16 08:25:01,175 - INFO - ✓ Request completed: 52217 characters received
2025-12-16 08:25:01,177 - INFO - Finish reason: STOP (normal completion)
2025-12-16 08:25:01,177 - INFO - ✓ Response completed normally
2025-12-16 08:25:01,182 - ERROR - Part 5: JSON parse error: Expecting ',' delimiter: line 128 column 20 (char 45517)
2025-12-16 08:25:01,184 - ERROR - Part 5: Response text (first 1000 chars): {
  "chunk_index": 5,
  "is_last": true,
  "rows": [
    {
      "Type": "Table",
      "Extraction": "{\"Title\": \"THERAPEUTIC LADDER FOR BULLOUS PEMPHIGOID\", \"Number\": \"30.4\", \"Header\": [\"\", \"\"], \"Body\": [{\"Row\": [\"Mild and/or localized disease\", \"\"]}, {\"Row\": [\"First-line\", \"• Superpotent topical corticosteroids (1*)\\n• Oral corticosteroidst (1)\\n• Minocycline, doxycycline or tetracycline, alone or in combination with nicotinamide (1)\"]}, {\"Row\": [\"Second-line\", \"• Topical immunomodulators (e.g. tacrolimus) (3)\\n• Dapsone, sulfonamides (3)\\n• Erythromycin, penicillins (3)\"]}, {\"Row\": [\"Extensive/persistent cutaneous disease\", \"\"]}, {\"Row\": [\"First-line, as primary treatment\", \"• Superpotent topical corticosteroids (1*)\\n• Oral corticosteroids+ (1+)\"]}, {\"Row\": [\"Second-line, or as adjunctive therapy\", \"• Azathioprine (1)\\n• Mycophenolate mofetil (1)\\n• Methotrexate# (2)\\n• Omalizumab (3)\\n• Dupilumab (3)\\n• IVIg (1)\\n• Ritu
2025-12-16 08:25:01,184 - ERROR - Part 5: Response text (last 500 chars): overlying joints. Note the resemblance to dystrophic epidermolysis bullosa. *Courtesy Kalman Watsky, MD.*\", \"Labels\": []}",
      "Number": 533.e4,
      "Part": 2
    },
    {
      "Type": "Figure",
      "Extraction": "{\"Number\": \"eFig. 30.18\", \"Description\": \"**Epidermolysis bullosa acquisita - inflammatory bullous pemphigoid-like presentation.** Bullae and circular erosions in a patient with multiple myeloma.\", \"Labels\": []}",
      "Number": 533.e4,
      "Part": 2
    }
  ]
}
2025-12-16 08:25:01,185 - ERROR - Part 5: Failed to parse response
2025-12-16 08:25:01,185 - ERROR - Part 5: Response text (first 1000 chars): ```json
{
  "chunk_index": 5,
  "is_last": true,
  "rows": [
    {
      "Type": "Table",
      "Extraction": "{\"Title\": \"THERAPEUTIC LADDER FOR BULLOUS PEMPHIGOID\", \"Number\": \"30.4\", \"Header\": [\"\", \"\"], \"Body\": [{\"Row\": [\"Mild and/or localized disease\", \"\"]}, {\"Row\": [\"First-line\", \"• Superpotent topical corticosteroids (1*)\\n• Oral corticosteroidst (1)\\n• Minocycline, doxycycline or tetracycline, alone or in combination with nicotinamide (1)\"]}, {\"Row\": [\"Second-line\", \"• Topical immunomodulators (e.g. tacrolimus) (3)\\n• Dapsone, sulfonamides (3)\\n• Erythromycin, penicillins (3)\"]}, {\"Row\": [\"Extensive/persistent cutaneous disease\", \"\"]}, {\"Row\": [\"First-line, as primary treatment\", \"• Superpotent topical corticosteroids (1*)\\n• Oral corticosteroids+ (1+)\"]}, {\"Row\": [\"Second-line, or as adjunctive therapy\", \"• Azathioprine (1)\\n• Mycophenolate mofetil (1)\\n• Methotrexate# (2)\\n• Omalizumab (3)\\n• Dupilumab (3)\\n• IVIg (1)\
2025-12-16 08:25:01,186 - ERROR - Part 5: Retrying same part...
2025-12-16 08:25:06,186 - INFO - === Processing Part 5 ===
2025-12-16 08:25:19,368 - INFO - PDF uploaded successfully with API key: bagher
2025-12-16 08:25:19,369 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 08:25:19,370 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-16 08:25:19,370 - INFO - Using max_output_tokens: 32768
2025-12-16 08:25:19,371 - INFO - Using model: gemini-2.5-pro
2025-12-16 08:25:19,372 - INFO - Sending prompt (length: 6196 characters)
2025-12-16 08:25:19,372 - INFO - Max output tokens: 32768
2025-12-16 08:25:19,373 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-16 08:25:19,373 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-16 08:25:19,374 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-16 08:26:31,443 - INFO - ✓ Request completed: 11539 characters received
2025-12-16 08:26:31,445 - INFO - Finish reason: STOP (normal completion)
2025-12-16 08:26:31,445 - INFO - ✓ Response completed normally
2025-12-16 08:26:31,446 - INFO - Part 5: Parsed successfully - is_last=True, rows=19
2025-12-16 08:26:31,446 - INFO - Part 5: Added 19 rows (total: 94)
2025-12-16 08:26:31,446 - INFO - Part 5: is_last=true, processing complete!
2025-12-16 08:26:31,447 - INFO - === Processing Summary ===
2025-12-16 08:26:31,447 - INFO - Parts processed: 4
2025-12-16 08:26:31,447 - INFO - Total parts in final output: 4
2025-12-16 08:26:31,447 - INFO - Total rows collected: 94
2025-12-16 08:26:31,447 - INFO - Deduplicating 94 rows...
2025-12-16 08:26:31,450 - WARNING - Removed 7 duplicate rows using enhanced deduplication
2025-12-16 08:26:31,451 - INFO - Final row count after deduplication: 87
2025-12-16 08:26:31,451 - INFO - Sorting 87 rows by Number (as float)...
2025-12-16 08:26:31,451 - INFO - Rows sorted successfully
2025-12-16 08:26:31,455 - INFO - ✓ Final JSON output saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-16 08:26:31,456 - INFO -   - File path: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-16 08:26:31,456 - INFO -   - Total parts: 4
2025-12-16 08:26:31,456 - INFO -   - Total rows: 87
2025-12-16 08:26:31,456 - INFO -   - File size: 122.12 KB
2025-12-16 08:26:31,464 - INFO - ✓ Final CSV output saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.csv
2025-12-16 08:26:31,464 - INFO -   - File path: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.csv
2025-12-16 08:26:31,464 - INFO -   - Total rows: 87
2025-12-16 08:26:31,464 - INFO -   - File size: 114.72 KB
2025-12-16 08:31:01,891 - INFO - Processing Part 1 with second-stage prompt...
2025-12-16 08:32:22,443 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-16 08:32:22,448 - INFO - Processing Part 2 with second-stage prompt...
2025-12-16 08:33:38,485 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-16 08:33:38,488 - INFO - Processing Part 3 with second-stage prompt...
2025-12-16 08:35:03,542 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-16 08:35:03,571 - INFO - Post-processed JSON saved to: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed.json
2025-12-16 09:16:50,393 - INFO - Loaded 6 predefined prompts
2025-12-16 09:32:05,510 - INFO - Loaded 6 predefined prompts
2025-12-16 09:38:02,469 - INFO - Loaded 6 predefined prompts
2025-12-16 09:39:57,718 - INFO - Loaded 6 predefined prompts
2025-12-16 09:40:53,025 - INFO - Loaded 6 predefined prompts
2025-12-16 09:41:16,577 - INFO - Loaded 3 API keys
2025-12-16 10:06:17,222 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-16 10:24:06,643 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-16 10:25:32,448 - INFO - Loaded 6 predefined prompts
2025-12-16 11:47:53,012 - INFO - Loaded 6 predefined prompts
2025-12-16 11:50:23,422 - INFO - Loaded 3 API keys
2025-12-16 11:58:36,808 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-16 12:03:56,843 - INFO - Loaded 6 predefined prompts
2025-12-16 12:04:19,840 - INFO - Loaded 3 API keys
2025-12-16 12:08:31,630 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-16 12:11:30,411 - INFO - Loaded 6 predefined prompts
2025-12-16 12:11:51,575 - INFO - Loaded 3 API keys
2025-12-16 12:16:11,146 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-16 12:57:21,708 - INFO - Loaded 6 predefined prompts
2025-12-16 12:58:12,342 - INFO - Loaded 3 API keys
2025-12-16 13:00:43,423 - INFO - === Starting PDF Processing ===
2025-12-16 13:00:43,423 - INFO - Model: gemini-2.5-pro
2025-12-16 13:00:43,423 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 13:00:43,424 - INFO - Full prompt being sent (5165 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple CHUNKS.

IMPORTANT:
- A CHUNK is ONLY a technical split of the RESPONSE due to size limits.
- CHUNKS are identified ONLY by the field "chunk_index".
- CHUNKS have NOTHING to do with the medical or logical structure of the chapter.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE CHUNK of the final output
- NOT repeat rows from previous chunks
- Preserve the exact order of rows across chunks

====================
OUTPUT FORMAT (EXACT)
====================
{
  "chunk_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <integer>
    }
  ]
}

====================
MEANING OF chunk_index
====================
- "chunk_index" indicates ONLY the sequential number of this RESPONSE CHUNK.
- chunk_index = 1 means: first technical chunk of the output.
- chunk_index = 2 means: second technical chunk of the output.
- chunk_index has NO semantic meaning about the chapter content.
- chunk_index MUST strictly increase by 1 across responses.

====================
MEANING OF Part (VERY IMPORTANT)
====================
- "Part" represents the LOGICAL CONTENT PART of the chapter.
- "Part" is NOT related to chunk_index.

How to define "Part":
1) At the beginning of the chapter, there is a "Chapter contents" section that lists
   the parts and their first page.
2) Assign integer labels starting from 1:
   - part 1
   - part 2
   - part 3
   - etc.


Rules for assigning "Part" in rows:
- Every row MUST have exactly ONE integer "Part" value.
- A single page MAY belong to more than one "Part" values if a part boundary
  occurs in the middle of the page.
- In such cases, split the page text into multiple separate rows:
  - one row for the text of the previous part with the previous Part value
  - one row for the text of the next part with the next Part value
- NEVER mix content from two different Parts inside the same row.
- NEVER change Part value before a part ends.
====================
PAGE-BY-PAGE FORWARD-ONLY PROCESSING (CRITICAL)
====================
You MUST process the document STRICTLY page by page, in ascending page order.
- NEVER go back to a previous page.
- NEVER re-extract or regenerate content from any page that has already appeared
  in earlier chunks.
- Once a page (or a portion of a page) is output in any chunk, it is considered FINAL.
- Subsequent chunks MUST continue ONLY from the next unprocessed page or page segment.
====================
Rules for rows
====================
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.
====================
Rules for eFig and eTable
====================
- eFigs and eTables are some contents added after the chapter ends. They are not necessarily related contextually to the last part. They can be related each of the previous parts.
- you must find that each eFig and eTable belongs to which one of the parts. 
- so when you are working on each chunk you must also check and find and include the eFigs and eTables that are related contextually to this chunk. Write the correct part value for each eFig and eTable.
  


====================
CHUNK INSTRUCTIONS
====================
This is CHUNK {chunk_index} of the output.

Generate ONLY the rows that belong to this CHUNK.
Stop when you reach a safe size limit for a single response.
If more content remains after this CHUNK, set:
  "is_last": false
Otherwise set:
  "is_last": true


====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate CHUNK {chunk_index}.
2025-12-16 13:00:43,429 - INFO - Parts directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/parts_Bolognia 5th Edition 2024 (1)-7-26-46.pdf_d9f553c4
2025-12-16 13:00:43,430 - INFO - Final output will be saved to current directory: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project
2025-12-16 13:00:43,430 - INFO - === Processing Part 1 ===
2025-12-16 13:00:59,270 - INFO - PDF uploaded successfully with API key: bagher
2025-12-16 13:00:59,271 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 13:00:59,271 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-16 13:00:59,272 - INFO - Using max_output_tokens: 32768
2025-12-16 13:00:59,272 - INFO - Using model: gemini-2.5-pro
2025-12-16 13:00:59,273 - INFO - Sending prompt (length: 5278 characters)
2025-12-16 13:00:59,273 - INFO - Max output tokens: 32768
2025-12-16 13:00:59,273 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-16 13:00:59,274 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-16 13:00:59,274 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-16 13:02:35,059 - INFO - ✓ Request completed: 30770 characters received
2025-12-16 13:02:35,060 - INFO - Finish reason: STOP (normal completion)
2025-12-16 13:02:35,062 - INFO - ✓ Response completed normally
2025-12-16 13:02:35,066 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,067 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,067 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,068 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,068 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,069 - WARNING - Part 1, row 9: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,069 - WARNING - Part 1, row 10: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,070 - WARNING - Part 1, row 14: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,071 - WARNING - Part 1, row 16: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,072 - WARNING - Part 1, row 17: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,073 - WARNING - Part 1, row 18: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,073 - WARNING - Part 1, row 19: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,074 - WARNING - Part 1, row 23: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,074 - WARNING - Part 1, row 25: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,075 - WARNING - Part 1, row 26: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,075 - WARNING - Part 1, row 27: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,076 - WARNING - Part 1, row 31: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,076 - WARNING - Part 1, row 32: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,077 - WARNING - Part 1, row 33: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,078 - WARNING - Part 1, row 2: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,079 - WARNING - Part 1, row 5: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,080 - WARNING - Part 1, row 6: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,080 - WARNING - Part 1, row 7: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,081 - WARNING - Part 1, row 8: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,082 - WARNING - Part 1, row 9: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,083 - WARNING - Part 1, row 10: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,083 - WARNING - Part 1, row 14: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,084 - WARNING - Part 1, row 16: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,084 - WARNING - Part 1, row 17: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,086 - WARNING - Part 1, row 18: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,087 - WARNING - Part 1, row 19: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,089 - WARNING - Part 1, row 23: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,089 - WARNING - Part 1, row 25: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,094 - WARNING - Part 1, row 26: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,095 - WARNING - Part 1, row 27: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,095 - WARNING - Part 1, row 31: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,096 - WARNING - Part 1, row 32: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,096 - WARNING - Part 1, row 33: Extraction contains newlines (should use \n)
2025-12-16 13:02:35,101 - INFO - Part 1: Parsed successfully - is_last=False, rows=34
2025-12-16 13:02:35,116 - INFO - Part 1: Added 34 rows (total: 34)
2025-12-16 13:02:35,118 - INFO - Part 1: is_last=false, continuing to next part...
2025-12-16 13:02:35,121 - INFO - Waiting 12.9s before next part...
2025-12-16 13:02:48,006 - INFO - === Processing Part 2 ===
2025-12-16 13:02:56,846 - INFO - PDF uploaded successfully with API key: bagher
2025-12-16 13:02:56,847 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 13:02:56,848 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-16 13:02:56,848 - INFO - Using max_output_tokens: 32768
2025-12-16 13:02:56,849 - INFO - Using model: gemini-2.5-pro
2025-12-16 13:02:56,849 - INFO - Sending prompt (length: 5361 characters)
2025-12-16 13:02:56,849 - INFO - Max output tokens: 32768
2025-12-16 13:02:56,850 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-16 13:02:56,850 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-16 13:02:56,851 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-16 13:04:43,747 - INFO - ✓ Request completed: 38991 characters received
2025-12-16 13:04:43,748 - INFO - Finish reason: STOP (normal completion)
2025-12-16 13:04:43,749 - INFO - ✓ Response completed normally
2025-12-16 13:04:43,753 - INFO - Part 2: Parsed successfully - is_last=False, rows=22
2025-12-16 13:04:43,758 - INFO - Part 2: Added 22 rows (total: 56)
2025-12-16 13:04:43,759 - INFO - Part 2: is_last=false, continuing to next part...
2025-12-16 13:04:43,760 - INFO - Waiting 8.8s before next part...
2025-12-16 13:04:52,543 - INFO - === Processing Part 3 ===
2025-12-16 13:05:02,684 - INFO - PDF uploaded successfully with API key: bagher
2025-12-16 13:05:02,685 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 13:05:02,686 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-16 13:05:02,687 - INFO - Using max_output_tokens: 32768
2025-12-16 13:05:02,687 - INFO - Using model: gemini-2.5-pro
2025-12-16 13:05:02,689 - INFO - Sending prompt (length: 5361 characters)
2025-12-16 13:05:02,690 - INFO - Max output tokens: 32768
2025-12-16 13:05:02,690 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-16 13:05:02,691 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-16 13:05:02,691 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-16 13:07:15,043 - INFO - ✓ Request completed: 39824 characters received
2025-12-16 13:07:15,045 - INFO - Finish reason: STOP (normal completion)
2025-12-16 13:07:15,046 - INFO - ✓ Response completed normally
2025-12-16 13:07:15,050 - WARNING - Part 3, row 3: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,051 - WARNING - Part 3, row 4: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,051 - WARNING - Part 3, row 5: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,052 - WARNING - Part 3, row 9: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,052 - WARNING - Part 3, row 10: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,052 - WARNING - Part 3, row 14: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,053 - WARNING - Part 3, row 15: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,054 - WARNING - Part 3, row 16: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,055 - WARNING - Part 3, row 19: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,056 - WARNING - Part 3, row 20: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,056 - WARNING - Part 3, row 22: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,057 - WARNING - Part 3, row 24: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,057 - WARNING - Part 3, row 25: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,058 - WARNING - Part 3, row 26: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,058 - WARNING - Part 3, row 27: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,059 - WARNING - Part 3, row 28: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,059 - WARNING - Part 3, row 29: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,060 - WARNING - Part 3, row 3: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,060 - WARNING - Part 3, row 4: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,061 - WARNING - Part 3, row 5: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,061 - WARNING - Part 3, row 9: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,062 - WARNING - Part 3, row 10: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,062 - WARNING - Part 3, row 14: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,063 - WARNING - Part 3, row 15: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,063 - WARNING - Part 3, row 16: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,064 - WARNING - Part 3, row 19: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,064 - WARNING - Part 3, row 20: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,065 - WARNING - Part 3, row 22: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,065 - WARNING - Part 3, row 24: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,067 - WARNING - Part 3, row 25: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,067 - WARNING - Part 3, row 26: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,068 - WARNING - Part 3, row 27: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,068 - WARNING - Part 3, row 28: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,068 - WARNING - Part 3, row 29: Extraction contains newlines (should use \n)
2025-12-16 13:07:15,070 - INFO - Part 3: Parsed successfully - is_last=False, rows=40
2025-12-16 13:07:15,076 - INFO - Part 3: Added 40 rows (total: 96)
2025-12-16 13:07:15,077 - INFO - Part 3: is_last=false, continuing to next part...
2025-12-16 13:07:15,079 - INFO - Waiting 11.3s before next part...
2025-12-16 13:07:26,334 - INFO - === Processing Part 4 ===
2025-12-16 13:07:37,115 - INFO - PDF uploaded successfully with API key: bagher
2025-12-16 13:07:37,116 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 13:07:37,117 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-16 13:07:37,117 - INFO - Using max_output_tokens: 32768
2025-12-16 13:07:37,118 - INFO - Using model: gemini-2.5-pro
2025-12-16 13:07:37,118 - INFO - Sending prompt (length: 5361 characters)
2025-12-16 13:07:37,119 - INFO - Max output tokens: 32768
2025-12-16 13:07:37,119 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-16 13:07:37,120 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-16 13:07:37,120 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-16 13:09:18,928 - INFO - ✓ Request completed: 37874 characters received
2025-12-16 13:09:18,929 - INFO - Finish reason: STOP (normal completion)
2025-12-16 13:09:18,930 - INFO - ✓ Response completed normally
2025-12-16 13:09:18,934 - WARNING - Part 4, row 2: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,935 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,935 - WARNING - Part 4, row 7: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,936 - WARNING - Part 4, row 9: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,937 - WARNING - Part 4, row 10: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,938 - WARNING - Part 4, row 11: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,938 - WARNING - Part 4, row 15: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,939 - WARNING - Part 4, row 2: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,940 - WARNING - Part 4, row 4: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,940 - WARNING - Part 4, row 7: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,941 - WARNING - Part 4, row 9: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,942 - WARNING - Part 4, row 10: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,943 - WARNING - Part 4, row 11: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,944 - WARNING - Part 4, row 15: Extraction contains newlines (should use \n)
2025-12-16 13:09:18,944 - INFO - Part 4: Parsed successfully - is_last=False, rows=16
2025-12-16 13:09:18,949 - INFO - Part 4: Added 16 rows (total: 112)
2025-12-16 13:09:18,951 - INFO - Part 4: is_last=false, continuing to next part...
2025-12-16 13:09:18,953 - INFO - Waiting 10.7s before next part...
2025-12-16 13:09:29,657 - INFO - === Processing Part 5 ===
2025-12-16 13:09:39,416 - INFO - PDF uploaded successfully with API key: bagher
2025-12-16 13:09:39,417 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-7-26-46.pdf
2025-12-16 13:09:39,418 - INFO - Model: gemini-2.5-pro, Max tokens for model: 32768, Using: 32768
2025-12-16 13:09:39,418 - INFO - Using max_output_tokens: 32768
2025-12-16 13:09:39,419 - INFO - Using model: gemini-2.5-pro
2025-12-16 13:09:39,420 - INFO - Sending prompt (length: 5361 characters)
2025-12-16 13:09:39,420 - INFO - Max output tokens: 32768
2025-12-16 13:09:39,421 - INFO - Multi-part mode: Using user's prompt as-is
2025-12-16 13:09:39,421 - INFO - Streaming disabled (force_no_streaming=True for multi-part processing)
2025-12-16 13:09:39,422 - INFO - Generating content with NON-STREAMING (large request detected to avoid rate limits)...
2025-12-16 13:12:47,416 - INFO - ✓ Request completed: 72688 characters received
2025-12-16 13:12:47,418 - INFO - Finish reason: STOP (normal completion)
2025-12-16 13:12:47,419 - INFO - ✓ Response completed normally
2025-12-16 13:12:47,427 - INFO - Part 5: Parsed successfully - is_last=True, rows=50
2025-12-16 13:12:47,435 - INFO - Part 5: Added 50 rows (total: 162)
2025-12-16 13:12:47,436 - INFO - Part 5: is_last=true, processing complete!
2025-12-16 13:12:47,437 - INFO - === Processing Summary ===
2025-12-16 13:12:47,438 - INFO - Parts processed: 4
2025-12-16 13:12:47,439 - INFO - Total parts in final output: 4
2025-12-16 13:12:47,439 - INFO - Total rows collected: 162
2025-12-16 13:12:47,440 - INFO - Deduplicating 162 rows...
2025-12-16 13:12:47,465 - WARNING - Removed 19 duplicate rows using enhanced deduplication
2025-12-16 13:12:47,466 - INFO - Final row count after deduplication: 143
2025-12-16 13:12:47,467 - INFO - Sorting 143 rows by Number (as float)...
2025-12-16 13:12:47,468 - INFO - Rows sorted successfully
2025-12-16 13:12:47,497 - INFO - ✓ Final JSON output saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-16 13:12:47,498 - INFO -   - File path: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-16 13:12:47,498 - INFO -   - Total parts: 4
2025-12-16 13:12:47,498 - INFO -   - Total rows: 143
2025-12-16 13:12:47,498 - INFO -   - File size: 208.99 KB
2025-12-16 13:12:47,523 - INFO - ✓ Final CSV output saved to /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.csv
2025-12-16 13:12:47,523 - INFO -   - File path: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.csv
2025-12-16 13:12:47,524 - INFO -   - Total rows: 143
2025-12-16 13:12:47,524 - INFO -   - File size: 197.15 KB
2025-12-16 13:20:51,361 - INFO - Processing Part 1 with second-stage prompt...
2025-12-16 13:23:00,595 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-16 13:23:00,597 - ERROR - Failed to parse JSON response in post-processor
2025-12-16 13:23:00,599 - ERROR - Failed to parse JSON for Part 1, aborting
2025-12-16 13:25:13,654 - INFO - Processing Part 1 with second-stage prompt...
2025-12-16 13:27:17,012 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-16 13:27:17,017 - ERROR - Failed to parse JSON response in post-processor
2025-12-16 13:27:17,019 - ERROR - Failed to parse JSON for Part 1, aborting
2025-12-16 13:40:29,387 - INFO - Processing Part 1 with second-stage prompt...
2025-12-16 13:42:07,000 - INFO - Loaded 6 predefined prompts
2025-12-16 13:44:32,605 - INFO - Loaded 3 API keys
2025-12-16 13:46:16,187 - INFO - Processing Part 1 with second-stage prompt...
2025-12-16 13:48:24,748 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-16 13:48:24,752 - ERROR - Failed to parse JSON response in post-processor
2025-12-16 13:48:24,752 - ERROR - Failed to parse JSON for Part 1, aborting
2025-12-16 14:03:35,551 - INFO - Loaded 6 predefined prompts
2025-12-16 14:03:53,879 - INFO - Loaded 3 API keys
2025-12-16 14:05:22,669 - INFO - Processing Part 1 with second-stage prompt...
2025-12-16 14:05:25,117 - ERROR - Text processing failed: 429 Resource has been exhausted (e.g. check quota).
2025-12-16 14:05:25,118 - ERROR - No response for Part 1, aborting post-process
2025-12-16 14:07:50,009 - INFO - Processing Part 1 with second-stage prompt...
2025-12-16 14:07:51,359 - ERROR - Text processing failed: 429 Resource has been exhausted (e.g. check quota).
2025-12-16 14:07:51,359 - ERROR - No response for Part 1, aborting post-process
2025-12-16 14:10:22,411 - INFO - === Starting PDF Processing ===
2025-12-16 14:10:22,412 - INFO - Model: gemini-2.5-pro
2025-12-16 14:10:22,413 - INFO - PDF: /home/mohammadbagher/Downloads/PDFs/Bolognia 5th Edition 2024 (1)-29-6-22.pdf
2025-12-16 14:10:22,413 - INFO - Full prompt being sent (6000 chars): You are a meticulous medical OCR & structuring assistant.

Your job is to extract ONLY what is present on each provided textbook page image/PDF
and convert it into clean, AI-ready text with structured sections.

You MUST avoid hallucinations and preserve original medical meaning precisely.

====================
GLOBAL PRINCIPLES
====================
- NO HALLUCINATIONS: Output only content visible on the page(s). If unreadable/unclear, write "[UNREADABLE]" or add an "uncertain" flag with brief reason.
- LANGUAGE & SPELLING: Preserve original English spelling and medical terminology.
- CLEAN OCR:
  - Remove headers/footers and running titles.
  - Fix broken words at line breaks.
  - Replace ligatures (ﬁ, ﬂ).
  - Preserve italics (*italic*), bold (**bold**), and subscripts/superscripts via LaTeX.
- CITATIONS: Keep in-text citations verbatim.
- MATH/CHEM: Use inline LaTeX.
- NO IMAGES: Describe figures textually only; do not invent labels.

====================
CRITICAL OUTPUT CONTRACT (MULTI-PART)
====================
The full output is TOO LARGE to fit in one response.

You MUST split the final output into multiple CHUNKS.

IMPORTANT:
- A CHUNK is ONLY a technical split of the RESPONSE due to size limits.
- CHUNKS are identified ONLY by the field "chunk_index".
- CHUNKS have NOTHING to do with the medical or logical structure of the chapter.

Each response MUST:
- Output ONLY valid JSON
- Contain ONLY ONE CHUNK of the final output
- NOT repeat rows from previous chunks
- Preserve the exact order of rows across chunks

====================
OUTPUT FORMAT (EXACT)
====================
{
  "chunk_index": <integer starting from 1>,
  "is_last": <true | false>,
  "rows": [
    {
      "Type": "page text | Figure | Table",
      "Extraction": "<single-line text or JSON>",
      "Number": <page number>,
      "Part": <integer>
    }
  ]
}

====================
MEANING OF chunk_index
====================
- "chunk_index" indicates ONLY the sequential number of this RESPONSE CHUNK.
- chunk_index = 1 means: first technical chunk of the output.
- chunk_index = 2 means: second technical chunk of the output.
- chunk_index has NO semantic meaning about the chapter content.
- chunk_index MUST strictly increase by 1 across responses.

====================
MEANING OF Part (VERY IMPORTANT)
====================
- "Part" represents the LOGICAL CONTENT PART of the chapter.
- "Part" is NOT related to chunk_index.
- "Part" is the result of grouping AUTHOR PARTS into YOUR OWN PARTS ("Our parts").

How to define "Part":
1) At the beginning of the chapter, there is a "Chapter contents" section that lists
   the author-defined parts ("author parts") and their first page.
2) You MUST group consecutive author parts into larger groups called "Our parts".
3) Each "Our part" MUST:
   - consist of consecutive author parts
   - NOT exceed 10 pages total
4) Assign integer labels starting from 1:
   - Our part 1
   - Our part 2
   - Our part 3
   - etc.

Example:
If author parts have page counts:
2, 4, 5, 3, 1, 7, 5

Then:
- Our part 1 = author parts 1 + 2 (in this example it is wrong to add the third author part because this way the first our part will be 11 pages which is more than 10 pages.)
- Our part 2 = author parts 3 + 4 + 5 (it is correct because they are 9 pages together which is less than 10 pages.)
- Our part 3 = author part 6
- Our part 4 = author part 7

Rules for assigning "Part" in rows:
- Every row MUST have exactly ONE integer "Part" value.
- A single page MAY belong to TWO different "Part" values if an Our part boundary
  occurs in the middle of the page.
- In such cases, split the page text into TWO separate rows:
  - one row with the previous Part value
  - one row with the next Part value
- NEVER mix content from two different Parts inside the same row.
- NEVER change Part value before an author part ends.
====================
PAGE-BY-PAGE FORWARD-ONLY PROCESSING (CRITICAL)
====================
You MUST process the document STRICTLY page by page, in ascending page order.
- NEVER go back to a previous page.
- NEVER re-extract or regenerate content from any page that has already appeared
  in earlier chunks.
- Once a page (or a portion of a page) is output in any chunk, it is considered FINAL.
- Subsequent chunks MUST continue ONLY from the next unprocessed page or page segment.
====================
Rules for rows
====================
- Each row represents exactly ONE of:
  - page text
  - figure
  - table
- Extraction MUST be single-line (no ENTER).
- JSON inside Extraction MUST be minified and valid.
- References section at end of chapter MUST be ignored.
====================
Rules for eFig and eTable
====================
- eFigs and eTables are some contents added after the chapter ends. They are not necessarily related contextually to the last our part. They can be related each of the previous our parts.
- you must find that each eFig and eTable belongs to which one of the our parts. 
- so when you are working on each chunk you must also check and find and include the eFigs and eTables that are related contextually to this chunk. Write the correct our part value for each eFig and eTable.
  


====================
CHUNK INSTRUCTIONS
====================
This is CHUNK {chunk_index} of the output.

Generate ONLY the rows that belong to this CHUNK.
Stop when you reach a safe size limit for a single response.
If more content remains after this CHUNK, set:
  "is_last": false
Otherwise set:
  "is_last": true

====================
AUTHOR PARTS → OUR PARTS RULES
====================
[keep your full original rules here verbatim — unchanged]

====================
FINAL RULES
====================
- DO NOT summarize.
- DO NOT explain.
- DO NOT add commentary.
- Output ONLY the JSON object described above.

You will now receive a PDF.
Generate CHUNK {chunk_index}.
2025-12-16 14:10:22,457 - INFO - Processing PDF with 17 pages in batches of 10 pages
2025-12-16 14:10:22,458 - INFO - Using original prompt with JSON output instruction for batch processing (prompt preserved)
2025-12-16 14:10:30,777 - INFO - Uploaded PDF file: Bolognia 5th Edition 2024 (1)-29-6-22.pdf
2025-12-16 14:10:30,778 - INFO - Processing batch 1/2: pages 1-10
2025-12-16 14:13:32,355 - INFO - ✓ Batch pages 1-10: Completed normally
2025-12-16 14:13:32,356 - INFO - Extracted content from generic code block
2025-12-16 14:13:32,356 - INFO - Found JSON array in 'rows' key with 55 items
2025-12-16 14:13:32,356 - INFO - Batch pages 1-10: Extracted 55 rows
2025-12-16 14:13:32,360 - INFO - Processing batch 2/2: pages 11-17
2025-12-16 14:16:00,995 - INFO - ✓ Batch pages 11-17: Completed normally
2025-12-16 14:16:00,997 - INFO - Extracted content from generic code block
2025-12-16 14:16:01,001 - INFO - Found JSON array in 'rows' key with 55 items
2025-12-16 14:16:01,001 - INFO - Batch pages 11-17: Extracted 55 rows
2025-12-16 14:16:01,035 - INFO - JSON saved to: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 (1)-29-6-22_output_20251216_141601.json
2025-12-16 14:16:01,074 - INFO - JSON saved to: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 (1)-29-6-22_output_20251216_141601.json
2025-12-16 14:16:02,876 - ERROR - Batch processing failed or returned no output
2025-12-16 14:16:02,878 - ERROR - Multi-part processing returned no final output file
2025-12-16 14:18:53,381 - INFO - Processing Part 1 with second-stage prompt...
2025-12-16 14:18:55,445 - ERROR - Text processing failed: 429 Resource has been exhausted (e.g. check quota).
2025-12-16 14:18:55,447 - ERROR - No response for Part 1, aborting post-process
2025-12-16 14:25:36,823 - INFO - Loaded 6 predefined prompts
2025-12-16 14:26:06,109 - INFO - Loaded 3 API keys
2025-12-16 14:28:05,510 - INFO - Processing Part 1 with second-stage prompt...
2025-12-16 14:28:07,952 - ERROR - Text processing failed: 429 Resource has been exhausted (e.g. check quota).
2025-12-16 14:28:07,953 - ERROR - No response for Part 1, aborting post-process
2025-12-17 08:10:45,284 - INFO - Loaded 6 predefined prompts
2025-12-17 08:11:05,877 - INFO - Loaded 3 API keys
2025-12-17 08:15:11,068 - INFO - Processing Part 1 with second-stage prompt...
2025-12-17 08:17:07,984 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 08:17:07,988 - ERROR - Failed to parse JSON response in post-processor
2025-12-17 08:17:07,989 - ERROR - Failed to parse JSON for Part 1, aborting
2025-12-17 08:20:22,048 - INFO - Loaded 6 predefined prompts
2025-12-17 08:20:45,238 - INFO - Loaded 3 API keys
2025-12-17 08:22:12,137 - INFO - Processing Part 1 with second-stage prompt...
2025-12-17 08:23:55,162 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 08:23:55,172 - INFO - Processing Part 2 with second-stage prompt...
2025-12-17 08:25:56,001 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 08:25:56,006 - ERROR - Failed to parse JSON response in post-processor
2025-12-17 08:25:56,006 - ERROR - Response length: 31706
2025-12-17 08:25:56,007 - ERROR - Response text (first 1000 chars):
```json
{
  "chapter": "گروه پمفیگوئید",
  "content": [
    {
      "level_1": "فصل: گروه پمفیگوئید",
      "children": [
        {
          "level_2": "زیرفصل: پمفیگوئید غشاء مخاطی (MMP) - کلیات",
          "children": [
            {
              "level_3": "مبحث: تعاریف و تاریخچه",
              "children": [
                {
                  "level_4": "عنوان: تعاریف کلیدی و مشخصات اصلی",
                  "children": [
                    {
                      "level_5": "زیرعنوان: ماهیت بیماری",
                      "points": [
                        "• یک اختلال تاولی، خودایمن و مزمن زیر اپیتلیال",
                        "• مشخصه اصلی: درگیری غالب سطوح مخاطی خارجی",
                        "• مشخصه اصلی: تمایل به ایجاد اسکار در نواحی درگیر",
                        "• یک \"فنوتیپ بیماری\" مشترک بین گروهی از بیماری‌های هتروژن با ترجیح درگیری مخاط",
                        "• سیر مزمن و پیشرونده"
                      ]
                    },
                    {
       
2025-12-17 08:25:56,008 - ERROR - Direct parse error: Expecting value: line 1 column 1 (char 0)
2025-12-17 08:25:56,008 - ERROR - Extract parse error: Expecting ',' delimiter: line 624 column 24 (char 31298)
2025-12-17 08:25:56,008 - ERROR - Failed to parse JSON for Part 2, aborting
2025-12-17 08:25:56,009 - ERROR - Response received (first 500 chars): ```json
{
  "chapter": "گروه پمفیگوئید",
  "content": [
    {
      "level_1": "فصل: گروه پمفیگوئید",
      "children": [
        {
          "level_2": "زیرفصل: پمفیگوئید غشاء مخاطی (MMP) - کلیات",
          "children": [
            {
              "level_3": "مبحث: تعاریف و تاریخچه",
              "children": [
                {
                  "level_4": "عنوان: تعاریف کلیدی و مشخصات اصلی",
                  "children": [
                    {
                      "level_5": "زیرعنوان: ما
2025-12-17 08:31:26,909 - INFO - Loaded 6 predefined prompts
2025-12-17 08:31:51,475 - INFO - Loaded 3 API keys
2025-12-17 08:33:10,015 - INFO - Processing Part 1 with second-stage prompt...
2025-12-17 08:35:10,716 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 08:35:10,720 - INFO - Processing Part 2 with second-stage prompt...
2025-12-17 08:36:42,660 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 08:36:42,660 - INFO - Processing Part 3 with second-stage prompt...
2025-12-17 08:38:04,937 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 08:38:04,941 - INFO - Post-processed output saved to: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed.txt
2025-12-17 08:43:32,623 - INFO - Loaded 6 predefined prompts
2025-12-17 08:43:51,371 - INFO - Loaded 3 API keys
2025-12-17 08:45:16,851 - INFO - Loading input JSON file: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-17 08:45:16,864 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-17 08:45:16,866 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-17 08:45:16,881 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-17 08:47:15,416 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 08:47:15,417 - INFO - Part 1 processed successfully. Response length: 27438 characters
2025-12-17 08:47:15,423 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-17 08:49:11,357 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 08:49:11,358 - INFO - Part 2 processed successfully. Response length: 21308 characters
2025-12-17 08:49:11,360 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-17 08:50:31,669 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 08:50:31,670 - INFO - Part 3 processed successfully. Response length: 18410 characters
2025-12-17 08:50:31,671 - INFO - Combining responses from all parts...
2025-12-17 08:50:31,671 - INFO - Extracting JSON blocks from responses...
2025-12-17 08:50:31,702 - INFO - Found 2 JSON block(s) in responses
2025-12-17 08:50:31,705 - WARNING - Failed to parse JSON block 2/2: Expecting ',' delimiter: line 428 column 12 (char 21299). Attempting fallback extraction...
2025-12-17 08:50:31,706 - WARNING - Fallback extraction failed for block 2
2025-12-17 08:50:31,706 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-17 08:50:31,706 - INFO - Combining JSON blocks into final structure...
2025-12-17 08:50:31,706 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-17 08:50:31,707 - INFO - Saving post-processed JSON to: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed.json
2025-12-17 08:50:31,712 - INFO - Post-processed JSON saved successfully: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed.json
2025-12-17 08:56:50,411 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 08:56:50,427 - ERROR - Failed to parse JSON from response. Direct parse error: Expecting value: line 1 column 1 (char 0), Extract parse error: Expecting ',' delimiter: line 842 column 22 (char 44493)
2025-12-17 08:56:50,429 - WARNING - Could not parse hierarchical structure from model response.

Reason: Failed to extract JSON from response string.
2025-12-17 09:07:21,346 - INFO - Loaded 6 predefined prompts
2025-12-17 09:07:40,348 - INFO - Loaded 3 API keys
2025-12-17 09:11:36,675 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 09:11:36,716 - INFO - Loading third stage file: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed_corrected_raw.json
2025-12-17 09:11:36,727 - INFO - Extracting JSON from response field...
2025-12-17 09:11:36,779 - WARNING - Direct JSON parse failed: Expecting value: line 1 column 1 (char 0). Trying fallback extraction...
2025-12-17 09:11:36,780 - ERROR - Failed to extract JSON from response
2025-12-17 09:11:36,780 - WARNING - Converter failed, falling back to old method
2025-12-17 09:11:36,782 - ERROR - Failed to parse JSON from response. Direct parse error: Expecting value: line 1 column 1 (char 0), Extract parse error: Expecting ',' delimiter: line 897 column 14 (char 40218)
2025-12-17 09:11:36,783 - WARNING - Could not parse hierarchical structure from model response.

Reason: Failed to extract JSON from response string.
2025-12-17 09:14:26,379 - INFO - Loaded 6 predefined prompts
2025-12-17 09:14:59,051 - INFO - Loaded 3 API keys
2025-12-17 09:18:58,263 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 09:18:58,316 - INFO - Loading third stage file: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed_corrected_raw.json
2025-12-17 09:18:58,321 - INFO - Extracting JSON from response field...
2025-12-17 09:18:58,386 - WARNING - Direct JSON parse failed: Expecting value: line 1 column 1 (char 0). Trying fallback extraction...
2025-12-17 09:18:58,387 - WARNING - Object extraction parse failed: Expecting ',' delimiter: line 844 column 22 (char 43852)
2025-12-17 09:18:58,399 - ERROR - All JSON extraction methods failed
2025-12-17 09:18:58,399 - ERROR - Failed to extract JSON from response
2025-12-17 09:18:58,399 - WARNING - Converter failed, falling back to old method
2025-12-17 09:18:58,401 - ERROR - Failed to parse JSON from response. Direct parse error: Expecting value: line 1 column 1 (char 0), Extract parse error: Expecting ',' delimiter: line 844 column 22 (char 43852)
2025-12-17 09:18:58,401 - WARNING - Could not parse hierarchical structure from model response.

Reason: Failed to extract JSON from response string.
2025-12-17 09:46:17,452 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 09:46:17,463 - INFO - Loading third stage file: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed_corrected_raw.json
2025-12-17 09:46:17,470 - INFO - Extracting JSON from response field...
2025-12-17 09:46:17,543 - WARNING - Direct JSON parse failed: Expecting value: line 1 column 1 (char 0). Trying fallback extraction...
2025-12-17 09:46:17,544 - WARNING - Object extraction parse failed: Expecting ',' delimiter: line 895 column 22 (char 47987)
2025-12-17 09:46:17,561 - ERROR - All JSON extraction methods failed
2025-12-17 09:46:17,564 - ERROR - Failed to extract JSON from response
2025-12-17 09:46:17,564 - WARNING - Converter failed, falling back to old method
2025-12-17 09:46:17,566 - ERROR - Failed to parse JSON from response. Direct parse error: Expecting value: line 1 column 1 (char 0), Extract parse error: Expecting ',' delimiter: line 895 column 22 (char 47987)
2025-12-17 09:46:17,567 - WARNING - Could not parse hierarchical structure from model response.

Reason: Failed to extract JSON from response string.
2025-12-17 10:10:46,242 - INFO - Loaded 6 predefined prompts
2025-12-17 10:12:06,938 - INFO - Loaded 3 API keys
2025-12-17 10:13:32,247 - INFO - Starting third-stage chunked processing...
2025-12-17 10:13:32,248 - INFO - Processing third-stage chunk 1...
2025-12-17 10:15:11,212 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 10:15:11,213 - INFO - Chunk 1: added 1 content item(s). Total so far: 1
2025-12-17 10:15:11,213 - INFO - Processing third-stage chunk 2...
2025-12-17 10:17:16,626 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 10:17:16,631 - INFO - Chunk 2: added 1 content item(s). Total so far: 2
2025-12-17 10:17:16,633 - INFO - Processing third-stage chunk 3...
2025-12-17 10:18:43,355 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 10:18:43,359 - INFO - Chunk 3: added 1 content item(s). Total so far: 3
2025-12-17 10:18:43,361 - INFO - Processing third-stage chunk 4...
2025-12-17 10:19:51,285 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 10:19:51,286 - INFO - Chunk 4: added 1 content item(s). Total so far: 4
2025-12-17 10:19:51,288 - INFO - Received last chunk (index=4).
2025-12-17 10:19:51,288 - INFO - Third-stage chunked processing completed. Total content items: 4
2025-12-17 10:19:51,303 - INFO - Loading third stage file: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed_corrected_raw.json
2025-12-17 10:19:51,304 - INFO - Extracting JSON from response field...
2025-12-17 10:19:51,306 - INFO - Flattening hierarchical structure to points...
2025-12-17 10:19:51,306 - INFO - Processing chapter: 'گروه پمفیگوئید' with 4 top-level items
2025-12-17 10:19:51,312 - INFO - Extracted 561 points. Generating PointIds...
2025-12-17 10:19:51,320 - INFO - Saving converted JSON to: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed_corrected_raw_converted.json
2025-12-17 10:19:51,338 - INFO - Successfully converted and saved: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed_corrected_raw_converted.json
2025-12-17 11:33:55,629 - INFO - Loaded 6 predefined prompts
2025-12-17 11:34:54,421 - INFO - Loaded 3 API keys
2025-12-17 11:37:24,295 - INFO - Starting third-stage chunked processing...
2025-12-17 11:37:24,296 - INFO - Processing third-stage chunk 1...
2025-12-17 11:38:36,138 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 11:38:36,140 - ERROR - Error in fourth-stage processing: 'list' object has no attribute 'get'
Traceback (most recent call last):
  File "/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/main_gui.py", line 1541, in process_fourth_stage_worker
    final_structured_json = run_third_stage_chunked(
                            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/third_stage_chunk_processor.py", line 179, in run_third_stage_chunked
    payload_content = payload.get("content", [])
                      ^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'get'
2025-12-17 11:42:34,092 - INFO - Loaded 6 predefined prompts
2025-12-17 11:42:53,460 - INFO - Loaded 3 API keys
2025-12-17 11:44:20,498 - INFO - Starting third-stage chunked processing...
2025-12-17 11:44:20,498 - INFO - Processing third-stage chunk 1...
2025-12-17 11:45:11,604 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 11:45:11,605 - INFO - Chunk 1: added 10 content item(s). Total so far: 10
2025-12-17 11:45:11,606 - INFO - Processing third-stage chunk 2...
2025-12-17 11:45:59,219 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 11:45:59,220 - INFO - Chunk 2: added 7 content item(s). Total so far: 17
2025-12-17 11:45:59,222 - INFO - Processing third-stage chunk 3...
2025-12-17 11:46:32,499 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 11:46:32,500 - INFO - Chunk 3: added 4 content item(s). Total so far: 21
2025-12-17 11:46:32,500 - INFO - Processing third-stage chunk 4...
2025-12-17 11:47:47,465 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 11:47:47,468 - INFO - Chunk 4: added 21 content item(s). Total so far: 42
2025-12-17 11:47:47,470 - INFO - Received last chunk (index=4).
2025-12-17 11:47:47,472 - INFO - Third-stage chunked processing completed. Total content items: 42
2025-12-17 12:18:59,199 - INFO - Loaded 6 predefined prompts
2025-12-17 12:20:17,132 - INFO - Loaded 3 API keys
2025-12-17 12:24:13,765 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 12:27:40,805 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 12:32:22,280 - INFO - Starting third-stage chunked processing...
2025-12-17 12:32:22,281 - INFO - Processing third-stage chunk 1...
2025-12-17 12:34:41,351 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 12:34:41,352 - ERROR - Failed to parse JSON for third-stage chunk 1: Expecting value: line 1 column 1 (char 0)
2025-12-17 12:59:32,055 - INFO - Loaded 6 predefined prompts
2025-12-17 12:59:50,716 - INFO - Loaded 3 API keys
2025-12-17 13:05:17,229 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 13:07:38,775 - INFO - Starting third-stage chunked processing...
2025-12-17 13:07:38,776 - INFO - Processing third-stage chunk 1...
2025-12-17 13:08:55,572 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 13:08:55,576 - INFO - Chunk 1: added 1 content item(s). Total so far: 1
2025-12-17 13:08:55,578 - INFO - Processing third-stage chunk 2...
2025-12-17 13:10:52,894 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 13:10:52,899 - INFO - Chunk 2: added 1 content item(s). Total so far: 2
2025-12-17 13:10:52,901 - INFO - Processing third-stage chunk 3...
2025-12-17 13:12:56,733 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 13:12:56,738 - INFO - Chunk 3: added 1 content item(s). Total so far: 3
2025-12-17 13:12:56,740 - INFO - Processing third-stage chunk 4...
2025-12-17 13:14:25,647 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 13:14:25,656 - INFO - Chunk 4: added 1 content item(s). Total so far: 4
2025-12-17 13:14:25,660 - INFO - Received last chunk (index=4).
2025-12-17 13:14:25,661 - INFO - Third-stage chunked processing completed. Total content items: 4
2025-12-17 13:14:25,675 - WARNING - Failed to save raw corrected JSON: [Errno 36] File name too long: '/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed_corrected_stage3_raw_converted_corrected_raw.json'
2025-12-17 13:14:25,676 - ERROR - Input file not found: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed_corrected_stage3_raw_converted_corrected_raw.json
2025-12-17 13:14:25,676 - WARNING - Converter failed, falling back to old method
2025-12-17 13:14:25,684 - ERROR - Error in third-stage processing: [Errno 36] File name too long: '/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed_corrected_stage3_raw_converted_corrected.json'
Traceback (most recent call last):
  File "/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/main_gui.py", line 1487, in process_third_stage_worker
    with open(output_path, "w", encoding="utf-8") as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 36] File name too long: '/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed_corrected_stage3_raw_converted_corrected.json'
2025-12-17 13:23:07,442 - INFO - Loaded 6 predefined prompts
2025-12-17 13:23:58,313 - INFO - Loaded 3 API keys
2025-12-17 13:26:09,486 - INFO - Starting third-stage chunked processing...
2025-12-17 13:26:09,487 - INFO - Processing third-stage chunk 1...
2025-12-17 13:27:59,516 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 13:27:59,520 - INFO - Chunk 1: added 1 content item(s). Total so far: 1
2025-12-17 13:27:59,522 - INFO - Processing third-stage chunk 2...
2025-12-17 13:29:35,924 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 13:29:35,928 - INFO - Chunk 2: added 1 content item(s). Total so far: 2
2025-12-17 13:29:35,929 - INFO - Processing third-stage chunk 3...
2025-12-17 13:31:15,664 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 13:31:15,667 - INFO - Chunk 3: added 1 content item(s). Total so far: 3
2025-12-17 13:31:15,669 - INFO - Processing third-stage chunk 4...
2025-12-17 13:33:11,812 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 13:33:11,816 - INFO - Chunk 4: added 1 content item(s). Total so far: 4
2025-12-17 13:33:11,818 - INFO - Processing third-stage chunk 5...
2025-12-17 13:34:46,791 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-17 13:34:46,792 - INFO - Chunk 5: added 1 content item(s). Total so far: 5
2025-12-17 13:34:46,792 - INFO - Received last chunk (index=5).
2025-12-17 13:34:46,792 - INFO - Third-stage chunked processing completed. Total content items: 5
2025-12-17 13:34:46,797 - WARNING - Failed to save raw corrected JSON: [Errno 36] File name too long: '/home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed_corrected_stage3_raw_converted_corrected_raw.json'
2025-12-17 13:34:46,798 - ERROR - Input file not found: /home/mohammadbagher/Desktop/tts app bagher/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_Bolognia 5th Edition 2024 1-7-26-46_final_output_post_processed_corrected_stage3_raw_converted_corrected_raw.json
2025-12-17 13:34:46,798 - WARNING - Converter failed, falling back to old method
2025-12-17 14:04:32,649 - INFO - Loaded 6 predefined prompts
2025-12-17 14:10:11,088 - INFO - Starting fourth-stage chunked processing...
2025-12-17 14:10:11,090 - INFO - Processing fourth-stage chunk 1...
2025-12-17 14:10:11,091 - ERROR - No API key available
2025-12-17 14:10:11,093 - INFO - ❌ No response for chunk 1
2025-12-18 10:14:17,909 - INFO - Loaded 6 predefined prompts
2025-12-18 11:00:37,401 - INFO - Loaded 6 predefined prompts
2025-12-18 11:04:38,955 - INFO - Loaded 3 API keys
2025-12-18 11:15:42,612 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 11:15:42,615 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 11:15:42,615 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 11:15:42,618 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 11:17:46,691 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:17:46,691 - INFO - Part 1 processed successfully. Response length: 20331 characters
2025-12-18 11:17:46,694 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 11:19:46,032 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:19:46,032 - INFO - Part 2 processed successfully. Response length: 41209 characters
2025-12-18 11:19:46,033 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 11:21:18,486 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:21:18,486 - INFO - Part 3 processed successfully. Response length: 19609 characters
2025-12-18 11:21:18,487 - INFO - Combining responses from all parts...
2025-12-18 11:21:18,487 - INFO - Extracting JSON blocks from responses...
2025-12-18 11:21:18,493 - INFO - Found 2 JSON block(s) in responses
2025-12-18 11:21:18,494 - WARNING - Failed to parse JSON block 1/2: Unterminated string starting at: line 402 column 25 (char 20316). Attempting fallback extraction...
2025-12-18 11:21:18,494 - WARNING - Fallback extraction failed for block 1
2025-12-18 11:21:18,494 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-18 11:21:18,495 - INFO - Combining JSON blocks into final structure...
2025-12-18 11:21:18,495 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-18 11:21:18,495 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 11:21:18,497 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 11:21:18,514 - INFO - Starting third-stage chunked processing...
2025-12-18 11:21:18,515 - INFO - Processing third-stage chunk 1...
2025-12-18 11:22:30,389 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:22:30,393 - INFO - Chunk 1: added 1 content item(s). Total so far: 1
2025-12-18 11:22:30,394 - INFO - Processing third-stage chunk 2...
2025-12-18 11:23:52,751 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:23:52,754 - INFO - Chunk 2: added 1 content item(s). Total so far: 2
2025-12-18 11:23:52,756 - INFO - Processing third-stage chunk 3...
2025-12-18 11:25:31,906 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:25:31,910 - INFO - Chunk 3: added 1 content item(s). Total so far: 3
2025-12-18 11:25:31,911 - INFO - Processing third-stage chunk 4...
2025-12-18 11:27:22,587 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:27:22,589 - INFO - Chunk 4: added 1 content item(s). Total so far: 4
2025-12-18 11:27:22,590 - INFO - Processing third-stage chunk 5...
2025-12-18 11:28:53,139 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:28:53,144 - INFO - Chunk 5: added 1 content item(s). Total so far: 5
2025-12-18 11:28:53,145 - INFO - Received last chunk (index=5).
2025-12-18 11:28:53,146 - INFO - Third-stage chunked processing completed. Total content items: 5
2025-12-18 11:28:53,148 - INFO - Processing chapter: 'گروه پمفیگوئید' with 5 top-level items
2025-12-18 11:28:53,173 - INFO - Starting fourth-stage chunked processing...
2025-12-18 11:28:53,174 - INFO - Processing fourth-stage chunk 1...
2025-12-18 11:30:39,264 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:30:39,265 - INFO - Chunk 1: added 1 content item(s). Total so far: 1
2025-12-18 11:30:39,266 - INFO - Processing fourth-stage chunk 2...
2025-12-18 11:33:05,308 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:33:05,309 - ERROR - Failed to parse JSON for fourth-stage chunk 2: Expecting value: line 1 column 1 (char 0)
2025-12-18 11:33:05,342 - INFO - Starting third-stage chunked processing...
2025-12-18 11:33:05,343 - INFO - Processing third-stage chunk 1...
2025-12-18 11:34:24,571 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:34:24,573 - INFO - Chunk 1: added 1 content item(s). Total so far: 1
2025-12-18 11:34:24,574 - INFO - Processing third-stage chunk 2...
2025-12-18 11:36:30,752 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:36:30,756 - INFO - Chunk 2: added 1 content item(s). Total so far: 2
2025-12-18 11:36:30,757 - INFO - Processing third-stage chunk 3...
2025-12-18 11:37:29,393 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:37:29,394 - INFO - Chunk 3: added 1 content item(s). Total so far: 3
2025-12-18 11:37:29,395 - INFO - Processing third-stage chunk 4...
2025-12-18 11:39:23,347 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:39:23,349 - INFO - Chunk 4: added 1 content item(s). Total so far: 4
2025-12-18 11:39:23,350 - INFO - Processing third-stage chunk 5...
2025-12-18 11:40:59,330 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:40:59,332 - INFO - Chunk 5: added 1 content item(s). Total so far: 5
2025-12-18 11:40:59,334 - INFO - Processing third-stage chunk 6...
2025-12-18 11:42:04,835 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:42:04,837 - INFO - Chunk 6: added 1 content item(s). Total so far: 6
2025-12-18 11:42:04,839 - INFO - Processing third-stage chunk 7...
2025-12-18 11:43:44,663 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:43:44,665 - INFO - Chunk 7: added 1 content item(s). Total so far: 7
2025-12-18 11:43:44,668 - INFO - Received last chunk (index=7).
2025-12-18 11:43:44,669 - INFO - Third-stage chunked processing completed. Total content items: 7
2025-12-18 11:43:44,670 - INFO - Processing chapter: 'گروه پمفیگوئید' with 7 top-level items
2025-12-18 11:43:44,693 - INFO - Starting fourth-stage chunked processing...
2025-12-18 11:43:44,694 - INFO - Processing fourth-stage chunk 1...
2025-12-18 11:45:12,154 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:45:12,157 - INFO - Chunk 1: added 1 content item(s). Total so far: 1
2025-12-18 11:45:12,158 - INFO - Processing fourth-stage chunk 2...
2025-12-18 11:47:18,345 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:47:18,347 - INFO - Chunk 2: added 1 content item(s). Total so far: 2
2025-12-18 11:47:18,348 - INFO - Processing fourth-stage chunk 3...
2025-12-18 11:48:48,705 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:48:48,706 - INFO - Chunk 3: added 1 content item(s). Total so far: 3
2025-12-18 11:48:48,707 - INFO - Processing fourth-stage chunk 4...
2025-12-18 11:50:20,146 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:50:20,148 - INFO - Chunk 4: added 1 content item(s). Total so far: 4
2025-12-18 11:50:20,149 - INFO - Processing fourth-stage chunk 5...
2025-12-18 11:51:38,966 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:51:38,968 - INFO - Chunk 5: added 1 content item(s). Total so far: 5
2025-12-18 11:51:38,969 - INFO - Processing fourth-stage chunk 6...
2025-12-18 11:53:29,955 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:53:29,958 - INFO - Chunk 6: added 1 content item(s). Total so far: 6
2025-12-18 11:53:29,959 - INFO - Received last chunk (index=6).
2025-12-18 11:53:29,960 - INFO - Third-stage chunked processing completed. Total content items: 6
2025-12-18 11:53:29,992 - INFO - Starting third-stage chunked processing...
2025-12-18 11:53:29,993 - INFO - Processing third-stage chunk 1...
2025-12-18 11:55:19,411 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:55:19,413 - INFO - Chunk 1: added 1 content item(s). Total so far: 1
2025-12-18 11:55:19,414 - INFO - Processing third-stage chunk 2...
2025-12-18 11:56:37,348 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:56:37,350 - INFO - Chunk 2: added 1 content item(s). Total so far: 2
2025-12-18 11:56:37,350 - INFO - Processing third-stage chunk 3...
2025-12-18 11:57:47,471 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:57:47,474 - INFO - Chunk 3: added 1 content item(s). Total so far: 3
2025-12-18 11:57:47,475 - INFO - Processing third-stage chunk 4...
2025-12-18 11:59:51,028 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 11:59:51,030 - INFO - Chunk 4: added 1 content item(s). Total so far: 4
2025-12-18 11:59:51,032 - INFO - Processing third-stage chunk 5...
2025-12-18 12:01:20,383 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:01:20,386 - INFO - Chunk 5: added 1 content item(s). Total so far: 5
2025-12-18 12:01:20,387 - INFO - Received last chunk (index=5).
2025-12-18 12:01:20,388 - INFO - Third-stage chunked processing completed. Total content items: 5
2025-12-18 12:01:20,389 - INFO - Processing chapter: 'گروه پمفیگوئید' with 5 top-level items
2025-12-18 12:01:20,413 - INFO - Starting fourth-stage chunked processing...
2025-12-18 12:01:20,413 - INFO - Processing fourth-stage chunk 1...
2025-12-18 12:03:03,798 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:03:03,802 - INFO - Chunk 1: added 1 content item(s). Total so far: 1
2025-12-18 12:03:03,804 - INFO - Processing fourth-stage chunk 2...
2025-12-18 12:05:18,922 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:05:18,923 - INFO - Chunk 2: added 1 content item(s). Total so far: 2
2025-12-18 12:05:18,924 - INFO - Processing fourth-stage chunk 3...
2025-12-18 12:07:42,032 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:07:42,033 - ERROR - Failed to parse JSON for fourth-stage chunk 3: Expecting value: line 1 column 1 (char 0)
2025-12-18 12:12:12,997 - INFO - Loaded 6 predefined prompts
2025-12-18 12:12:40,737 - INFO - Loaded 3 API keys
2025-12-18 12:14:25,534 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 12:14:25,538 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 12:14:25,538 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 12:14:25,542 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 12:16:24,612 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:16:24,613 - INFO - Part 1 processed successfully. Response length: 40734 characters
2025-12-18 12:16:24,615 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 12:18:26,958 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:18:26,959 - INFO - Part 2 processed successfully. Response length: 26283 characters
2025-12-18 12:18:26,960 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 12:19:53,485 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:19:53,486 - INFO - Part 3 processed successfully. Response length: 25089 characters
2025-12-18 12:19:53,487 - INFO - Combining responses from all parts...
2025-12-18 12:19:53,487 - INFO - Extracting JSON blocks from responses...
2025-12-18 12:19:53,496 - INFO - Found 3 JSON block(s) in responses
2025-12-18 12:19:53,496 - INFO - Successfully extracted 3 valid JSON block(s)
2025-12-18 12:19:53,496 - INFO - Combining JSON blocks into final structure...
2025-12-18 12:19:53,497 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 3 content items
2025-12-18 12:19:53,497 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 12:19:53,498 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 12:19:53,513 - INFO - Starting third-stage chunked processing...
2025-12-18 12:19:53,513 - INFO - Processing third-stage chunk 1...
2025-12-18 12:21:31,035 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:21:31,038 - INFO - Chunk 1: added 1 content item(s). Total so far: 1
2025-12-18 12:21:31,039 - INFO - Processing third-stage chunk 2...
2025-12-18 12:22:47,430 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:22:47,432 - INFO - Chunk 2: added 1 content item(s). Total so far: 2
2025-12-18 12:22:47,434 - INFO - Processing third-stage chunk 3...
2025-12-18 12:24:19,640 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:24:19,643 - INFO - Chunk 3: added 1 content item(s). Total so far: 3
2025-12-18 12:24:19,646 - INFO - Processing third-stage chunk 4...
2025-12-18 12:25:59,353 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:25:59,354 - INFO - Chunk 4: added 1 content item(s). Total so far: 4
2025-12-18 12:25:59,355 - INFO - Received last chunk (index=4).
2025-12-18 12:25:59,356 - INFO - Third-stage chunked processing completed. Total content items: 4
2025-12-18 12:25:59,372 - INFO - Starting fourth-stage chunked processing...
2025-12-18 12:25:59,372 - INFO - Processing fourth-stage chunk 1...
2025-12-18 12:27:12,147 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:27:12,148 - INFO - Chunk 1: added 1 content item(s). Total so far: 1
2025-12-18 12:27:12,149 - INFO - Processing fourth-stage chunk 2...
2025-12-18 12:28:23,545 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:28:23,546 - INFO - Chunk 2: added 1 content item(s). Total so far: 2
2025-12-18 12:28:23,548 - INFO - Processing fourth-stage chunk 3...
2025-12-18 12:29:43,485 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:29:43,488 - INFO - Chunk 3: added 1 content item(s). Total so far: 3
2025-12-18 12:29:43,490 - INFO - Processing fourth-stage chunk 4...
2025-12-18 12:31:20,148 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:31:20,151 - INFO - Chunk 4: added 1 content item(s). Total so far: 4
2025-12-18 12:31:20,152 - INFO - Processing fourth-stage chunk 5...
2025-12-18 12:32:45,411 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:32:45,412 - INFO - Chunk 5: added 1 content item(s). Total so far: 5
2025-12-18 12:32:45,413 - INFO - Processing fourth-stage chunk 6...
2025-12-18 12:37:35,591 - INFO - Loaded 6 predefined prompts
2025-12-18 12:37:58,316 - INFO - Loaded 3 API keys
2025-12-18 12:40:54,996 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 12:40:54,999 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 12:40:55,000 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 12:40:55,004 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 12:42:59,058 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:42:59,058 - INFO - Part 1 processed successfully. Response length: 35418 characters
2025-12-18 12:42:59,060 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 12:44:52,998 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:44:52,998 - INFO - Part 2 processed successfully. Response length: 29519 characters
2025-12-18 12:44:53,000 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 12:46:24,383 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:46:24,384 - INFO - Part 3 processed successfully. Response length: 24789 characters
2025-12-18 12:46:24,384 - INFO - Combining responses from all parts...
2025-12-18 12:46:24,384 - INFO - Extracting JSON blocks from responses...
2025-12-18 12:46:24,397 - INFO - Found 3 JSON block(s) in responses
2025-12-18 12:46:24,398 - INFO - Successfully extracted 3 valid JSON block(s)
2025-12-18 12:46:24,398 - INFO - Combining JSON blocks into final structure...
2025-12-18 12:46:24,398 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 3 content items
2025-12-18 12:46:24,399 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 12:46:24,402 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 12:48:36,263 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:48:36,264 - WARNING - No closing markdown marker found, JSON may be incomplete
2025-12-18 12:48:36,266 - WARNING - Direct JSON parse failed: Expecting property name enclosed in double quotes: line 661 column 100 (char 38863). Trying fallback extraction...
2025-12-18 12:48:36,267 - WARNING - Object extraction parse failed: Expecting ',' delimiter: line 659 column 22 (char 38740)
2025-12-18 12:48:36,274 - INFO - Attempting to repair incomplete JSON...
2025-12-18 12:48:36,282 - WARNING - Repair method returned None
2025-12-18 12:48:36,282 - ERROR - All JSON extraction methods failed
2025-12-18 12:56:08,512 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 12:56:08,515 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 12:56:08,515 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 12:56:08,519 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 12:57:59,310 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:57:59,311 - INFO - Part 1 processed successfully. Response length: 35659 characters
2025-12-18 12:57:59,313 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 12:59:49,215 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 12:59:49,216 - INFO - Part 2 processed successfully. Response length: 26186 characters
2025-12-18 12:59:49,217 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 13:01:15,451 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 13:01:15,452 - INFO - Part 3 processed successfully. Response length: 23409 characters
2025-12-18 13:01:15,452 - INFO - Combining responses from all parts...
2025-12-18 13:01:15,452 - INFO - Extracting JSON blocks from responses...
2025-12-18 13:01:15,463 - INFO - Found 3 JSON block(s) in responses
2025-12-18 13:01:15,465 - INFO - Successfully extracted 3 valid JSON block(s)
2025-12-18 13:01:15,465 - INFO - Combining JSON blocks into final structure...
2025-12-18 13:01:15,465 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 3 content items
2025-12-18 13:01:15,466 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 13:01:15,470 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 13:03:22,157 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 13:03:22,157 - WARNING - No closing markdown marker found, JSON may be incomplete
2025-12-18 13:03:22,157 - WARNING - Direct JSON parse failed: Unterminated string starting at: line 271 column 25 (char 13062). Trying fallback extraction...
2025-12-18 13:03:22,158 - WARNING - Object extraction parse failed: Expecting ',' delimiter: line 263 column 18 (char 12678)
2025-12-18 13:03:22,158 - INFO - Attempting to repair incomplete JSON...
2025-12-18 13:03:22,159 - WARNING - Repair method returned None
2025-12-18 13:03:22,159 - ERROR - All JSON extraction methods failed
2025-12-18 13:23:54,884 - INFO - Loaded 6 predefined prompts
2025-12-18 13:24:39,112 - INFO - Loaded 3 API keys
2025-12-18 13:27:02,436 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 13:27:02,440 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 13:27:02,440 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 13:27:02,443 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 13:29:05,679 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 13:29:05,680 - INFO - Part 1 processed successfully. Response length: 25138 characters
2025-12-18 13:29:05,683 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 13:31:11,825 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 13:31:11,825 - INFO - Part 2 processed successfully. Response length: 33836 characters
2025-12-18 13:31:11,827 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 13:32:44,152 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 13:32:44,153 - INFO - Part 3 processed successfully. Response length: 18810 characters
2025-12-18 13:32:44,153 - INFO - Combining responses from all parts...
2025-12-18 13:32:44,153 - INFO - Extracting JSON blocks from responses...
2025-12-18 13:32:44,160 - INFO - Found 2 JSON block(s) in responses
2025-12-18 13:32:44,161 - WARNING - Failed to parse JSON block 1/2: Unterminated string starting at: line 521 column 25 (char 25103). Attempting fallback extraction...
2025-12-18 13:32:44,162 - WARNING - Fallback extraction failed for block 1
2025-12-18 13:32:44,162 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-18 13:32:44,162 - INFO - Combining JSON blocks into final structure...
2025-12-18 13:32:44,162 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-18 13:32:44,163 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 13:32:44,164 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 13:34:25,073 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 13:36:09,050 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 13:38:20,703 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 13:38:20,704 - WARNING - No closing markdown marker found, JSON may be incomplete
2025-12-18 13:38:20,705 - WARNING - Direct JSON parse failed: Unterminated string starting at: line 899 column 25 (char 44503). Trying fallback extraction...
2025-12-18 13:38:20,706 - WARNING - Object extraction parse failed: Expecting ',' delimiter: line 891 column 18 (char 44125)
2025-12-18 13:38:20,713 - INFO - Attempting to repair incomplete JSON...
2025-12-18 13:38:20,723 - WARNING - Repair method returned None
2025-12-18 13:38:20,723 - ERROR - All JSON extraction methods failed
2025-12-18 13:40:23,211 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 13:40:23,212 - WARNING - No closing markdown marker found, JSON may be incomplete
2025-12-18 13:40:23,213 - WARNING - Direct JSON parse failed: Expecting value: line 531 column 32 (char 29681). Trying fallback extraction...
2025-12-18 13:40:23,214 - WARNING - Object extraction parse failed: Expecting ',' delimiter: line 528 column 22 (char 29549)
2025-12-18 13:40:23,219 - INFO - Attempting to repair incomplete JSON...
2025-12-18 13:40:23,228 - WARNING - Repair method returned None
2025-12-18 13:40:23,228 - ERROR - All JSON extraction methods failed
2025-12-18 13:50:07,839 - INFO - Loaded 6 predefined prompts
2025-12-18 13:50:34,712 - INFO - Loaded 3 API keys
2025-12-18 13:53:32,656 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 13:53:32,658 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 13:53:32,659 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 13:53:32,662 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 13:55:43,170 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 13:55:43,171 - INFO - Part 1 processed successfully. Response length: 12860 characters
2025-12-18 13:55:43,173 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 13:57:49,542 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 13:57:49,543 - INFO - Part 2 processed successfully. Response length: 25474 characters
2025-12-18 13:57:49,544 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 13:59:07,667 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 13:59:07,668 - INFO - Part 3 processed successfully. Response length: 17400 characters
2025-12-18 13:59:07,669 - INFO - Combining responses from all parts...
2025-12-18 13:59:07,669 - INFO - Extracting JSON blocks from responses...
2025-12-18 13:59:07,674 - INFO - Found 2 JSON block(s) in responses
2025-12-18 13:59:07,674 - WARNING - Failed to parse JSON block 1/2: Unterminated string starting at: line 251 column 25 (char 12850). Attempting fallback extraction...
2025-12-18 13:59:07,675 - WARNING - Fallback extraction failed for block 1
2025-12-18 13:59:07,675 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-18 13:59:07,675 - INFO - Combining JSON blocks into final structure...
2025-12-18 13:59:07,676 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-18 13:59:07,676 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 13:59:07,678 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 14:01:08,395 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:01:08,396 - WARNING - No closing markdown marker found, JSON may be incomplete
2025-12-18 14:01:08,396 - WARNING - Direct JSON parse failed: Unterminated string starting at: line 149 column 32 (char 6943). Trying fallback extraction...
2025-12-18 14:01:08,397 - WARNING - Object extraction parse failed: Expecting ',' delimiter: line 144 column 16 (char 6800)
2025-12-18 14:01:08,399 - INFO - Attempting to repair incomplete JSON...
2025-12-18 14:01:08,401 - WARNING - Repair method returned None
2025-12-18 14:01:08,402 - ERROR - All JSON extraction methods failed
2025-12-18 14:24:01,059 - INFO - Loaded 6 predefined prompts
2025-12-18 14:24:40,188 - INFO - Loaded 3 API keys
2025-12-18 14:26:27,460 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 14:26:27,462 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 14:26:27,462 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 14:26:27,465 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 14:28:33,277 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:28:33,278 - INFO - Part 1 processed successfully. Response length: 7580 characters
2025-12-18 14:28:33,279 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 14:30:35,056 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:30:35,057 - INFO - Part 2 processed successfully. Response length: 32427 characters
2025-12-18 14:30:35,058 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 14:32:00,235 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:32:00,235 - INFO - Part 3 processed successfully. Response length: 22049 characters
2025-12-18 14:32:00,236 - INFO - Combining responses from all parts...
2025-12-18 14:32:00,236 - INFO - Extracting JSON blocks from responses...
2025-12-18 14:32:00,241 - INFO - Found 2 JSON block(s) in responses
2025-12-18 14:32:00,241 - WARNING - Failed to parse JSON block 1/2: Expecting value: line 147 column 68 (char 7571). Attempting fallback extraction...
2025-12-18 14:32:00,242 - WARNING - Fallback extraction failed for block 1
2025-12-18 14:32:00,243 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-18 14:32:00,243 - INFO - Combining JSON blocks into final structure...
2025-12-18 14:32:00,243 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-18 14:32:00,244 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 14:32:00,246 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 14:33:42,835 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:33:42,836 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk1_20251218_143342.txt
2025-12-18 14:35:16,444 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:35:16,445 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk2_20251218_143516.txt
2025-12-18 14:37:05,745 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:37:05,746 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk3_20251218_143705.txt
2025-12-18 14:38:21,446 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:38:21,447 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk4_20251218_143821.txt
2025-12-18 14:39:45,675 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:39:45,676 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk5_20251218_143945.txt
2025-12-18 14:46:26,015 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 14:46:26,019 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 14:46:26,019 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 14:46:26,023 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 14:48:38,241 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:48:38,242 - INFO - Part 1 processed successfully. Response length: 19963 characters
2025-12-18 14:48:38,244 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 14:50:33,723 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:50:33,724 - INFO - Part 2 processed successfully. Response length: 42954 characters
2025-12-18 14:50:33,725 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 14:52:12,682 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:52:12,682 - INFO - Part 3 processed successfully. Response length: 29103 characters
2025-12-18 14:52:12,683 - INFO - Combining responses from all parts...
2025-12-18 14:52:12,684 - INFO - Extracting JSON blocks from responses...
2025-12-18 14:52:12,691 - INFO - Found 2 JSON block(s) in responses
2025-12-18 14:52:12,691 - WARNING - Failed to parse JSON block 1/2: Expecting property name enclosed in double quotes: line 396 column 14 (char 19940). Attempting fallback extraction...
2025-12-18 14:52:12,692 - WARNING - Fallback extraction failed for block 1
2025-12-18 14:52:12,692 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-18 14:52:12,692 - INFO - Combining JSON blocks into final structure...
2025-12-18 14:52:12,693 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-18 14:52:12,693 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 14:52:12,695 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 14:53:57,240 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:53:57,241 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk1_20251218_145357.txt
2025-12-18 14:55:57,852 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 14:55:57,853 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk2_20251218_145557.txt
2025-12-18 14:55:57,854 - WARNING - No closing markdown marker found, JSON may be incomplete
2025-12-18 14:55:57,855 - WARNING - Direct JSON parse failed: Unterminated string starting at: line 1166 column 25 (char 45492). Trying fallback extraction...
2025-12-18 14:55:57,856 - WARNING - Object extraction parse failed: Expecting ',' delimiter: line 1162 column 22 (char 45353)
2025-12-18 14:55:57,862 - INFO - Attempting to repair incomplete JSON...
2025-12-18 14:55:57,867 - WARNING - Repair method returned None
2025-12-18 14:55:57,867 - ERROR - All JSON extraction methods failed
2025-12-18 15:04:04,068 - INFO - Loaded 6 predefined prompts
2025-12-18 15:04:26,965 - INFO - Loaded 3 API keys
2025-12-18 15:06:32,011 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 15:06:32,014 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 15:06:32,014 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 15:06:32,017 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 15:08:42,820 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:08:42,821 - INFO - Part 1 processed successfully. Response length: 42324 characters
2025-12-18 15:08:42,823 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 15:10:36,896 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:10:36,897 - INFO - Part 2 processed successfully. Response length: 20842 characters
2025-12-18 15:10:36,898 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 15:12:05,043 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:12:05,044 - INFO - Part 3 processed successfully. Response length: 19235 characters
2025-12-18 15:12:05,045 - INFO - Combining responses from all parts...
2025-12-18 15:12:05,045 - INFO - Extracting JSON blocks from responses...
2025-12-18 15:12:05,054 - INFO - Found 2 JSON block(s) in responses
2025-12-18 15:12:05,055 - WARNING - Failed to parse JSON block 1/2: Unterminated string starting at: line 775 column 25 (char 42297). Attempting fallback extraction...
2025-12-18 15:12:05,055 - WARNING - Fallback extraction failed for block 1
2025-12-18 15:12:05,055 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-18 15:12:05,056 - INFO - Combining JSON blocks into final structure...
2025-12-18 15:12:05,056 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-18 15:12:05,056 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 15:12:05,058 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 15:13:01,494 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:13:01,495 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk1_20251218_151301.txt
2025-12-18 15:14:37,863 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:14:37,864 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk2_20251218_151437.txt
2025-12-18 15:16:22,765 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:16:22,767 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk3_20251218_151622.txt
2025-12-18 15:18:12,889 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:18:12,890 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk4_20251218_151812.txt
2025-12-18 15:19:27,965 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:19:27,966 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk5_20251218_151927.txt
2025-12-18 15:20:56,987 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:20:56,989 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk6_20251218_152056.txt
2025-12-18 15:22:08,956 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:22:08,957 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk7_20251218_152208.txt
2025-12-18 15:23:24,981 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:23:24,982 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk8_20251218_152324.txt
2025-12-18 15:25:02,823 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:25:02,824 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk9_20251218_152502.txt
2025-12-18 15:26:26,045 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:26:26,046 - INFO - Saved raw Stage 3 chunk response to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage3_chunk10_20251218_152626.txt
2025-12-18 15:30:19,948 - INFO - Loaded 6 predefined prompts
2025-12-18 15:30:48,536 - INFO - Loaded 3 API keys
2025-12-18 15:32:16,203 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 15:32:16,206 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 15:32:16,206 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 15:32:16,209 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 15:34:16,875 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:34:16,876 - INFO - Part 1 processed successfully. Response length: 36500 characters
2025-12-18 15:34:16,880 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 15:36:08,953 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:36:08,954 - INFO - Part 2 processed successfully. Response length: 35529 characters
2025-12-18 15:36:08,955 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 15:37:29,816 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:37:29,817 - INFO - Part 3 processed successfully. Response length: 17959 characters
2025-12-18 15:37:29,818 - INFO - Combining responses from all parts...
2025-12-18 15:37:29,818 - INFO - Extracting JSON blocks from responses...
2025-12-18 15:37:29,830 - INFO - Found 3 JSON block(s) in responses
2025-12-18 15:37:29,831 - INFO - Successfully extracted 3 valid JSON block(s)
2025-12-18 15:37:29,832 - INFO - Combining JSON blocks into final structure...
2025-12-18 15:37:29,832 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 3 content items
2025-12-18 15:37:29,832 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 15:37:29,836 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 15:41:44,975 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:41:44,990 - INFO - Found 0 JSON block(s) in responses
2025-12-18 15:41:44,991 - ERROR - No valid JSON blocks found in responses
2025-12-18 15:49:55,833 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 15:49:55,836 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 15:49:55,836 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 15:49:55,839 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 15:52:09,691 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:52:09,692 - INFO - Part 1 processed successfully. Response length: 28809 characters
2025-12-18 15:52:09,694 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 15:53:51,020 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:53:51,021 - INFO - Part 2 processed successfully. Response length: 23401 characters
2025-12-18 15:53:51,022 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 15:55:47,258 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:55:47,259 - INFO - Part 3 processed successfully. Response length: 18256 characters
2025-12-18 15:55:47,260 - INFO - Combining responses from all parts...
2025-12-18 15:55:47,260 - INFO - Extracting JSON blocks from responses...
2025-12-18 15:55:47,267 - INFO - Found 2 JSON block(s) in responses
2025-12-18 15:55:47,268 - WARNING - Failed to parse JSON block 1/2: Unterminated string starting at: line 558 column 25 (char 28800). Attempting fallback extraction...
2025-12-18 15:55:47,268 - WARNING - Fallback extraction failed for block 1
2025-12-18 15:55:47,269 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-18 15:55:47,269 - INFO - Combining JSON blocks into final structure...
2025-12-18 15:55:47,269 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-18 15:55:47,269 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 15:55:47,271 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 15:57:48,307 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 15:57:48,313 - INFO - Found 1 JSON block(s) in responses
2025-12-18 15:57:48,313 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-18 15:57:48,313 - INFO - Combining JSON blocks into final structure...
2025-12-18 15:57:48,313 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-18 16:00:07,713 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 16:00:07,731 - INFO - Found 0 JSON block(s) in responses
2025-12-18 16:00:07,731 - ERROR - No valid JSON blocks found in responses
2025-12-18 16:02:25,117 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 16:02:25,131 - INFO - Found 0 JSON block(s) in responses
2025-12-18 16:02:25,132 - ERROR - No valid JSON blocks found in responses
2025-12-18 16:05:54,927 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 16:05:54,930 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 16:05:54,930 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 16:05:54,933 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 16:11:38,438 - INFO - Loaded 6 predefined prompts
2025-12-18 16:12:22,089 - INFO - Loaded 3 API keys
2025-12-18 16:14:23,556 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 16:14:23,560 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 16:14:23,560 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 16:14:23,564 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 16:16:34,053 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 16:16:34,054 - INFO - Part 1 processed successfully. Response length: 23313 characters
2025-12-18 16:16:34,056 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 16:18:39,171 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 16:18:39,172 - INFO - Part 2 processed successfully. Response length: 22379 characters
2025-12-18 16:18:39,174 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 16:20:16,027 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 16:20:16,028 - INFO - Part 3 processed successfully. Response length: 16726 characters
2025-12-18 16:20:16,029 - INFO - Combining responses from all parts...
2025-12-18 16:20:16,029 - INFO - Extracting JSON blocks from responses...
2025-12-18 16:20:16,035 - INFO - Found 2 JSON block(s) in responses
2025-12-18 16:20:16,036 - WARNING - Failed to parse JSON block 1/2: Unterminated string starting at: line 505 column 25 (char 23303). Attempting fallback extraction...
2025-12-18 16:20:16,036 - WARNING - Fallback extraction failed for block 1
2025-12-18 16:20:16,036 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-18 16:20:16,036 - INFO - Combining JSON blocks into final structure...
2025-12-18 16:20:16,037 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-18 16:20:16,037 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 16:20:16,038 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 16:22:20,686 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 16:22:20,694 - INFO - Found 0 JSON block(s) in responses
2025-12-18 16:22:20,694 - ERROR - No valid JSON blocks found in responses
2025-12-18 16:24:27,689 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 16:24:27,704 - INFO - Found 0 JSON block(s) in responses
2025-12-18 16:24:27,704 - ERROR - No valid JSON blocks found in responses
2025-12-18 16:26:38,006 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 16:26:38,022 - INFO - Found 0 JSON block(s) in responses
2025-12-18 16:26:38,022 - ERROR - No valid JSON blocks found in responses
2025-12-18 17:18:00,466 - INFO - Loaded 6 predefined prompts
2025-12-18 17:18:22,322 - INFO - Loaded 3 API keys
2025-12-18 17:19:49,000 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-18 17:19:49,003 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-18 17:19:49,003 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-18 17:19:49,006 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-18 17:22:08,283 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 17:22:08,284 - INFO - Part 1 processed successfully. Response length: 29410 characters
2025-12-18 17:22:08,286 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-18 17:24:28,168 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 17:24:28,169 - INFO - Part 2 processed successfully. Response length: 25394 characters
2025-12-18 17:24:28,170 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-18 17:25:53,194 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 17:25:53,195 - INFO - Part 3 processed successfully. Response length: 15093 characters
2025-12-18 17:25:53,195 - INFO - Combining responses from all parts...
2025-12-18 17:25:53,196 - INFO - Extracting JSON blocks from responses...
2025-12-18 17:25:53,203 - INFO - Found 2 JSON block(s) in responses
2025-12-18 17:25:53,204 - WARNING - Failed to parse JSON block 1/2: Unterminated string starting at: line 561 column 25 (char 29376). Attempting fallback extraction...
2025-12-18 17:25:53,204 - WARNING - Fallback extraction failed for block 1
2025-12-18 17:25:53,205 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-18 17:25:53,205 - INFO - Combining JSON blocks into final structure...
2025-12-18 17:25:53,205 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-18 17:25:53,205 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 17:25:53,207 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-18 17:28:02,638 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 17:30:17,219 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 17:32:18,127 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 17:33:51,309 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 17:35:51,722 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-18 17:37:25,878 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 13:59:20,072 - INFO - Loaded 6 predefined prompts
2025-12-19 13:59:45,091 - INFO - Loaded 3 API keys
2025-12-19 14:01:21,535 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-19 14:01:21,537 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-19 14:01:21,537 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-19 14:01:21,540 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-19 14:03:27,214 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:03:27,214 - INFO - Part 1 processed successfully. Response length: 30058 characters
2025-12-19 14:03:27,217 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-19 14:05:29,182 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:05:29,183 - INFO - Part 2 processed successfully. Response length: 35617 characters
2025-12-19 14:05:29,184 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-19 14:06:46,907 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:06:46,908 - INFO - Part 3 processed successfully. Response length: 28226 characters
2025-12-19 14:06:46,908 - INFO - Combining responses from all parts...
2025-12-19 14:06:46,909 - INFO - Extracting JSON blocks from responses...
2025-12-19 14:06:46,916 - INFO - Found 2 JSON block(s) in responses
2025-12-19 14:06:46,916 - WARNING - Failed to parse JSON block 1/2: Unterminated string starting at: line 629 column 25 (char 30043). Attempting fallback extraction...
2025-12-19 14:06:46,917 - WARNING - Fallback extraction failed for block 1
2025-12-19 14:06:46,917 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-19 14:06:46,917 - INFO - Combining JSON blocks into final structure...
2025-12-19 14:06:46,917 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-19 14:06:46,917 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-19 14:06:46,918 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-19 14:08:51,608 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:10:58,180 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:13:26,171 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:15:20,700 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:17:00,442 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:18:21,003 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:18:21,021 - WARNING - No closing markdown marker found, JSON may be incomplete
2025-12-19 14:18:21,021 - WARNING - Direct JSON parse failed: Expecting value: line 158 column 98 (char 8746). Trying fallback extraction...
2025-12-19 14:18:21,022 - WARNING - Object extraction parse failed: Expecting ',' delimiter: line 150 column 14 (char 8293)
2025-12-19 14:18:21,023 - INFO - Attempting to repair incomplete JSON...
2025-12-19 14:18:21,026 - WARNING - Repair method returned None
2025-12-19 14:18:21,026 - ERROR - All JSON extraction methods failed
2025-12-19 14:18:21,026 - INFO - Falling back to manual JSON extraction for /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage4.txt
2025-12-19 14:18:21,028 - ERROR - Failed to parse JSON from cleaned TXT content for /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage4.txt: Expecting ',' delimiter: line 150 column 14 (char 8293)
2025-12-19 14:18:21,029 - WARNING - Skipping Stage 4 TXT (could not extract JSON): /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage4.txt
2025-12-19 14:18:21,030 - INFO - Successfully extracted JSON from TXT using ThirdStageConverter for /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part2_stage4.txt
2025-12-19 14:18:21,030 - INFO - Processing chapter: 'گروه پمفیگوئید' with 1 top-level items
2025-12-19 14:18:21,031 - INFO - Successfully extracted JSON from TXT using ThirdStageConverter for /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part3_stage4.txt
2025-12-19 14:18:21,032 - INFO - Processing chapter: 'گروه پمفیگوئید' with 1 top-level items
2025-12-19 14:33:16,360 - INFO - Loaded 6 predefined prompts
2025-12-19 14:33:34,900 - INFO - Loaded 3 API keys
2025-12-19 14:34:53,638 - INFO - Loading input JSON file: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-19 14:34:53,642 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-19 14:34:53,642 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-19 14:34:53,646 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-19 14:37:00,633 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:37:00,633 - INFO - Part 1 processed successfully. Response length: 41675 characters
2025-12-19 14:37:00,636 - INFO - Processing Part 2 (36 rows) with second-stage prompt...
2025-12-19 14:39:02,140 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:39:02,141 - INFO - Part 2 processed successfully. Response length: 28195 characters
2025-12-19 14:39:02,142 - INFO - Processing Part 3 (13 rows) with second-stage prompt...
2025-12-19 14:40:40,241 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:40:40,241 - INFO - Part 3 processed successfully. Response length: 25415 characters
2025-12-19 14:40:40,242 - INFO - Combining responses from all parts...
2025-12-19 14:40:40,242 - INFO - Extracting JSON blocks from responses...
2025-12-19 14:40:40,252 - INFO - Found 2 JSON block(s) in responses
2025-12-19 14:40:40,253 - WARNING - Failed to parse JSON block 1/2: Expecting property name enclosed in double quotes: line 927 column 94 (char 41666). Attempting fallback extraction...
2025-12-19 14:40:40,254 - WARNING - Fallback extraction failed for block 1
2025-12-19 14:40:40,255 - INFO - Successfully extracted 1 valid JSON block(s)
2025-12-19 14:40:40,255 - INFO - Combining JSON blocks into final structure...
2025-12-19 14:40:40,255 - INFO - Final structure: chapter 'گروه پمفیگوئید' with 1 content items
2025-12-19 14:40:40,255 - INFO - Saving post-processed JSON to: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-19 14:40:40,256 - INFO - Post-processed JSON saved successfully: /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_stage2.json
2025-12-19 14:42:45,696 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:44:56,181 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:47:01,038 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:49:00,462 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:50:41,478 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:52:05,557 - INFO - Text processed successfully with gemini-2.5-pro
2025-12-19 14:52:05,572 - WARNING - No closing markdown marker found, JSON may be incomplete
2025-12-19 14:52:05,572 - WARNING - Direct JSON parse failed: Unterminated string starting at: line 795 column 25 (char 35452). Trying fallback extraction...
2025-12-19 14:52:05,573 - WARNING - Object extraction parse failed: Expecting ',' delimiter: line 788 column 18 (char 35212)
2025-12-19 14:52:05,578 - INFO - Attempting to repair incomplete JSON...
2025-12-19 14:52:05,585 - WARNING - Repair method returned None
2025-12-19 14:52:05,586 - ERROR - All JSON extraction methods failed
2025-12-19 14:52:05,586 - INFO - Falling back to manual JSON extraction for /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage4.txt
2025-12-19 14:52:05,589 - ERROR - Failed to parse JSON from cleaned TXT content for /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage4.txt: Expecting ',' delimiter: line 788 column 18 (char 35212)
2025-12-19 14:52:05,589 - WARNING - Skipping Stage 4 TXT (could not extract JSON): /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part1_stage4.txt
2025-12-19 14:52:05,590 - INFO - Successfully extracted JSON from TXT using ThirdStageConverter for /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part2_stage4.txt
2025-12-19 14:52:05,590 - INFO - Processing chapter: 'گروه پمفیگوئید' with 1 top-level items
2025-12-19 14:52:05,591 - INFO - Successfully extracted JSON from TXT using ThirdStageConverter for /home/shahmir/Downloads/Bolognia 5th Edition 2024 1-7-26-46_final_output_part3_stage4.txt
2025-12-19 14:52:05,591 - INFO - Processing chapter: 'گروه پمفیگوئید' with 1 top-level items
2025-12-19 15:28:03,681 - INFO - Loaded 6 predefined prompts
2025-12-19 15:29:30,357 - INFO - Loaded 6 predefined prompts
2025-12-19 15:29:59,765 - INFO - Loaded 6 predefined prompts
2025-12-19 15:30:29,282 - INFO - Loaded 6 predefined prompts
2025-12-19 15:31:58,121 - INFO - Loaded 3 API keys
2025-12-19 15:32:24,781 - INFO - Loading input JSON file: /media/shahmir/Program/automation_pileh/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-19 15:32:24,784 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-19 15:32:24,784 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-19 15:32:24,787 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-19 15:32:25,908 - ERROR - Text processing failed: 403 Received http2 header with status: 403
2025-12-19 15:32:25,909 - ERROR - No response received for Part 1, aborting post-process
2025-12-19 15:33:02,688 - INFO - Loading input JSON file: /media/shahmir/Program/automation_pileh/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-19 15:33:02,692 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-19 15:33:02,693 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-19 15:33:02,697 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-19 15:43:02,704 - ERROR - Text processing failed: 504 Deadline Exceeded
2025-12-19 15:43:02,705 - ERROR - No response received for Part 1, aborting post-process
2025-12-19 15:44:17,925 - INFO - Loading input JSON file: /media/shahmir/Program/automation_pileh/content_automation_project/Bolognia 5th Edition 2024 1-7-26-46_final_output.json
2025-12-19 15:44:17,929 - INFO - Found 143 rows in input JSON. Grouping by Part...
2025-12-19 15:44:17,929 - INFO - Processing 3 parts: [1, 2, 3]
2025-12-19 15:44:17,933 - INFO - Processing Part 1 (94 rows) with second-stage prompt...
2025-12-19 17:38:15,547 - INFO - Loaded 6 predefined prompts
